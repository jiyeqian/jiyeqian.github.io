<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jiye Qian</title>
    <link href="http://qianjiye.de/feed/" rel="self" />
    <link href="http://qianjiye.de" />
    <lastbuilddate>2015-01-19T21:20:50+08:00</lastbuilddate>
    <webmaster>ccf.developer@gmail.com</webmaster>
    
    <item>
      <title>å›¾åƒåˆ†ç±»ï¼ˆ1ï¼‰ï¼šåŸºäºkæœ€è¿‘é‚»ç®—æ³•çš„ç®€ä»‹</title>
      <link href="http://qianjiye.de/2015/01/image-classification-knn-based-introduction" />
      <pubdate>2015-01-19T17:20:03+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/image-classification-knn-based-introduction</guid>
      <content:encoded>&lt;![CDATA[<p>æœ¬æ–‡ä¸»è¦å‚è€ƒ<em>Convolutional Neural Networks for Visual Recognition</em><a href="#lifeifei_CNN_kNN_2015">[1]</a>è¯¾ç¨‹ç¬”è®°ã€‚</p>

<h2 id="section">ç®€ä»‹</h2>

<p>å›¾åƒåˆ†ç±»çš„ä»»åŠ¡æ˜¯æ ¹æ®å·²çŸ¥çš„ç¡®å®šæ ‡ç­¾é›†ï¼Œä¸ºè¾“å…¥å›¾åƒåˆ†é…ä¸€ä¸ªæ ‡ç­¾ï¼ˆæ ‡ç­¾å°±æ˜¯æ‰€è°“çš„ç±»åˆ«ï¼‰ã€‚å…¶å®ƒä¸€äº›è®¡ç®—æœºè§†è§‰é—®é¢˜ï¼Œæ¯”å¦‚ç›®æ ‡æå–ã€åˆ†å‰²ç­‰ï¼Œéƒ½å¯ä»¥è¢«å½’ç»“åˆ°å›¾åƒåˆ†ç±»ã€‚</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-classify.png"><img src="/assets/images/2015-01-19-image-classification-knn-based-introduction-classify.png" alt="å›¾åƒåˆ†ç±»ç¤ºä¾‹" /></a><div class="caption">Figure 1:  å›¾åƒåˆ†ç±»ç¤ºä¾‹ [<a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-classify.png">PNG</a>]</div></div></div>

<p>ä¸Šå›¾å±•ç¤ºä¸€ä¸ªå›¾åƒåˆ†ç±»æ¨¡å‹ï¼Œé€šè¿‡è®¡ç®—å±äº4ä¸ªæ ‡ç­¾ï½›ğŸ±ï¼ŒğŸ¶ï¼ŒğŸ©ï¼ŒğŸµï½çš„æ¦‚ç‡ï¼Œä¸ºå›¾åƒåˆ†é…æœ€å¤§æ¦‚ç‡å¯¹åº”çš„æ ‡ç­¾ã€‚å½©è‰²å›¾åƒç”¨3ç»´çŸ©é˜µè¡¨ç¤ºï¼Œæœ¬ä¾‹ä¸­å®½248åƒç´ ï¼Œé«˜400åƒç´ çš„å›¾åƒï¼Œç”¨248Ã—400Ã—3çš„çŸ©é˜µè¡¨ç¤ºã€‚çŸ©é˜µçš„æ¯ä¸ªå…ƒç´ å¯¹åº”ä¸€ä¸ªåƒç´ å€¼ï¼Œå–å€¼æ˜¯0åˆ°255çš„æ•´æ•°ã€‚å…·ä½“æ¥è¯´ï¼Œå›¾åƒåˆ†ç±»çš„ä»»åŠ¡æ˜¯é€šè¿‡è¿™äº›åƒç´ å€¼ï¼Œåˆ©ç”¨è®¡ç®—æœºè§†è§‰ç®—æ³•ï¼Œå¾—åˆ°ç±»åˆ«æ ‡ç­¾ï¼ˆæœ¬ä¾‹è¾“å…¥å›¾ç‰‡çš„ç±»åˆ«æ ‡ç­¾æ˜¯ğŸ±ï¼‰ã€‚</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-challenges.jpeg"><img src="/assets/images/2015-01-19-image-classification-knn-based-introduction-challenges.jpeg" alt="å›¾åƒåˆ†ç±»é¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜" /></a><div class="caption">Figure 2:  å›¾åƒåˆ†ç±»é¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜ [<a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-challenges.jpeg">JPEG</a>]</div></div></div>

<p>è®¡ç®—æœºè§†è§‰ç®—æ³•è¿›è¡Œå›¾åƒåˆ†ç±»é¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜åŒ…æ‹¬ï¼šè§†è§’å˜åŒ–ï¼ˆviewpoint variationï¼‰ã€å°ºåº¦å˜åŒ–ï¼ˆscale variationï¼‰ã€å½¢å˜ï¼ˆdeformationï¼‰ã€å…‰ç…§å½±å“ï¼ˆillumination conditionsï¼‰ã€èƒŒæ™¯æ··æ‚ï¼ˆbackground clutterï¼‰ã€ç±»å†…å˜åŒ–ï¼ˆintra-class variationï¼‰ç­‰ï¼Œå¦‚ä¸Šå›¾æ‰€ç¤ºã€‚å¥½çš„å›¾åƒåˆ†ç±»æ¨¡å‹åº”å½“èƒ½åº”å¯¹è¿™äº›æŒ‘æˆ˜ã€‚</p>

<p>å›¾åƒåˆ†ç±»ç®—æ³•ä¸ä¼ ç»Ÿçš„è®¡ç®—æœºç®—æ³•ï¼ˆæ¯”å¦‚æ’åºï¼‰å¼€å‘ä¸åŒã€‚é¦–å…ˆéœ€è¦ç»™è®¡ç®—è¾“å…¥ä¾›åŒ…å«æ¯ç±»è‹¥å¹²ç¤ºä¾‹å›¾åƒçš„<a href="http://cs231n.github.io/assets/trainset.jpg">è®­ç»ƒé›†</a>ï¼›ç„¶åå¼€å‘å­¦ä¹ ç®—æ³•ä»æ ·æœ¬é›†ä¸­çš„æ¯ç±»å­¦ä¹ ï¼›æœ€åé€šè¿‡é¢„æµ‹ç»“æœè¯„ä¼°ç®—æ³•æ€§èƒ½ã€‚è¿™ç§ä¾èµ–å·²æ ‡æ³¨æ ·æœ¬é›†çš„æ–¹æ³•ç§°ä¸º<strong>æ•°æ®é©±åŠ¨çš„æ–¹æ³•</strong>ï¼ˆdata-driven approachï¼‰ã€‚</p>

<p>å›¾åƒåˆ†ç±»ç®—æ³•å¼€å‘çš„æµç¨‹å¦‚ä¸‹ï¼š</p>

<ol>
  <li>è¾“å…¥ï¼šè¾“å…¥åŒ…å«$N$å¼ å›¾åƒï¼Œå·²ç»ç”¨Kä¸ªæ ‡ç­¾ä¹‹ä¸€æ ‡æ³¨äº†æ¯å¼ å›¾åƒï¼Œè¿™ç§°ä¸ºè®­ç»ƒé›†ï¼ˆtraining setï¼‰ã€‚</li>
  <li>å­¦ä¹ ï¼šå¼€å‘å­¦ä¹ ç®—æ³•ï¼Œé€šè¿‡è®­ç»ƒé›†å­¦ä¹ æ¯ç±»çš„æ ·å­ï¼Œè¿™ç§°ä¸ºè®­ç»ƒåˆ†ç±»å™¨ï¼ˆtraining classifierï¼‰æˆ–å­¦ä¹ æ¨¡å‹ï¼ˆlearning a modelï¼‰ã€‚</li>
  <li>è¯„ä¼°ï¼šè¾“å…¥åˆ†ç±»ç®—æ³•æ²¡æœ‰å­¦ä¹ è¿‡çš„å›¾ç‰‡ï¼Œé€šè¿‡ç®—æ³•é¢„æµ‹æ ‡ç­¾ï¼Œæ ¹æ®é¢„æµ‹å’ŒçœŸå®ç»“æœçš„å¯¹æ¯”è¯„ä¼°ç®—æ³•çš„æ•ˆæœã€‚</li>
</ol>

<h2 id="section-1">æœ€è¿‘é‚»åˆ†ç±»å™¨</h2>

<p>æœ€è¿‘é‚»åˆ†ç±»å™¨ï¼ˆnearest neighbor classifierï¼‰å®¹æ˜“å®ç°ï¼Œæœ¬æ–‡é€šè¿‡å®ƒä»‹ç»å›¾åƒåˆ†ç±»çš„åŸºæœ¬æ–¹æ³•æµç¨‹ï¼Œä½†æ˜¯åœ¨å®é™…åº”ç”¨ä¸­å¾ˆå°‘ä½¿ç”¨è¯¥æ–¹æ³•ã€‚</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-nn.jpg"><img src="/assets/images/2015-01-19-image-classification-knn-based-introduction-nn.jpg" alt="ï¼»å·¦ï¼½ï¼šCIFAR-10ç¤ºä¾‹å›¾åƒï¼›ï¼»å³ï¼½ï¼šä¸ç¬¬1åˆ—æœ€ç›¸é‚»çš„10å¼ å›¾ç‰‡" /></a><div class="caption">Figure 3:  ï¼»å·¦ï¼½ï¼šCIFAR-10ç¤ºä¾‹å›¾åƒï¼›ï¼»å³ï¼½ï¼šä¸ç¬¬1åˆ—æœ€ç›¸é‚»çš„10å¼ å›¾ç‰‡ [<a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-nn.jpg">JPG</a>]</div></div></div>

<p>å›¾åƒæ•°æ®é›†é‡‡ç”¨<a href="http://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a>ï¼Œå®ƒåŒ…å«å°ºå¯¸32Ã—32çš„60000å¼ å°å›¾ï¼Œæ¯å¼ å›¾ç‰‡å·²ç»è¢«ï½›âœˆï¸ï¼ŒğŸš—ï¼ŒğŸ¦ï¼ŒğŸ±ï¼Œâ€¦â€¦ï½ç­‰10ä¸ªæ ‡ç­¾ä¹‹ä¸€æ ‡æ³¨ï¼Œå¦‚ä¸Šå›¾å·¦æ‰€ç¤ºã€‚60000å¼ å›¾ç‰‡è¢«åˆ†å‰²æˆ50000å¼ å›¾ç‰‡ï¼ˆæ¯ç±»5000å¼ ï¼‰çš„è®­ç»ƒé›†å’Œ10000å¼ å›¾ç‰‡ï¼ˆæ¯ç±»1000å¼ ï¼‰çš„æµ‹è¯•é›†ã€‚</p>

<p>æœ€è¿‘é‚»åˆ†ç±»å™¨è®­ç»ƒåˆ†ç±»å™¨çš„æ–¹æ³•ï¼Œå°±æ˜¯è®°ä½è®­ç»ƒé›†å³å¯ã€‚åœ¨é¢„æµ‹çš„æ—¶å€™ç›´æ¥å’Œè®­ç»ƒé›†ä¸­çš„æ¯å¼ å›¾ç‰‡æ¯”è¾ƒï¼Œå¾—åˆ°è¾“å…¥å›¾åƒä¸è®­ç»ƒé›†ä¸­æœ€ç›¸é‚»é‚£å¼ å›¾ç‰‡çš„æ ‡ç­¾ï¼Œå°†è¯¥æ ‡ç­¾ä½œä¸ºé¢„æµ‹ç»“æœã€‚ä¸Šå›¾å³æ˜¯æœ€è¿‘é‚»åˆ†ç±»å™¨çš„ç»“æœï¼Œå…¶ä¸­ç¬¬8è¡Œï¼Œä¸ç¬¬1åˆ—ğŸæœ€ç›¸é‚»çš„æ˜¯ğŸš—ï¼ŒğŸå°±ä¼šè¢«è¯¯æ ‡è®°ä¸ºğŸš—ã€‚</p>

<p>æœ€è¿‘é‚»ç®—æ³•åº¦é‡ä¸¤å¼ å›¾ç‰‡çš„ç›¸é‚»ç¨‹åº¦ï¼Œé€šå¸¸é‡‡ç”¨åƒç´ å€¼ä¹‹é—´çš„$L_1$è·ç¦»æˆ–$L_2$è·ç¦»ï¼š
\[
d_1(\mathbf I_1,\mathbf I_2)=\sum_p\left\lvert\mathbf I_1^p-\mathbf I_2^p\right\rvertï¼›\qquad d_2(\mathbf I_1,\mathbf I_2)=\sqrt{\sum_p\left(\mathbf I_1^p-\mathbf I_2^p\right)^2}ã€‚
\]
åœ¨CIFAR-10æ•°æ®é›†ä¸Šï¼Œç”¨$L_1$è·ç¦»å¾—åˆ°çš„åˆ†ç±»æ­£ç¡®ç‡å¤§çº¦æ˜¯38.6%ï¼Œ$L_2$è·ç¦»å¾—åˆ°çš„åˆ†ç±»æ­£ç¡®ç‡å¤§çº¦æ˜¯35.4%ï¼Œé«˜äºéšæœºçŒœæƒ³10%çš„ç²¾åº¦ï¼Œç›®å‰æœ€å…ˆè¿›çš„å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼Œconvolutional neural networksï¼‰<a href="http://www.kaggle.com/c/cifar-10/leaderboard">æ­£ç¡®ç‡åœ¨95%ä»¥ä¸Š</a><sup id="fnref:what-is-kaggle-score"><a href="#fn:what-is-kaggle-score" class="footnote">1</a></sup>ã€‚</p>

<p>åœ¨åº¦é‡ä¸¤ä¸ªå‘é‡å·®å¼‚æ—¶ï¼Œ$L_2$çš„æ•ˆæœæ¯”$L_1$ç³Ÿç³•ï¼ˆThat is, the $L_2$ distance prefers many medium disagreements to one big one. ï¼‰ã€‚$L_1$å’Œ$L_2$æ˜¯å¸¸ç”¨çš„ä¸¤ä¸ª<a href="http://planetmath.org/vectorpnorm">pèŒƒæ•°</a>ç‰¹ä¾‹ã€‚</p>

<h2 id="k">kæœ€è¿‘é‚»åˆ†ç±»å™¨</h2>

<p>kæœ€è¿‘é‚»åˆ†ç±»å™¨ï¼ˆk-NNï¼Œk-nearest neighbor classifierï¼‰æ˜¯å¯¹æœ€è¿‘é‚»åˆ†ç±»å™¨çš„ç®€å•æ‰©å±•ï¼šä»è®­ç»ƒé›†ä¸­é€‰å‡ºä¸è¾“å…¥å›¾åƒæœ€ç›¸é‚»çš„kå¼ å›¾åƒçš„ç±»åˆ«æ ‡ç­¾ï¼Œé€šè¿‡è¿™kä¸ªæ ‡ç­¾å¯¹è¾“å…¥å›¾åƒçš„ç±»åˆ«æ ‡ç­¾è¿›è¡ŒæŠ•ç¥¨ã€‚k=1æ—¶ï¼Œkæœ€è¿‘é‚»åˆ†ç±»å™¨å’Œæœ€è¿‘é‚»åˆ†ç±»å™¨ç­‰ä»·ã€‚ç›´è§‚ä¸Šç†è§£ï¼Œkæœ€è¿‘é‚»åˆ†ç±»å™¨å–å¤§çš„kå€¼ï¼Œå¯¹åˆ¤åˆ«è¾¹ç•Œæœ‰å¹³æ»‘ä½œç”¨ï¼Œèƒ½æ›´å¥½çš„æŠ—å‡»å™ªå£°å¹²æ‰°ã€‚</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-knn.jpeg"><img src="/assets/images/2015-01-19-image-classification-knn-based-introduction-knn.jpeg" alt="kæœ€è¿‘é‚»åˆ†ç±»å™¨çš„åˆ†ç±»æ•ˆæœ" /></a><div class="caption">Figure 4:  kæœ€è¿‘é‚»åˆ†ç±»å™¨çš„åˆ†ç±»æ•ˆæœ [<a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-knn.jpeg">JPEG</a>]</div></div></div>

<p>ä¸Šå›¾çš„kæœ€è¿‘é‚»åˆ†ç±»å™¨é‡‡ç”¨çš„æ˜¯$L_2$è·ç¦»ã€‚ä¸Šå›¾ä¸­å¯ä»¥çœ‹åˆ°ï¼Œè“è‰²åŒºåŸŸä¸­çš„å°å—ç»¿è‰²å­¤å²›æ˜¯ç”±äºå™ªå£°ç‚¹å¹²æ‰°å¯¼è‡´çš„ï¼Œè¿™å°†å¯¼è‡´é¢„æµ‹é”™è¯¯ï¼›ä¸Šå›¾å³çš„5-NNä¸å—è¿™äº›å¼‚å¸¸å€¼çš„å¹²æ‰°ï¼Œèƒ½åœ¨æµ‹è¯•é›†ä¸Šå–å¾—è·Ÿå¥½çš„æ³›åŒ–ï¼ˆgeneralizationï¼‰æ•ˆæœã€‚ä¸Šå›¾å³çš„ç°è‰²è¡¨ç¤ºæœ‰äº‰è®®çš„åŒºåŸŸï¼Œåœ¨è¿™äº›åŒºåŸŸè‡³å°‘2ä¸ªç±»åˆ«æ ‡ç­¾éƒ½å¾—åˆ°äº†æœ€é«˜ç¥¨ã€‚</p>

<h2 id="section-2">äº¤å‰éªŒè¯</h2>

<p>åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¦‚ä½•é€‰æ‹©kNNçš„å‚æ•°kå‘¢ï¼Ÿé™¤kä¹‹å¤–ï¼Œè¿˜æœ‰åº¦é‡è·ç¦»çš„$L_1$å’Œ$L_2$ç­‰å…¶å®ƒå‚æ•°éœ€è¦è°ƒèŠ‚ã€‚è¿™äº›å€™é€‰å‚æ•°ç§°ä¸º<strong>è¶…å‚æ•°</strong>ï¼ˆhyperparametersï¼‰ã€‚åœ¨åŸºäºæ•°æ®é©±åŠ¨çš„æœºå™¨å­¦ä¹ ç®—æ³•ä¸­ï¼Œå‚æ•°é€‰æ‹©éå¸¸æ™®éã€‚</p>

<p>åœ¨å®é™…åº”ç”¨ä¸­ï¼Œä¸èƒ½é‡‡ç”¨æµ‹è¯•é›†é€‰æ‹©å‚æ•°ã€‚å¦‚æœé‡‡ç”¨æµ‹è¯•é›†è°ƒæ•´å‚æ•°ï¼Œåˆ†ç±»å™¨å°±å¯èƒ½å¯¹æµ‹è¯•é›†è¿‡æ‹Ÿåˆï¼ˆoverfitï¼‰ï¼Œå½“æœ€ç»ˆå‘å¸ƒåˆ°åº”ç”¨ç¯å¢ƒï¼Œåˆ†ç±»å™¨çš„æ€§èƒ½å¯èƒ½å¤§æ‰“æŠ˜æ‰£ã€‚ç”¨æµ‹è¯•é›†è°ƒæ•´å‚æ•°ï¼Œç›¸å½“äºæŠŠæµ‹è¯•é›†å½“è®­ç»ƒé›†ä½¿ç”¨ã€‚æµ‹è¯•é›†åªåº”è¯¥åœ¨æœ€ç»ˆæµ‹è¯•åˆ†ç±»å™¨æ³›åŒ–æ€§èƒ½æ—¶ï¼Œè¢«ä½¿ç”¨1æ¬¡ã€‚</p>

<p>åˆé€‚çš„åšæ³•æ˜¯ä»è®­ç»ƒé›†åˆ†å‰²å‡ºä¸€ä¸ªè¾ƒå°çš„å­é›†ï¼Œä½œä¸ºéªŒè¯é›†ï¼ˆvalidation setï¼‰ã€‚å¯¹CIFAR-10æ•°æ®ï¼Œå¯ä»¥ç”¨49,000ä¸ªå›¾åƒä½œä¸ºè®­ç»ƒé›†ï¼Œåˆ©ç”¨å‰©ä¸‹äº†1,000ä¸ªå›¾åƒä½œä¸ºéªŒè¯é›†è¿›è¡Œå‚æ•°è°ƒèŠ‚ã€‚åœ¨é€‰æ‹©å‚æ•°kçš„æ—¶å€™ï¼Œåœ¨éªŒè¯é›†ä¸Šæµ‹è¯•æ¯ä¸ªkæ¨¡å‹çš„æ€§èƒ½ï¼Œä»ä¸­é€‰æ‹©ä½¿æ€§èƒ½è¾¾åˆ°æœ€å¥½çš„kã€‚é€‰å®škä¹‹åï¼Œåœ¨æµ‹è¯•é›†ä¸Šä»…è¿›è¡Œä¸€æ¬¡æ€§èƒ½è¯„ä¼°ã€‚</p>

<p>å½“è®­ç»ƒé›†åˆæµ‹è¯•é›†è¾ƒå°çš„æ—¶å€™ï¼Œå¯ä»¥é‡‡ç”¨æ›´èªæ˜çš„<strong>äº¤å‰éªŒè¯</strong>ï¼ˆcross-validationï¼‰è¿›è¡Œå‚æ•°é€‰æ‹©ã€‚é€šè¿‡è¯„ä¼°ä¸åŒéªŒè¯é›†ä¸Šçš„å¹³å‡æ€§èƒ½ï¼Œé€‰æ‹©åˆé€‚çš„å‚æ•°ã€‚ä»¥5-foldçš„äº¤å‰éªŒè¯ä¸ºä¾‹ï¼š</p>

<ol>
  <li>å°†è®­ç»ƒé›†åˆ†å‰²ä¸º5ç­‰ä»½ï¼›</li>
  <li>é€‰æ‹©1ä»½ä½œä¸ºéªŒè¯é›†ï¼Œå‰©ä½™çš„4ä»½ç»„æˆè®­ç»ƒé›†ï¼Œåœ¨éªŒè¯é›†ä¸Šè¯„ä¼°å‚æ•°çš„æ€§èƒ½ï¼›</li>
  <li>è½®æµå°†5ä»½ä½œä¸ºè®­ç»ƒé›†ï¼Œå°†5æ¬¡æ€§èƒ½çš„å¹³å‡ä½œä¸ºæœ€ç»ˆè¯„ä¼°ç»“æœã€‚</li>
</ol>

<div class="image_line" id="figure-5"><div class="image_card"><a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-cvplot.png"><img src="/assets/images/2015-01-19-image-classification-knn-based-introduction-cvplot.png" alt="5-foldäº¤å‰éªŒè¯é€‰æ‹©å‚æ•°kçš„æ­£ç¡®ç‡æ›²çº¿" /></a><div class="caption">Figure 5:  5-foldäº¤å‰éªŒè¯é€‰æ‹©å‚æ•°kçš„æ­£ç¡®ç‡æ›²çº¿ [<a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-cvplot.png">PNG</a>]</div></div></div>

<p>ä¸Šå›¾å±•ç¤ºäº†5-foldäº¤å‰éªŒè¯çš„æ•ˆæœï¼Œk=7æ˜¯ä¸ªä¸é”™çš„å‚æ•°ã€‚è‹¥åˆ†å‰²çš„ç­‰ä»½å¤§äº5ï¼Œä¸Šå›¾çš„æ›²çº¿å°†å˜å¾—æ›´åŠ å…‰æ»‘ã€‚</p>

<p>åœ¨å®é™…åº”ç”¨ä¸­ï¼Œç”±äºäº¤å‰éªŒè¯è®¡ç®—é‡å¾ˆå¤§ï¼Œå› è€Œä¼šé€‰æ‹©é‡‡ç”¨å•ä¸€éªŒè¯é›†è€Œé¿å…é‡‡ç”¨äº¤å‰éªŒè¯ã€‚é€šå¸¸ç”¨50%åˆ°90%çš„æ•°æ®ä½œä¸ºè®­ç»ƒé›†ï¼Œå‰©ä¸‹çš„ä½œä¸ºéªŒè¯é›†ï¼Œå€™é€‰è¶…å‚æ•°é›†è¶Šå¤§ï¼ŒéªŒè¯é›†è¶Šå¤§ã€‚å½“éªŒè¯é›†å¾ˆå°æ—¶ï¼ˆæ¯”å¦‚ä»…ä»…å‡ ç™¾ä¸ªæ•°æ®ï¼‰ï¼Œé‡‡ç”¨äº¤å‰éªŒè¯æ˜¯æ¯”è¾ƒä¿é™©çš„æ–¹æ³•ï¼Œå®ƒèƒ½å‡å°‘å‚æ•°é€‰æ‹©æ—¶çš„å™ªå£°å¹²æ‰°ï¼Œå¸¸ç”¨çš„æœ‰3-foleã€5-foldã€10-foldäº¤å‰éªŒè¯ã€‚</p>

<p>å¦ä¸€ä¸ªéœ€è¦è€ƒè™‘çš„é—®é¢˜æ˜¯ï¼Œåœ¨é€šè¿‡éªŒè¯é›†ç¡®å®šäº†æœ€ä½³å‚æ•°åï¼Œæ˜¯å¦éœ€è¦åˆ©ç”¨æ•´ä¸ªè®­ç»ƒé›†å’Œæœ€ä½³å‚æ•°é‡æ–°å­¦ä¹ ã€‚ç”±äºæ”¾å›äº†éªŒè¯é›†ï¼Œæ•´ä¸ªè®­ç»ƒé›†ä¸Šçš„è¡¨ç°å¿…ç„¶æœ‰æ‰€ä¸åŒã€‚å®é™…ä¸Šï¼Œæœ€ç»ˆå‘å¸ƒçš„åˆ†ç±»å™¨ä¸éœ€è¦éªŒè¯é›†çš„å‚ä¸ã€‚</p>

<h2 id="section-3">è¯„ä»·ä¸å»ºè®®</h2>

<p>kæœ€è¿‘é‚»ç®—æ³•çš„ä¸»è¦ä¼˜ç‚¹æ˜¯å®¹æ˜“ç†è§£å’Œå®ç°ï¼Œå¹¶ä¸”è®­ç»ƒä¸æ—¶è€—ï¼›ä¸»è¦ç¼ºç‚¹æ˜¯æµ‹è¯•ï¼ˆé¢„æµ‹ï¼‰æ—¶è€—é«˜ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œä¸»è¦å…³æ³¨çš„æ˜¯æµ‹è¯•ï¼ˆé¢„æµ‹ï¼‰æ—¶è€—ã€‚æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNï¼Œdeep neural networksï¼‰ç›¸åï¼Œè®­ç»ƒè€—æ—¶ä½†é¢„æµ‹é«˜æ•ˆï¼Œåœ¨å®é™…ä¸­æ›´é€‚ç”¨ã€‚</p>

<p>æœ€è¿‘é‚»ç®—æ³•ä¹Ÿæ˜¯ä¸€ä¸ªæ´»è·ƒçš„ç ”ç©¶é¢†åŸŸã€‚è¿‘ä¼¼æœ€è¿‘é‚»ç®—æ³•ï¼ˆANNï¼Œapproximate nearest neighborï¼‰é€šè¿‡å¯¹ç²¾åº¦å’Œé€Ÿåº¦ï¼ˆç©ºé—´ï¼‰è€—è´¹çš„æŠ˜ä¸­æé«˜æ•ˆç‡ï¼Œæ¯”å¦‚<a href="http://www.cs.ubc.ca/research/flann/">FLANN</a>ã€‚è¿™äº›ç®—æ³•é€šå¸¸éœ€è¦é€šè¿‡kdæ ‘æˆ–kå‡å€¼ç®—æ³•é¢„å¤„ç†æˆ–å»ºç«‹ç´¢å¼•ã€‚</p>

<p>kæœ€è¿‘é‚»ç®—æ³•æœ‰æ—¶æ˜¯ä¸é”™çš„é€‰æ‹©ï¼Œå°¤å…¶æ˜¯æ•°æ®ç»´æ•°è¾ƒä½çš„æ—¶å€™ï¼Œä½†åœ¨å›¾åƒåˆ†ç±»ä¸­å‡ ä¹å¾ˆå°‘ä½¿ç”¨ã€‚å›¾åƒæ˜¯é«˜ç»´æ•°æ®ï¼Œé«˜ç»´ç©ºé—´çš„è·ç¦»åº¦é‡è¡¨ç°æœ‰äº›åç›´è§‰ï¼ˆcounter-intuitiveï¼‰ã€‚</p>

<div class="image_line" id="figure-6"><div class="image_card"><a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-samenorm.png"><img src="/assets/images/2015-01-19-image-classification-knn-based-introduction-samenorm.png" alt="" /></a><div class="caption">Figure 6:   [<a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-samenorm.png">PNG</a>]</div></div></div>

<p>åˆ©ç”¨$L_2$è·ç¦»åº¦é‡ä¸Šå›¾ä¸­å°å›¾çš„ç›¸ä¼¼æ€§ï¼Œç»“æœè¿åç›´è§‰ã€‚å…¶å®ƒå›¾éƒ½æ˜¯æœ€å·¦å›¾å˜æ¢å¾—åˆ°çš„ï¼Œäººçœ¼è§‚å¯Ÿè¿™äº›å›¾æ¯”è¾ƒç›¸ä¼¼ï¼Œä½†æ˜¯åŸºäº$L_2$çš„åº¦é‡è¡¨æ˜å…¶å®ƒå›¾å’ŒåŸå›¾å·®å¼‚å¾ˆå¤§ã€‚å®é™…å±±ï¼Œåƒç´ çº§åˆ«çš„è·ç¦»åº¦é‡æ— æ³•åˆ¤æ–­åŸºäºç›´è§‰å’Œè¯­ä¹‰çš„ç›¸ä¼¼æ€§ã€‚</p>

<div class="image_line" id="figure-7"><div class="image_card"><a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-pixels_embed_cifar10.jpg"><img src="/assets/images/2015-01-19-image-classification-knn-based-introduction-pixels_embed_cifar10.jpg" alt="åˆ©ç”¨t-SNEå±•ç¤ºCIFAR-10å›¾åƒ" /></a><div class="caption">Figure 7:  åˆ©ç”¨t-SNEå±•ç¤ºCIFAR-10å›¾åƒ [<a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-pixels_embed_cifar10.jpg">JPG</a>]</div></div></div>

<p>ä¸Šå›¾ç”¨<a href="http://lvdmaaten.github.io/tsne/">t-SNE</a>å±•ç¤ºCIFAR-10çš„å›¾åƒï¼Œåœ¨åƒç´ çº§çš„$L_2$è·ç¦»åº¦é‡ä¸‹ï¼Œç›¸ä¼¼çš„å›¾åƒç›¸é‚»æ’åˆ—ã€‚ç»“æœè¡¨æ˜å¹¶æ‰€éæ‰€æœŸæœ›çš„é‚£æ ·ï¼ŒåŒç±»åˆ«çš„ç›¸é‚»æ’åˆ—ã€‚å®é™…ä¸Šï¼Œè¿™ç§åº¦é‡ä¸¥é‡å—èƒŒæ™¯å’Œé¢œè‰²åˆ†å¸ƒçš„å½±å“ï¼Œå¹¶éçœŸæ­£åº¦é‡å›¾åƒå†…å®¹çš„ç›¸ä¼¼æ€§ã€‚</p>

<p>kæœ€è¿‘é‚»ç®—æ³•åœ¨å®é™…ä½¿ç”¨ä¸­çš„å»ºè®®ï¼š</p>

<ol>
  <li>æ•°æ®é¢„å¤„ç†ï¼šç‰¹å¾å‘é‡å‡å€¼å½’0åŒ–ã€æ–¹å·®å•ä½åŒ–<sup id="fnref:why-not-here"><a href="#fn:why-not-here" class="footnote">2</a></sup>ï¼›</li>
  <li>å¯¹é«˜ç»´æ•°æ®ç”¨<a href="http://cs229.stanford.edu/notes/cs229-notes10.pdf">PCA</a>æˆ–<a href="http://scikit-learn.org/stable/modules/random_projection.html">éšæœºæŠ•å½±</a>ï¼ˆrandom projectionsï¼‰ç­‰ç®—æ³•é™ç»´å¤„ç†ï¼›</li>
  <li>æ ¹æ®å‰æ–‡å»ºè®®é‡‡ç”¨éªŒè¯ï¼ˆ50%åˆ°90%æ•°æ®ä½œä¸ºè®­ç»ƒé›†ï¼‰æˆ–äº¤å‰éªŒè¯ï¼Œé€šå¸¸foldæ•°è¶Šå¤šï¼Œæ•ˆæœè¶Šå¥½ï¼Œä½†ä¹Ÿè¶Šè€—æ—¶ï¼›</li>
  <li>é€šè¿‡éªŒè¯é›†é€‰æ‹©kï¼ˆå€™é€‰kè¶Šå¤šè¶Šå¥½ï¼‰å’Œè·ç¦»åº¦é‡æ–¹å¼ï¼›</li>
  <li>å¦‚æœç®—æ³•å¤ªè€—æ—¶ï¼Œå°è¯•é‡‡ç”¨ANNåŠ é€Ÿã€‚</li>
</ol>

<h2 id="section-4">ç¤ºä¾‹ä»£ç </h2>

<p>ä¸‹æ–‡ä¸­ä»£ç æ‰€éœ€è¦çš„å‡½æ•°å’Œæ•°æ®<a href="http://vision.stanford.edu/teaching/cs231n/assignment1.zip">åœ¨è¿™é‡Œè·å–</a>ã€‚</p>

<div class="highlight"><pre><code class="language-python"><span class="n">__author__</span> <span class="o">=</span> <span class="s">&#39;jiyeqian&#39;</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">cs231n.data_utils</span> <span class="kn">import</span> <span class="n">load_CIFAR10</span>

<span class="c"># a magic function we provide</span>
<span class="n">Xtr</span><span class="p">,</span> <span class="n">Ytr</span><span class="p">,</span> <span class="n">Xte</span><span class="p">,</span> <span class="n">Yte</span> <span class="o">=</span> <span class="n">load_CIFAR10</span><span class="p">(</span><span class="s">&#39;cs231n/datasets/cifar-10-batches-py&#39;</span><span class="p">)</span>
<span class="c"># Subsample the data for more efficient code execution</span>
<span class="n">num_training</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">mask</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_training</span><span class="p">)</span>
<span class="n">Xtr</span><span class="p">,</span> <span class="n">Ytr</span> <span class="o">=</span> <span class="n">Xtr</span><span class="p">[</span><span class="n">mask</span><span class="p">],</span> <span class="n">Ytr</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
<span class="n">num_test</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">mask</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_test</span><span class="p">)</span>
<span class="n">Xte</span><span class="p">,</span> <span class="n">Yte</span> <span class="o">=</span> <span class="n">Xte</span><span class="p">[</span><span class="n">mask</span><span class="p">],</span> <span class="n">Yte</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>

<span class="c"># flatten out all images to be one-dimensional</span>
<span class="n">Xtr_rows</span> <span class="o">=</span> <span class="n">Xtr</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Xtr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">32</span> <span class="o">*</span> <span class="mi">32</span> <span class="o">*</span> <span class="mi">3</span><span class="p">)</span> <span class="c"># Xtr_rows becomes 5000 x 3072</span>
<span class="n">Xte_rows</span> <span class="o">=</span> <span class="n">Xte</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Xte</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">32</span> <span class="o">*</span> <span class="mi">32</span> <span class="o">*</span> <span class="mi">3</span><span class="p">)</span> <span class="c"># Xte_rows becomes 500 x 3072</span>

<span class="k">class</span> <span class="nc">NearestNeighbor</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; X is N x D where each row is an example. Y is 1-dimension of size N &quot;&quot;&quot;</span>
        <span class="c"># the nearest neighbor classifier simply remembers all the training data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Xtr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ytr</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; X is N x D where each row is an example we wish to predict label for &quot;&quot;&quot;</span>
        <span class="n">num_test</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c"># lets make sure that the output type matches the input type</span>
        <span class="n">Ypred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_test</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ytr</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="c"># loop over all test rows</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">num_test</span><span class="p">):</span>
            <span class="c"># find the nearest training image to the i&#39;th test image</span>
            <span class="c"># using the L1 distance (sum of absolute value differences)</span>
            <span class="n">distances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Xtr</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,:]),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
            <span class="c"># L2 distance</span>
            <span class="c"># distances = np.linalg.norm(self.Xtr - X[i,:], axis = 1)</span>
            <span class="c"># min_index = np.argmin(distances) # get the index with smallest distance</span>
            <span class="c"># Ypred[i] = self.ytr[min_index] # predict the label of the nearest example</span>
            <span class="n">fre_idx</span><span class="p">,</span> <span class="n">fre_num</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ytr</span><span class="p">[</span><span class="n">distances</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[</span><span class="mi">0</span><span class="p">:</span><span class="n">k</span><span class="p">]],</span> \
                                         <span class="n">return_counts</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="n">Ypred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">fre_idx</span><span class="p">[</span><span class="n">fre_num</span> <span class="o">==</span> <span class="n">fre_num</span><span class="o">.</span><span class="n">max</span><span class="p">()]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">Ypred</span>


<span class="c"># Part 1: kNN prediction</span>

<span class="n">nn</span> <span class="o">=</span> <span class="n">NearestNeighbor</span><span class="p">()</span> <span class="c"># create a Nearest Neighbor classifier class</span>
<span class="n">nn</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">Xtr_rows</span><span class="p">,</span> <span class="n">Ytr</span><span class="p">)</span> <span class="c"># train the classifier on the training images and labels</span>
<span class="n">Yte_predict</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xte_rows</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c"># predict labels on the test images</span>
<span class="c"># and now print the classification accuracy, which is the average number</span>
<span class="c"># of examples that are correctly predicted (i.e. label matches)</span>
<span class="k">print</span> <span class="s">&#39;accuracy: </span><span class="si">%f</span><span class="s">&#39;</span> <span class="o">%</span> <span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Yte_predict</span> <span class="o">==</span> <span class="n">Yte</span><span class="p">)</span> <span class="p">)</span>


<span class="c"># Part 2: validation for choosing k</span>

<span class="c"># assume we have Xtr_rows, Ytr, Xte_rows, Yte as before</span>
<span class="c"># recall Xtr_rows is 5,000 x 3072 matrix</span>
<span class="n">Xval_rows</span><span class="p">,</span> <span class="n">Yval</span> <span class="o">=</span> <span class="n">Xtr_rows</span><span class="p">[:</span><span class="mi">1000</span><span class="p">,</span> <span class="p">:],</span> <span class="n">Ytr</span><span class="p">[:</span><span class="mi">1000</span><span class="p">]</span><span class="c"># take first 1000 for validation</span>
<span class="n">Xtr_rows</span><span class="p">,</span> <span class="n">Ytr</span> <span class="o">=</span> <span class="n">Xtr_rows</span><span class="p">[</span><span class="mi">1000</span><span class="p">:,</span> <span class="p">:],</span> <span class="n">Ytr</span><span class="p">[</span><span class="mi">1000</span><span class="p">:]</span> <span class="c"># keep last 4,000 for train</span>

<span class="c"># find hyperparameters that work best on the validation set</span>
<span class="n">validation_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span>

    <span class="c"># use a particular value of k and evaluation on validation data</span>
    <span class="n">nn</span> <span class="o">=</span> <span class="n">NearestNeighbor</span><span class="p">()</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">Xtr_rows</span><span class="p">,</span> <span class="n">Ytr</span><span class="p">)</span>
    <span class="c"># here we assume a modified NearestNeighbor class that can take a k as input</span>
    <span class="n">Yval_predict</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xval_rows</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">k</span><span class="p">)</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Yval_predict</span> <span class="o">==</span> <span class="n">Yval</span><span class="p">)</span>
    <span class="k">print</span> <span class="s">&#39;accuracy: </span><span class="si">%f</span><span class="s">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">acc</span><span class="p">,)</span>

    <span class="c"># keep track of what works on the validation set</span>
    <span class="n">validation_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="n">acc</span><span class="p">))</span></code></pre></div>

<p>kæœ€è¿‘é‚»ç®—æ³•é¢„æµ‹é˜¶æ®µè®¡ç®—å¤æ‚åº¦éå¸¸é«˜ï¼Œä¸ºäº†åŠ å¿«è®¡ç®—é€Ÿåº¦ï¼Œä¸Šè¿°ä»£ç åªæŠ½å–äº†10%çš„æ•°æ®ï¼Œå¾—åˆ°çš„ç»“æœå¦‚ä¸‹ï¼š</p>

<div class="highlight"><pre><code># Part 1:
accuracy: 0.290000
# Part 2:
accuracy: 0.291000
accuracy: 0.269000
accuracy: 0.275000
accuracy: 0.289000
accuracy: 0.287000
accuracy: 0.285000
accuracy: 0.283000
</code></pre></div>

<h2 id="section-5">å‚è€ƒæ–‡çŒ®</h2>

<ol class="bibliography"><li><span id="lifeifei_CNN_kNN_2015">[1]F.-F. Li and A. Karpathy, â€œImage classification: data-driven approach, nearest neighbor, train/val/test splits.â€ GitHub, 2015.</span>

[<a href="http://cs231n.github.io/classification/">Online</a>]

</li></ol>

<h3 id="section-6">è„šæ³¨</h3>

<div class="footnotes">
  <ol>
    <li id="fn:what-is-kaggle-score">
      <p>kaggleæ’åçš„å¾—åˆ†ï¼ˆscoreï¼‰æ˜¯å¦‚ä½•è®¡ç®—çš„ï¼Ÿ <a href="#fnref:what-is-kaggle-score" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:why-not-here">
      <p>We will cover this in more detail in later sections, and chose not to cover data normalization in this section because pixels in images are usually homogeneous and do not exhibit widely different distributions, alleviating the need for data normalization. <a href="#fnref:why-not-here" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>logisticå›å½’</title>
      <link href="http://qianjiye.de/2015/01/logistic-regression" />
      <pubdate>2015-01-17T16:28:27+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/logistic-regression</guid>
      <content:encoded>&lt;![CDATA[<p>æœ¬èŠ‚çš„ä¸»è¦å‚è€ƒèµ„æ–™æ˜¯æœºå™¨å­¦ä¹ åŸºçŸ³<a href="#lin_ml_logistic_regression_2014">[1]</a>å’Œæœºå™¨å­¦ä¹ <a href="#ng_ml_lr_2014">[2]</a>ç½‘ç»œè¯¾ç¨‹ã€‚</p>

<h2 id="soft">softäºŒåˆ†ç±»</h2>

<p>softäºŒåˆ†ç±»æ„Ÿå…´è¶£çš„ä¸ä»…ä»…æ˜¯$\{-1,+1\}$ç±»åˆ«çš„åˆ¤æ–­ï¼Œè€Œæ˜¯å±äºæŸä¸ªç±»åˆ«çš„å¯èƒ½æ€§ï¼Œæ¯”å¦‚
\begin{equation}
f(\mathbf x)=P(+1|\mathbf x)\in [0,1]ã€‚
\label{eq:f-vs-probility}
\end{equation}
ä½†æ˜¯åœ¨å®é™…åº”ç”¨ä¸­ï¼Œéš¾ä»¥è·å–å±äºæŸä¸ªç±»åˆ«çš„æ¦‚ç‡ï¼Œåªèƒ½å¾—åˆ°æ˜¯å¦å±äºæŸä¸ªç±»åˆ«ï¼Œä¹Ÿå°±æ˜¯ä¸äºŒåˆ†ç±»ä¸€æ ·çš„æ•°æ®é›†ã€‚</p>

<p>ä¸å¦¨å°†$\{-1,+1\}$ç±»åˆ«æ ‡ç­¾çš„æ•°æ®ï¼Œçœ‹ä½œæ˜¯æ¦‚ç‡æ ‡ç­¾æ•°æ®è¢«å™ªå£°æ±¡æŸ“çš„ç»“æœï¼Œe.g. $(\mathbf x_1,yâ€™_1=0.9=P(+1|\mathbf x_1))+{noise}\rightarrow(\mathbf x_1,y_1=\circ\sim P(+1|\mathbf x_1))$ã€‚</p>

<p>logisticå›å½’è§£å†³çš„é—®é¢˜ï¼Œå°±æ˜¯åœ¨$\{-1,+1\}$ç±»åˆ«æ ‡ç­¾çš„è®­ç»ƒé›†ä¸Šï¼Œé€šè¿‡softäºŒåˆ†ç±»äº§ç”Ÿæ¦‚ç‡æ ‡ç­¾çš„è¾“å‡ºã€‚</p>

<h2 id="logistic">logisticå›å½’æ¨¡å‹</h2>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-17-logistic-regression-logistic-function.png"><img src="/assets/images/2015-01-17-logistic-regression-logistic-function.png" alt="logisticå‡½æ•°" /></a><div class="caption">Figure 1:  logisticå‡½æ•° [<a href="/assets/images/2015-01-17-logistic-regression-logistic-function.png">PNG</a>]</div></div></div>

<p>å¯¹äºç‰¹å¾$\mathbf x=(x_0, x_1,\ldots,x_d)$ï¼Œå…ˆè®¡ç®—åŠ æƒçš„risk scoreï¼Œ$s=\mathbf w^T\mathbf x$ï¼Œç„¶åå†å°†æ­¤å¾—åˆ†ä»£å…¥å¦‚ä¸Šå›¾æ‰€ç¤ºçš„logisticå‡½æ•°<sup id="fnref:logistic-function-properties"><a href="#fn:logistic-function-properties" class="footnote">1</a></sup>
\begin{equation}
\theta(s)={1\over 1 + e^{-s}}
\label{eq:sigmoid-function}
\end{equation}
è½¬åŒ–ä¸ºæ¦‚ç‡çš„å½¢å¼ã€‚logisticå‡½æ•°ä¹Ÿç§°ä¸ºsigmoidå‡½æ•°ï¼Œå•è°ƒã€å…‰æ»‘ã€‚ä¹Ÿå°±æ˜¯å¯ç”¨logisticå›å½’æ¨¡å‹
\begin{equation}
h(\mathbf x)={1\over 1+\exp(-\mathbf w^T\mathbf x)}ï¼Œ
\end{equation}
ä½œä¸ºç›®æ ‡å‡½æ•°$f(\mathbf x)=P(y|\mathbf x)$çš„è¿‘ä¼¼ã€‚</p>

<p>å»ºç«‹logisticå›å½’æ¨¡å‹çš„åŸºæœ¬æ€è·¯æ˜¯ï¼Œæ‰¾åˆ°æœ€å¯èƒ½äº§ç”Ÿæ•°æ®é›†$\mathcal D$çš„å‡è®¾$h$ã€‚è€ƒè™‘æ•°æ®é›†$\mathcal D=\{(\mathbf x_1,\circ),(\mathbf x_2,\times),\ldots,(\mathbf x_N,\times)\}$ï¼Œæ ¹æ®\eqref{eq:f-vs-probility}å¯å¾—<sup id="fnref:andrew-class-label"><a href="#fn:andrew-class-label" class="footnote">2</a></sup>
\[
P(y|\mathbf x)=
\left\{
\begin{aligned}
&amp;f(\mathbf x)&amp;\mbox{for }y=+1&amp;\\
&amp;1-f(\mathbf x)&amp;\mbox{for }y=-1&amp;ï¼Œ
\end{aligned}
\right.
\]
é‚£ä¹ˆå¾—åˆ°è¿™ä¸ªæ•°æ®é›†çš„æ¦‚ç‡ä¸º
\[
\begin{aligned}
&amp;P(\mathbf x_1)P(\circ|\mathbf x_1)\times P(\mathbf x_2)P(\times|\mathbf x_2)\times\ldots P(\mathbf x_N)P(\times|\mathbf x_N)\\
=&amp;P(\mathbf x_1)f(\mathbf x_1)\times P(\mathbf x_2)(1-f(\mathbf x_2))\times\ldots P(\mathbf x_N)(1-f(\mathbf x_N))\Rightarrow\mbox{probability using }f\\
\approx &amp;P(\mathbf x_1)h(\mathbf x_1)\times P(\mathbf x_2)(1-h(\mathbf x_2))\times\ldots P(\mathbf x_N)(1-h(\mathbf x_N))\Rightarrow\mbox{likelihood}(h)ï¼Œ
\end{aligned}
\]
$h$äº§ç”Ÿè¿™ç¬”æ•°æ®çš„å¯èƒ½æ€§ï¼ˆlikelihoodï¼‰å’Œ$f$äº§ç”Ÿè¿™ç¬”æ•°æ®çš„æ¦‚ç‡ï¼ˆprobabilityï¼‰å·®ä¸å¤šï¼Œæœ€ç»ˆå¾—åˆ°äº†$h$äº§ç”Ÿè¿™ç¬”æ•°æ®çš„å¯èƒ½æ€§ã€‚æœŸæœ›$f$äº§ç”Ÿè¿™ç¬”æ•°æ®çš„æ¦‚ç‡ç›¸å½“å¤§<sup id="fnref:why-large-probability"><a href="#fn:why-large-probability" class="footnote">3</a></sup>ï¼Œå› æ­¤æœ‰
\[
\mbox{likelihood}(h)\approx\mbox{probability using }f\approx\mbox{large}ï¼Œ
\]
é€‰æ‹©å¯èƒ½æ€§æœ€é«˜çš„é‚£ä¸ª$h$
\[
g=\arg\max_h\mbox{likelihood}(h)ã€‚
\]
æ ¹æ®logisticå‡½æ•°çš„æ€§è´¨$\theta(-s)=1-\theta(s)$ï¼Œå¯è¿›ä¸€æ­¥å¾—åˆ°
\[
\mbox{likelihood}(h)=P(\mathbf x_1)h(+\mathbf x_1)\times P(\mathbf x_2)(-h(\mathbf x_2))\times\ldots P(\mathbf x_N)(-h(\mathbf x_N))ï¼Œ
\]
å¯¹æ‰€æœ‰$h$ï¼Œ$P(\mathbf x_i)$éƒ½ä¸å˜ï¼Œé‚£ä¹ˆå¯å¾—
\[
\mbox{likelihood}(\mbox{logistic }h)\varpropto\prod_{n=1}^Nh(y_n\mathbf x_n)ï¼Œ
\]
æœ€ä½³$\mathbf w$åº”æ»¡è¶³æ¡ä»¶
\[
\max_{\mathbf w}\mbox{likelihood}(\mathbf w)\varpropto\prod_{n=1}^N\theta(y_n\mathbf w^T\mathbf x_n)ã€‚
\]
åˆ©ç”¨$\ln$å°†ä¹˜æ³•åŒ–ä¸ºåŠ æ³•ï¼Œå¾—åˆ°ç­‰ä»·çš„ä¼˜åŒ–é—®é¢˜
\begin{equation}
\min_\mathbf wE_{in}(\mathbf w)={1\over N}\sum_{n=1}^N\ln\left(1+\exp\left(-y_n\mathbf w^T\mathbf x_n\right)\right)ï¼Œ
\end{equation}
å…¶ä¸­$err(\mathbf w,\mathbf x,y)=\ln\left(1+\exp\left(-y\mathbf w^T\mathbf x\right)\right)$ç§°ä¸º<strong>äº¤å‰ç†µè¯¯å·®</strong>ï¼ˆcross-entropy errorï¼‰ã€‚</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-17-logistic-regression-convex-or-non.png"><img src="/assets/images/2015-01-17-logistic-regression-convex-or-non.png" alt="ï¼»å·¦ï¼½ï¼šå¹³æ–¹è¯¯å·®ä»£ä»·å‡½æ•°ï¼›ï¼»å³ï¼½äº¤å‰ç†µè¯¯å·®ä»£ä»·å‡½æ•°" /></a><div class="caption">Figure 2:  ï¼»å·¦ï¼½ï¼šå¹³æ–¹è¯¯å·®ä»£ä»·å‡½æ•°ï¼›ï¼»å³ï¼½äº¤å‰ç†µè¯¯å·®ä»£ä»·å‡½æ•° [<a href="/assets/images/2015-01-17-logistic-regression-convex-or-non.png">PNG</a>]</div></div></div>

<p>ä¸Šå›¾å±•ç¤ºäº†ç”¨ä¸åŒè¯¯å·®åº¦é‡æ–¹å¼çš„ä»£ä»·å‡½æ•°ï¼Œä¸Šå›¾å·¦é‡‡ç”¨äº†çº¿æ€§å›å½’åŸºäºå¹³æ–¹è¯¯å·®çš„ä»£ä»·å‡½æ•°ï¼Œéå‡¸ä¸åˆ©äºä¼˜åŒ–ã€‚</p>

<h2 id="section">æ¢¯åº¦ä¸‹é™æ³•</h2>

<p>$E_{in}(\mathbf w)$æ˜¯è¿ç»­ã€å¯å¾®ã€äºŒæ¬¡å¯å¾®çš„å‡¸å‡½æ•°ï¼Œç†è®ºä¸Šå–å¾—æœ€å°å€¼æ—¶$\mathbf w$æ»¡è¶³$\nabla E_{in}(\mathbf w)=0$ï¼Œå…¶ä¸­
\begin{equation}
\nabla E_{in}(\mathbf w)={1\over N}\sum_{n=1}^N\theta(-y_n\mathbf w^T\mathbf x_n)(-y_n\mathbf x_n)ã€‚
\label{eq:gradient-logistic-object-function}
\end{equation}
ç”±äº$\nabla E_{in}(\mathbf w)=0$æ˜¯éçº¿æ€§æ–¹ç¨‹ï¼Œå¹¶ä¸”$\theta(-y_n\mathbf w^T\mathbf x_n)ï¼0$çš„æ¡ä»¶$y_n\mathbf w^T\mathbf x_n\gg 0$ä¹Ÿéš¾ä»¥æ»¡è¶³ï¼Œå› æ­¤ä¸å­˜åœ¨ç±»ä¼¼çº¿æ€§å›å½’çš„é—­å¼è§£ã€‚</p>

<p>å›é¡¾<a href="/2014/10/machine-learning-perceptron-learning-algorithm/#pla-algorithm">æ„ŸçŸ¥å™¨ç®—æ³•</a>çš„æƒå€¼æ›´æ–°ï¼Œç¨å¾®ä¿®æ”¹å…¶è¡¨ç°å½¢å¼
\[
\mathbf w_{t+1}\leftarrow\mathbf w_{t}+1\cdot\left(\left[\left[\mbox{sign}\left(\mathbf w_t^T\mathbf x_n\right)\neq y_n\right]\right]y_n\mathbf x_n\right)ï¼Œ
\]
ç®€è®°ä¸º
\[
\mathbf w_{t+1}\leftarrow\mathbf w_{t}+\eta\mathbf vï¼Œ
\]
å…¶ä¸­$\eta=1$è¡¨ç¤ºæ­¥é•¿ï¼Œ$\mathbf v=\left[\left[\mbox{sign}\left(\mathbf w_t^T\mathbf x_n\right)\neq y_n\right]\right]y_n\mathbf x_n$è¡¨ç¤ºæ–¹å‘ã€‚å¯¹$(\eta,\mathbf v)$å’Œç»ˆæ­¢æ¡ä»¶çš„ä¸åŒå®šä¹‰ï¼Œå°±ä¼šå¾—åˆ°ä¸åŒçš„è¿­ä»£ä¼˜åŒ–ç®—æ³•ã€‚è€ƒå¯Ÿæ¢¯åº¦è®¡ç®—å…¬å¼\eqref{eq:gradient-logistic-object-function}ï¼Œ$\theta(-y_n\mathbf w^T\mathbf x_n)$ç›¸å½“äºæ¢¯åº¦æ–¹å‘çš„åŠ æƒå€¼ï¼Œå½“$y_n\mathbf w^T\mathbf x_n$è¶Šå°çš„æ—¶å€™ï¼Œæƒå€¼è¶Šå¤§ï¼Œè´Ÿå€¼è¶Šå¤§è¡¨ç¤ºçŠ¯é”™è¶Šå‰å®³ã€‚å¦‚æœæŒ‰ç…§æ¢¯åº¦æ–¹å‘æ›´æ–°ï¼Œè¿™å’ŒPLAæœ‰ç›¸åŒçš„å«ä¹‰ï¼ŒçŠ¯é”™è¶Šå‰å®³çš„å¯¹æ›´æ–°è´¡çŒ®è¶Šå¤§ã€‚</p>

<p>å¯¹äºlogisticå›å½’çš„$E_{in}$ï¼Œä»¤$\eta&gt;0$ï¼Œ
\[
\min_{\lVert\mathbf v\rVert=1}E_{in}(\mathbf w_t+\eta\mathbf v)
\]
åˆ©ç”¨è´ªå©ªæ³•æ‰¾$\mathbf w_t$é™„è¿‘æœ€å¥½çš„ä¸€ä¸ªæ–¹å‘ï¼Œè®©$E_{in}$ä¸‹é™æœ€å¤šã€‚ä¸Šå¼ä»ç„¶æ˜¯éçº¿æ€§ï¼Œä¸”å¸¦çº¦æŸæ¡ä»¶ï¼Œéš¾ä»¥æ±‚è§£ã€‚å½“$\eta$è¶³å¤Ÿå°æ—¶ï¼Œåˆ©ç”¨Taylorå±•å¼å¯å¾—
\[
E_{in}(\mathbf w_t+\eta\mathbf v)\approx E_{in}(\mathbf w_t)+\eta\mathbf v^T\nabla E_{in}(\mathbf w_t)
\]
è‹¥è¦å®ç°
\[
\min_{\lVert\mathbf v\rVert=1}\left(E_{in}(\mathbf w_t)+\eta\mathbf v^T\nabla E_{in}(\mathbf w_t)\right)ï¼Œ
\]
å°±è¦ä½¿å¾—$\eta\mathbf v^T\nabla E_{in}(\mathbf w_t)$æœ€å°ï¼Œæ­¤æ—¶$\eta&gt;0$æ˜¯å¸¸æ•°ï¼Œå› æ­¤$\mathbf v$å’Œ$\nabla E_{in}(\mathbf w_t)$åå‘æ—¶å¾—åˆ°çš„å€¼æœ€å°ï¼Œ
\[
\mathbf v=-\frac{\nabla E_{in}(\mathbf w_t)}{\lVert\nabla E_{in}(\mathbf w_t)\rVert}ï¼Œ
\]
é‚£ä¹ˆå‚æ•°çš„æ›´æ–°è§„åˆ™ä¸º
\begin{equation}
\mathbf w_{t+1}\leftarrow\mathbf w_{t}-\eta\frac{\nabla E_{in}(\mathbf w_t)}{\lVert\nabla E_{in}(\mathbf w_t)\rVert}ã€‚
\label{eq:gd-iterate}
\end{equation}
è¿™ç§å‚æ•°æ›´æ–°æ–¹æ³•å°±æ˜¯æ¢¯åº¦ä¸‹é™æ³•ï¼Œæ˜¯ä¸€ç§ç®€å•ä¸”åº”ç”¨å¹¿æ³›çš„ä¼˜åŒ–ç®—æ³•ã€‚</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-17-logistic-regression-eta-example.png"><img src="/assets/images/2015-01-17-logistic-regression-eta-example.png" alt="ä¸åŒæ­¥é•¿çš„è¿­ä»£æ•ˆæœ" /></a><div class="caption">Figure 3:  ä¸åŒæ­¥é•¿çš„è¿­ä»£æ•ˆæœ [<a href="/assets/images/2015-01-17-logistic-regression-eta-example.png">PNG</a>]</div></div></div>

<p id="why-fixed-eta">ä¸Šå›¾å±•ç¤ºäº†åˆ©ç”¨\eqref{eq:gd-iterate}è¿­ä»£çš„æ•ˆæœï¼Œ$\eta$è¿‡å°å¯¼è‡´æ”¶æ•›å¤ªæ…¢ï¼Œè¿‡å¤§å¯¼è‡´ä¸ç¨³å®šï¼ŒåŠ¨æ€è°ƒæ•´å¯ä»¥å¾—åˆ°ä¸é”™çš„æ•ˆæœã€‚å¯¹äºåŠ¨æ€è°ƒæ•´çš„$\eta$ï¼Œå¡åº¦$\lVert\nabla E_{in}(\mathbf w_t)\rVert$å¤§çš„æ—¶å€™é‡‡ç”¨å¤§çš„$\eta$ï¼Œå°çš„æ—¶å€™é‡‡ç”¨å°çš„$\eta$ã€‚å½“$\eta\leftarrow{\eta\over\lVert\nabla E_{in}(\mathbf w_t)\rVert}$æ—¶ï¼Œå›ºå®šä½æ–°çš„$\eta$å°±ä¼šè¾¾åˆ°åŠ¨æ€è°ƒæ•´çš„æ•ˆæœï¼Œå› æ­¤å¯ä»¥é‡‡ç”¨å›ºå®š$\eta$çš„è‡ªé€‚åº”æ­¥é•¿æ›´æ–°æ–¹å¼</p>
<p>\begin{equation}
\mathbf w_{t+1}\leftarrow\mathbf w_{t}-\eta\nabla E_{in}(\mathbf w_t)ã€‚
\label{eq:gd-iterate-2}
\end{equation}</p>

<blockquote>
  <h4 id="logistic-1">æ¢¯åº¦ä¸‹é™æ³•æ±‚è§£logisticå›å½’å‚æ•°</h4>
  <hr />
  <p>åˆå§‹åŒ–$\mathbf w_0$å’Œ$\eta$ï¼›</p>

  <p>å¯¹$t=0,1,\ldots$å¾ªç¯ä»¥ä¸‹æ­¥éª¤ï¼Œç›´åˆ°$\nabla E_{in}(\mathbf w_{t+1})=0$æˆ–è¾¾åˆ°è®¾å®šè¿­ä»£æ¬¡æ•°ï¼š       </p>

  <ol>
    <li>åˆ©ç”¨å…¬å¼\eqref{eq:gradient-logistic-object-function}è®¡ç®—$\nabla E_{in}(\mathbf w_{t})$ï¼›</li>
    <li>åˆ©ç”¨å…¬å¼\eqref{eq:gd-iterate-2}æ›´æ–°å‚æ•°$\mathbf w_{t+1}$ã€‚</li>
  </ol>
</blockquote>

<p>æ¢¯åº¦ä¸‹é™æ³•çš„æ³¨æ„äº‹é¡¹å¯ä»¥å‚è€ƒ<a href="/2015/01/linear-regression/#gd-method">çº¿æ€§å›å½’æ¢¯åº¦æ³•</a>çš„æ³¨æ„äº‹é¡¹ã€‚</p>

<h2 id="section-1">å‚è€ƒæ–‡çŒ®</h2>

<ol class="bibliography"><li><span id="lin_ml_logistic_regression_2014">[1]H.-T. Lin, â€œLecture 10: Logistic Regression.â€ Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ntumlone">Online</a>]

</li>
<li><span id="ng_ml_lr_2014">[2]A. Ng, â€œLogistic Regression.â€ Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ml">Online</a>]

</li></ol>

<h3 id="section-2">è„šæ³¨</h3>

<div class="footnotes">
  <ol>
    <li id="fn:logistic-function-properties">
      <p>logisticå‡½æ•°çš„æ€§è´¨ï¼šï¼ˆ1ï¼‰$\theta(-s)=1-\theta(s)$ï¼›ï¼ˆ2ï¼‰${d\theta(s)\over ds}=\theta(s)(1-\theta(s))$ï¼ˆ${d\theta(s)\over d^Ns}=\theta(s)\prod_{n=0}^N(1-N\theta(s))$<strong>????</strong>ï¼‰ï¼›ï¼ˆ3ï¼‰${\theta(s)\over 1-\theta(s)}=e^s$ã€‚ <a href="#fnref:logistic-function-properties" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:andrew-class-label">
      <p>Andrew NGè¯¾ç¨‹ä¸­é‡‡ç”¨äº†$\{0,1\}$ç±»åˆ«æ ‡ç­¾<a href="#ng_ml_lr_2014">[2]</a>ï¼Œå› æ­¤å¾—åˆ°çš„å…¬å¼ä¸æœ¬æ–‡å½¢å¼ä¸åŒã€‚ <a href="#fnref:andrew-class-label" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:why-large-probability">
      <p><del>ä¸ºä»€ä¹ˆ$f$äº§ç”Ÿè¿™ç¬”æ•°æ®çš„æ¦‚ç‡å¾ˆå¤§ï¼Ÿ</del>æœŸæœ›æ‰¾åˆ°æœ€åˆé€‚çš„$h$ï¼Œä½¿äº§ç”Ÿæ•°æ®é›†$\mathcal D$çš„å¯èƒ½æ€§æœ€å¤§ã€‚ <a href="#fnref:why-large-probability" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>åˆ†ç±»å™¨èåˆï¼ˆ2ï¼‰ï¼šAdaBoost</title>
      <link href="http://qianjiye.de/2015/01/adaptive-boosting" />
      <pubdate>2015-01-17T13:02:33+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/adaptive-boosting</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">åŸºäºæ ·æœ¬åŠ æƒçš„è¯¯å·®åº¦é‡</h2>

<p>bootstrappingé‡é‡‡æ ·æ•°æ®é›†$\mathcal D=\{(\mathbf x_1,y_1),(\mathbf x_2,y_2),(\mathbf x_3,y_3),(\mathbf x_4,y_4)\}$ï¼Œå¯èƒ½å¾—åˆ°$\tilde{\mathcal D}_t=\{(\mathbf x_1,y_1),(\mathbf x_1,y_1),(\mathbf x_2,y_2),(\mathbf x_4,y_4)\}$ï¼Œé‚£ä¹ˆ$\tilde{\mathcal D}_t$ä¸Šçš„in-sampleè¯¯å·®æ˜¯$E_{in}^{0/1}(h)={1\over 4}\sum_{(\mathbf x,y)\in\tilde{\mathcal D}_t}[[y\neq h(\mathbf x)]]$ï¼Œä»¤$\mathbf u^{(t)}=[2,1,0,1]^T$ï¼Œè¯¥è¯¯å·®ä¹Ÿå¯ä»¥ç›´æ¥ç”¨$\mathcal D$ä¸Šçš„åŠ æƒè¯¯å·®$E_{in}$è¡¨ç¤ºï¼Œ$E_{in}^{\mathbf u^{(t)}}(h)={1\over 4}\sum_{n=1}^4u_n^{(t)}\cdot[[y_n\neq h(\mathbf x_n)]]$ã€‚è¿™å°±æ˜¯baggingé€šè¿‡æœ€å°åŒ–bootstrap-weightedè¯¯å·®å¾—åˆ°ä¸åŒ$g_t$çš„æ–¹æ³•ã€‚</p>

<p>é€šå¸¸éœ€è¦æœ€å°åŒ–çš„åŠ æƒè¯¯å·®ä¸º
\[
E_{in}^{\mathbf u}(h)={1\over N}\sum_{n=1}^Nu_n\cdot err(y_n, h(\mathbf x_n))ï¼Œ
\]
æŠŠ$\mathbf u$æ”¾å›ç®—æ³•å¹¶ä¸å›°éš¾ã€‚å¯¹äºSVMï¼Œåˆ©ç”¨å¯¹å¶QPæœ€å°åŒ–è¯¯å·®$E_{in}^{\mathbf u}\varpropto C\sum_{n=1}^Nu_n\widehat{err}_{SVM}$ï¼Œå¯ä»¥é€šè¿‡è°ƒæ•´åŸæ–¹æ³•çš„ä¸Šç•Œä¸º$0\leq \alpha_n\leq Cu_n$æ¥å®ç°ï¼›å¯¹äºlogisticå›å½’ï¼Œåˆ©ç”¨SGDæœ€å°åŒ–è¯¯å·®$E_{in}^{\mathbf u}\varpropto C\sum_{n=1}^Nu_n\widehat{err}_{CE}$ï¼Œå¯ä»¥é€šè¿‡æŒ‰ä¸åŒå€ç‡$u_n$çš„æ¦‚ç‡é‡‡æ ·$(\mathbf x_n,y_n)$æ¥å®ç°ã€‚</p>

<p>è¿™é‡Œæ˜¯åŸºäºä¸åŒæ ·æœ¬ç‚¹åŠ æƒçš„è¯¯å·®åº¦é‡æ–¹å¼ï¼Œä¸<a href="/2014/12/machine-learning-noise-and-error/#class-weighted-error">åŸºäºä¸åŒç±»åˆ«åŠ æƒçš„è¯¯å·®åº¦é‡æ–¹å¼</a>çš„åŠ æƒå¯¹è±¡ä¸åŒã€‚å¦‚ä½•å°†$\mathbf u$æ”¾å›åŸç®—æ³•æ˜¯è¿™ç±»åŠ æƒç®—æ³•è¦å¤„ç†çš„é‡è¦é—®é¢˜ã€‚</p>

<h2 id="section-1">æƒé‡è°ƒæ•´ç­–ç•¥</h2>

<p>å¦‚æœç®—æ³•ä¼šæ ¹æ®$\mathbf u$å†³å®š$g$ï¼Œé‚£ä¹ˆæ€æ ·æ”¹å˜$\mathbf u$ä½¿å¾—$g$è¶Šä¸ä¸€æ ·è¶Šå¥½ï¼Ÿè¶Šä¸ä¸€æ ·çš„$g$ï¼Œé€šè¿‡èšåˆï¼ˆaggregationï¼‰æœºåˆ¶ï¼Œè¶Šæœ‰å¯èƒ½å¾—åˆ°æ›´å¥½çš„ç»“æœã€‚</p>

<p>é€šè¿‡$u_n^{(t)}$å¾—åˆ°$g_t$ï¼Œ$u_n^{(t+1)}$å¾—åˆ°$g_{t+1}$ï¼Œ
\[
\left\{
\begin{aligned}
g_t&amp;\leftarrow\arg\min_{h\in\mathcal H}\left(\sum_{n=1}^Nu_n^{(t)}[[y_n\neq h(\mathbf x_n)]]\right)\\
g_{t+1}&amp;\leftarrow\arg\min_{h\in\mathcal H}\left(\sum_{n=1}^Nu_n^{(t+1)}[[y_n\neq h(\mathbf x_n)]]\right)ã€‚
\end{aligned}
\right.
\]
å¦‚æœå…ˆé€‰å®š$g_t$ï¼ˆå½“ä½œ$h$ï¼‰ï¼Œè°ƒæ•´æƒé‡$u_n^{(t+1)}$ä½¿å¾—$g_t$æ•ˆæœéå¸¸å·®ï¼Œ$g_t$ä»¥åŠä¸$g_t$ç›¸ä¼¼çš„å‡è®¾éƒ½ä¸ä¼šè¢«å½“ä½œ$g_{t+1}$ï¼Œè¿™æ ·å°±èƒ½é€‰æ‹©åˆ°ä¸€ä¸ªä¸$g_t$å¾ˆä¸ä¸€æ ·çš„$g_{t+1}$ã€‚è¿™å°±æ˜¯è·å¾—ä¸ä¸€æ ·$g$çš„åŸºæœ¬æ€æƒ³ã€‚ç†æƒ³çš„æƒ…å†µå°±æ˜¯æ„é€ $\mathbf u_n^{(t+1)}$ï¼Œä½¿å¾—$g_t$çš„è¡¨ç°å°±åƒéšæœºçŒœæƒ³ä¸€æ ·
\[
\frac{\sum_{n=1}^Nu_n^{(t+1)}[[y_n\neq g_t(\mathbf x_n)]]}{\sum_{n=1}^Nu_n^{(t+1)}}={1\over 2}ï¼Œ
\]
ä¹Ÿå°±æ˜¯æœŸæœ›
\[
\frac{\sum_{n=1}^Nu_n^{(t+1)}[[y_n\neq g_t(\mathbf x_n)]]}{\sum_{n=1}^Nu_n^{(t+1)}}=\frac{\clubsuit_{t+1}}{\clubsuit_{t+1}+\spadesuit_{t+1}}={1\over 2}ï¼Œ
\]
å…¶ä¸­
\[
\clubsuit_{t+1}=\sum_{n=1}^Nu_n^{(t+1)}[[y_n\neq g_t(\mathbf x_n)]]\qquad\spadesuit_{t+1}=\sum_{n=1}^Nu_n^{(t+1)}[[y_n= g_t(\mathbf x_n)]]ã€‚
\]</p>

<p>å‡è®¾çŠ¯é”™è¯¯çš„æ ·æœ¬ç‚¹æœ‰$1126$ä¸ªï¼Œæ­£ç¡®çš„æ ·æœ¬ç‚¹æœ‰$6211$ä¸ªï¼Œå¯¹äºé”™åˆ†çš„æ ·æœ¬ç‚¹å°±å¯ä»¥ç”¨$u_n^{(t+1)}\leftarrow u_n^{(t)}\cdot {6211\over 7337}$æ›´æ–°ï¼Œå¯¹äºæ­£ç¡®åˆ†ç±»çš„æ ·æœ¬ç‚¹å°±å¯ä»¥ç”¨$u_n^{(t+1)}\leftarrow u_n^{(t)}\cdot {1126\over 7337}$æ›´æ–°ã€‚æ›´æ–°æƒé‡$\mathbf u^{(t+1)}$æ—¶ï¼Œè®¾é”™è¯¯ç‡ä¸º
\begin{equation}
\epsilon_t=\frac{\sum_{n=1}^Nu_n^{(t)}[[y_n\neq g_t(\mathbf x_n)]]}{\sum_{n=1}^Nu_n^{(t)}}ï¼Œ
\label{eq:epsilon-t}
\end{equation}
é”™è¯¯çš„ç‚¹åŸæ¥çš„æƒé‡ä¹˜ä»¥ç³»æ•°$\varpropto(1-\epsilon_t)$ï¼Œæ­£ç¡®çš„ç‚¹åŸæ¥çš„æƒé‡ä¹˜ä»¥ç³»æ•°$\varpropto\epsilon_t$ã€‚</p>

<p>é€šå¸¸çš„åšæ³•æ˜¯å®šä¹‰ç¼©æ”¾å› å­
\begin{equation}
\blacklozenge_t=\sqrt{1-\epsilon_t\over\epsilon_t}ï¼Œ
\label{eq:blacklozenge-t}
\end{equation}
å…¶ä¸­$\epsilon_t$æŒ‰\eqref{eq:epsilon-t}è®¡ç®—ï¼Œæƒé‡æ›´æ–°æ–¹æ³•ä¸º
\[
\mbox{incorrect}\leftarrow\mbox{incorrect}\cdot\blacklozenge_t\qquad\mbox{correct}\leftarrow\mbox{correct }/\blacklozenge_tã€‚
\]
å½“$\epsilon\leq{1\over 2}$æ—¶ï¼Œ$\blacklozenge_t\geq 1$ï¼Œæ”¾å¤§é”™è¯¯çš„ä½œç”¨ï¼Œç¼©å°æ­£ç¡®çš„å½±å“ï¼Œæ›´å…³æ³¨é”™åˆ†çš„æ ·æœ¬ã€‚</p>

<h2 id="adaboost">AdaBoost</h2>

<p>AdaBoost<sup id="fnref:pi-jiang-method"><a href="#fn:pi-jiang-method" class="footnote">1</a></sup> ï¼ å¼±çš„åŸºç¡€å­¦ä¹ ç®—æ³•$\mathcal A$ï¼ˆå­¦ç”Ÿï¼‰ï¼‹æœ€ä¼˜çš„æƒé‡è°ƒæ•´å› å­$\blacklozenge_t$ï¼ˆè€å¸ˆï¼‰ï¼‹ç¥å¥‡çš„çº¿æ€§èšåˆ$\alpha_t$ï¼ˆç­çº§é›†ä½“æ™ºæ…§ï¼‰ã€‚</p>

<blockquote>
  <h4 id="adaboostadaptive-boosting">AdaBoostï¼ˆ<em>ada</em>ptive <em>boost</em>ingï¼‰ç®—æ³•</h4>
  <hr />

  <p>é¦–å…ˆï¼Œåˆå§‹åŒ–$\mathbf u^{(1)}=\left[{1\over N},{1\over N},\ldots,{1\over N}\right]$ï¼›</p>

  <p>å…¶æ¬¡ï¼Œå¯¹äº$t=1,2,\ldots,T$æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š</p>

  <ol>
    <li>åˆ©ç”¨$\mathcal A(\mathcal D, \mathbf u^{(t)})$å¾—åˆ°$g_t$ï¼Œå…¶ä¸­$\mathcal A$æœ€å°åŒ–$\mathbf u^{(t)}$åŠ æƒçš„0/1è¯¯å·®ï¼›</li>
    <li>å°†$\mathbf u^{(t)}$æ›´æ–°ä¸º$\mathbf u^{(tï¼‹1)}$ï¼š
\[
u_n^{(t+1)}\leftarrow\left\{
\begin{aligned}
u_n^{(t)}\cdot\blacklozenge_t&amp;\quad\mbox{if }[[y_n\neq g_t(\mathbf x_n)]]\\
u_n^{(t)}/\blacklozenge_t&amp;\quad\mbox{if }[[y_n= g_t(\mathbf x_n)]]ï¼Œ
\end{aligned}
\right.
\]
å…¶ä¸­$\blacklozenge_t$æŒ‰\eqref{eq:blacklozenge-t}è®¡ç®—ï¼›</li>
    <li>è®¡ç®—ç³»æ•°$\alpha_t=\ln(\blacklozenge_t)$ï¼›</li>
  </ol>

  <p>æœ€åï¼Œè¿”å›$G(\mathbf x)=\mbox{sign}\left(\sum_{t=1}^T\alpha_tg_t(\mathbf x)\right)$ã€‚</p>
</blockquote>

<p>å¥½çš„$g_t$åº”è¯¥æœ‰å¤§çš„$\alpha_t$ã€‚å¯¹äº$\epsilon_t={1\over 2}$ï¼Œè¿‘ä¼¼äºéšæœºçŒœæƒ³ï¼Œ$\alpha_t=0$ï¼›å¯¹äº$\epsilon_t=0$ï¼Œå®Œå…¨æ­£ç¡®çš„åˆ†ç±»å™¨ï¼Œ$\alpha_t=\infty$ã€‚</p>

<p>AdaBoostçš„VCç•Œæ˜¯
\[
E_{out}(G)\leq E_{in}(G)+O\left(\sqrt{O\left(d_{VC}(\mathcal H)\cdot T\log T\right)\cdot{\log N\over N}}\right)ï¼Œ
\]
å…¶ä¸­$d_{VC}(\mathcal H)$æ˜¯ä¸ºäº†$g_t$æ‰€è¦ä»˜å‡ºçš„ä»£ä»·ã€‚å½“$g_t$çš„æ€§èƒ½ä¼˜äºéšæœºçŒœæƒ³$\left(\epsilon_t\leq\epsilon&lt;{1\over 2}\right)$æ—¶ï¼Œç»è¿‡$T=O(\log N)$è½®è¿­ä»£å°±å¯ä»¥è¾¾åˆ°$E_{in}(G)=0$ã€‚ç”±äºæ€»å…±çš„$d_{VC}=O\left(d_{VC}(\mathcal H)\cdot T\log T\right)$éš$T$å¢é•¿ç¼“æ…¢ï¼Œä¸ç­‰å¼å³è¾¹ç¬¬äºŒé¡¹ä¹Ÿå¯ä»¥åšåˆ°å¾ˆå°ã€‚</p>

<p>AdaBoostæ˜¯ä¸€ç§æå‡ç®—æ³•ï¼ˆboostingï¼‰çš„å®ç°ï¼Œä»boostingçš„è§’åº¦ï¼Œè‹¥$\mathcal A$ç•¥ä¼˜äºéšæœºçŒœæƒ³$\left(\epsilon_t\leq\epsilon&lt;{1\over 2}\right)$ï¼ŒAdaBoostï¼‹$\mathcal A$å¯ä»¥è¾¾åˆ°å¾ˆå¼ºå¤§çš„æ€§èƒ½ï¼ˆ$E_{in}(G)=0$ï¼Œ$E_{out}$å¾ˆå°ï¼‰ã€‚</p>

<h2 id="adaboost-stump">AdaBoost-Stump</h2>

<p>å¯¹äºä¸€ä¸ªdecision stumpåˆ†ç±»å™¨
\[
h_{s,i,\theta}(\mathbf x)=s\cdot\mbox{sign}(\mathbf x_i-\theta)ï¼Œ
\]
$i$è¡¨ç¤ºç‰¹å¾ç»´ï¼Œ$\theta$è¡¨ç¤ºé˜ˆå€¼ï¼Œ$s$æ§åˆ¶æ–¹å‘ï¼Œåœ¨2Dç©ºé—´è¯¥åˆ†ç±»å™¨å°±æ˜¯æ°´å¹³æˆ–ç«–ç›´çº¿ï¼Œè¯¥ç®—æ³•ä¼˜åŒ–çš„æ—¶é—´å¤æ‚åº¦ä¸º$O(d\cdot N\log N)$ã€‚decision stumpèƒ½å¤Ÿé«˜æ•ˆçš„æœ€å°åŒ–$E_{in}^\mathbf u$ï¼Œä½†æ˜¯è‡ªèº«çš„æ€§èƒ½å´å¾ˆå¼±ã€‚
å°†decision stumpä½œä¸ºåŸºç¡€åˆ†ç±»å™¨ï¼Œå¯ä»¥ç»„åˆå‡ºåŠŸèƒ½å¼ºå¤§çš„<strong>AdaBoost-Stump</strong>ã€‚</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-17-adaptive-boosting-adaboost-stump.png"><img src="/assets/images/2015-01-17-adaptive-boosting-adaboost-stump.png" alt="AdaBoost-Stumpç¤ºä¾‹" /></a><div class="caption">Figure 1:  AdaBoost-Stumpç¤ºä¾‹ [<a href="/assets/images/2015-01-17-adaptive-boosting-adaboost-stump.png">PNG</a>]</div></div></div>

<p>ä¸Šå›¾å±•ç¤ºäº†åŸºäºdecision stumpæ„é€ çš„AdaBoost-Stumpï¼Œå½“$t=5$æ—¶å°±èƒ½å®Œç¾çš„åˆ†ç±»ã€‚AdaBoost-Stumpèƒ½å¤Ÿæ¯”æ ¸SVMæ›´é«˜æ•ˆåœ°å¾—åˆ°éçº¿æ€§åˆ†ç±»å™¨ã€‚</p>

<p>ä¸–ç•Œä¸Šç¬¬ä¸€ä¸ªå®æ—¶äººè„¸è¯†åˆ«ç¨‹åºå°±æ˜¯åŸºäºAdaBoost-Stumpã€‚ä»$24\times 24$è§„æ ¼çš„162336å¼ å€™é€‰å›¾ç‰‡ä¸­é€šè¿‡decision stumpæŒ‘é€‰å…³é”®å›¾ç‰‡ï¼Œåœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œçº¿æ€§èšåˆï¼ˆlinear aggregationï¼‰<sup id="fnref:how-to-do-AdaBoost-face"><a href="#fn:how-to-do-AdaBoost-face" class="footnote">2</a></sup>ã€‚ä¸ºäº†æé«˜é€Ÿåº¦ï¼Œäººè„¸è¯†åˆ«é‡‡ç”¨çš„$G$ä¼šå°½æ—©æ’é™¤éäººè„¸ã€‚</p>

<p>åœ¨å®é™…åº”ç”¨ä¸­ï¼Œç‰¹å¾ç»´æ•°å¯èƒ½å¾ˆé«˜ï¼ŒAdaBoost-Stumpèƒ½å¤Ÿæœ‰æ•ˆçš„è¿›è¡Œç‰¹å¾é€‰æ‹©å’Œèšåˆã€‚ä¸Šä¾‹æ˜¯2ç»´çš„ä½çº¬åº¦æƒ…å†µï¼Œè¿›è¡Œäº†5æ¬¡è¿­ä»£ï¼Œæ²¡æœ‰ç‰¹å¾é€‰æ‹©çš„åŠŸèƒ½ã€‚</p>

<h2 id="section-2">å‚è€ƒèµ„æ–™</h2>

<ol class="bibliography"></ol>

<h3 id="section-3">è„šæ³¨</h3>

<div class="footnotes">
  <ol>
    <li id="fn:pi-jiang-method">
      <p>ä¹Ÿå¯ç§°ä¸ºâ€œçš®åŒ æ³•â€ï¼Œæ„ä¸ºâ€œä¸‰ä¸ªè‡­çš®åŒ ï¼Œèƒœè¿‡è¯¸è‘›äº®â€ã€‚ <a href="#fnref:pi-jiang-method" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:how-to-do-AdaBoost-face">
      <p>è¿™é‡Œå¦‚ä½•æ„é€ äººè„¸è¯†åˆ«ç¨‹åºçš„å‘¢ï¼Ÿï¼ˆ1ï¼‰<a href="https://class.coursera.org/ntumltwo-001/forum/thread?thread_id=172">è®ºå›è®¨è®º</a>ï¼›ï¼ˆ2ï¼‰<a href="http://en.wikipedia.org/wiki/Violaâ€“Jones_object_detection_framework">Violaâ€“Jones object detection framework</a>ã€‚ <a href="#fnref:how-to-do-AdaBoost-face" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>åˆ†ç±»å™¨èåˆï¼ˆ1ï¼‰ï¼šæ··åˆä¸è‡ªåŠ©èšåˆ</title>
      <link href="http://qianjiye.de/2015/01/blending-and-bagging" />
      <pubdate>2015-01-15T15:12:32+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/blending-and-bagging</guid>
      <content:encoded>&lt;![CDATA[<p><strong>æ··åˆ</strong>ï¼ˆblendingï¼‰æ˜¯å°†ä¸åŒçš„å‡è®¾ç”¨å‡åŒ€ã€çº¿æ€§æˆ–éçº¿æ€§çš„æ–¹å¼ç»„åˆèµ·æ¥ï¼›å¦‚æœå…ˆä»boostrappedæ•°æ®ä¸Šå­¦ä¹ åˆ°å„ç§ä¸åŒçš„å‡è®¾ï¼Œç„¶åå†æ··åˆï¼Œå°±ç§°ä¸º<strong>è‡ªåŠ©èšåˆ</strong>ï¼ˆbagging, bootstrap aggregatingï¼‰ã€‚</p>

<h2 id="section">èšåˆæ³•ç®€ä»‹</h2>

<p>å¦‚ä½•å°†ç‰¹å¾å’Œå‡è®¾é›†ç»„åˆèµ·æ¥ï¼Œè®©æœºå™¨å­¦ä¹ çš„æ€§èƒ½æ›´å¥½å‘¢ï¼Ÿ</p>

<p>å‡è®¾$T$ä¸ªğŸ‘¬æœ‹å‹$g_1,\ldots,g_T$ç»™å‡ºå‚è€ƒæ„è§$g_t(\mathbf x)$é¢„æµ‹è‚¡ç¥¨æ˜¯å¦ä¼šæ¶¨ï¼Œå¦‚ä½•å†³ç­–å‘¢ï¼Ÿ</p>

<ol>
  <li>æ ¡éªŒæ³•ï¼ˆvalidationï¼‰ï¼šå¬ä»æœ€æ‡‚è‚¡ç¥¨é‚£ä¸ªæœ‹å‹çš„æ„è§ï¼Œ
\begin{equation*}
G(\mathbf x)=g_{t_*}(\mathbf x)ï¼Œ\qquad t_*=\arg\min_{t\in\{1,2,\ldots,T\}}E_{val}\left(g_t^-\right)ï¼Œ
\end{equation*}
$E_{val}\left(g_{t}^-\right)$è¡¨ç¤º$g^-$æ˜¯åœ¨ä¸€ä¸ªè¾ƒå°æ•°æ®é›†ä¸Šå¾—åˆ°çš„ç»“æœï¼Œé€‰æ‹©å®Œæˆä¹‹ååœ¨å…¨éªŒè¯é›†ä¸Šå¾—åˆ°å®Œæ•´çš„$g$ã€‚</li>
  <li>æŠ•ç¥¨æ³•ï¼ˆvoteï¼‰ï¼šä¸€äººä¸€ç¥¨çš„å‡åŒ€æŠ•ç¥¨ï¼Œå¬ä»å¤šæ•°äººçš„æ„è§ï¼Œ
\begin{equation}
G(\mathbf x)=\mbox{sign}\left(\sum_{t=1}^T1\cdot g_t(\mathbf x)\right)ã€‚
\label{eq:uniform-blending-hypothesis}
\end{equation}</li>
  <li>åŠ æƒæŠ•ç¥¨æ³•ï¼šæ¯ä¸ªäººçš„ç¥¨æ•°ä¸ä¸€æ ·ï¼Œå¬ä»å¤šæ•°ç¥¨çš„æ„è§ï¼Œ
\begin{equation}
G(\mathbf x)=\mbox{sign}\left(\sum_{t=1}^T\alpha_t\cdot g_t(\mathbf x)\right),\qquad\alpha_t\geq 0ã€‚
\label{eq:linear-blending-hypothesis}
\end{equation}
å½“$\alpha_t=[[E_{val}\left(g_{t}^-\right)\mbox{ smallest}]]$æ—¶ï¼Œä¸æ–¹æ³•1ä¸€æ ·ï¼›å½“$\alpha_t=1$æ—¶ï¼Œä¸æ–¹æ³•2ä¸€æ ·ã€‚</li>
  <li>æœ‰æ¡ä»¶çš„ç»„åˆï¼šæ¯”å¦‚ç§‘æŠ€è‚¡å¬ä»æ“…é•¿è¿™æ–¹é¢çš„æœ‹å‹ï¼Œä¼ ç»Ÿè¡Œä¸šè‚¡ç¥¨å¬ä»é‚£äº›â€¦â€¦
\begin{equation*}
G(\mathbf x)=\mbox{sign}\left(\sum_{t=1}^T q_t(\mathbf x)\cdot g_t(\mathbf x)\right),\qquad q_t(\mathbf x)\geq 0ï¼Œ
\end{equation*}
å½“$q_t(\mathbf x)=\alpha_t$æ—¶ï¼Œä¸æ–¹æ³•3ä¸€æ ·ï¼Œä¹Ÿå°±æ˜¯åŒ…å«äº†å‰é¢æ‰€æœ‰æƒ…å†µã€‚</li>
</ol>

<p><strong>èšåˆæ³•</strong>çš„ç›®çš„æ˜¯ç»¼åˆå¤šä¸ªå‡è®¾ï¼ˆå¯èƒ½æ˜¯æ¯”è¾ƒå¼±çš„ï¼‰è®©æ•ˆæœæ›´å¥½ã€‚ä¸Šè¿°æ–¹æ³•ä¸­ï¼Œ2ï½4ç§°ä¸º<strong>èšåˆæ¨¡å‹</strong>ï¼ˆaggregation modelï¼‰ã€‚</p>

<p>å¯¹äºä¸Šè¿°1çš„æ ¡éªŒï¼ˆvalidationï¼‰æ–¹æ³•ï¼Œå¦‚æœç”¨$E_{in}(g_t)$ä»£æ›¿$E_{val}(g_t)$è¿›è¡Œé€‰æ‹©ï¼Œæœ€ç»ˆå¯èƒ½ä¼šä»˜å‡ºå¾ˆå¤§VCç»´çš„ä»£ä»·<sup id="fnref:why-large-dvc"><a href="#fn:why-large-dvc" class="footnote">1</a></sup>ã€‚è¿™ç§æ–¹æ³•éœ€è¦ä¸€ä¸ªå¼ºå¤§ä¼˜ç§€çš„$g_t^-$ï¼Œå¦åˆ™ä¹Ÿåªæ˜¯å·®ä¸­æ‹©ä¼˜ã€‚</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-15-blending-and-bagging-vote-method.png"><img src="/assets/images/2015-01-15-blending-and-bagging-vote-method.png" alt="ï¼»å·¦ï¼½ï¼šæ°´å¹³å‚ç›´çº¿æŠ•ç¥¨ï¼›ï¼»å³ï¼½PLAæŠ•ç¥¨" /></a><div class="caption">Figure 1:  ï¼»å·¦ï¼½ï¼šæ°´å¹³å‚ç›´çº¿æŠ•ç¥¨ï¼›ï¼»å³ï¼½PLAæŠ•ç¥¨ [<a href="/assets/images/2015-01-15-blending-and-bagging-vote-method.png">PNG</a>]</div></div></div>

<p>ä¸Šå›¾å±•ç¤ºäº†åˆ©ç”¨èšåˆæ³•çš„æŠ•ç¥¨æœºåˆ¶ï¼Œç°è‰²çš„åˆ¤åˆ«ç•Œè¡¨ç¤ºå‚ä¸æŠ•ç¥¨çš„åˆ†ç±»å™¨ã€‚ä¸Šå›¾å·¦ä¸­ï¼Œæ°´å¹³çº¿å°†å¹³é¢åˆ†å‰²æˆäº†9å—åŒºåŸŸï¼Œå¦‚æœæŒ‰â€œå‚ç›´ã€æ°´å¹³å·¦ï¼Œæ°´å¹³å³â€çš„é¡ºåºæŠ•ç¥¨ï¼Œæ¯ä¸ªåŒºåŸŸä¸­çš„æŠ•ç¥¨ç»“æœå¦‚å›¾ä¸­ç»¿è‰²æ ‡æ³¨ï¼Œæœ€ç»ˆç»“æœç›¸å½“äºç»„åˆæˆäº†é»‘è‰²çš„åˆ¤åˆ«ç•Œã€‚ä¸Šå›¾å·¦å±•ç¤ºçš„æŠ•ç¥¨æ–¹æ³•ï¼Œç›¸å½“äºç‰¹å¾å˜æ¢ï¼ˆfeature transformï¼‰çš„æ•ˆæœ<sup id="fnref:why-feateure-tansform"><a href="#fn:why-feateure-tansform" class="footnote">2</a></sup>ï¼›ä¸Šå›¾å³å±•ç¤ºäº†æ„ŸçŸ¥å™¨çš„æŠ•ç¥¨ç»“æœï¼Œç›¸å½“äºæ­£åˆ™åŒ–çš„æ•ˆæœã€‚é€šè¿‡ä¸Šå›¾å¯çœ‹å‡ºï¼Œåˆç†çš„é›†åˆæ–¹æ³•èƒ½æå‡æ€§èƒ½ã€‚</p>

<h2 id="section-1">å‡åŒ€æ··åˆ</h2>

<p>å‡åŒ€æ··åˆï¼ˆuniform blendingï¼‰ä¹Ÿå°±æ˜¯æŠ•ç¥¨(voting)æ–¹æ³•\eqref{eq:uniform-blending-hypothesis}ã€‚å¦‚æœæ¯ä¸ª$g_t$éƒ½ç›¸åŒï¼Œç»“æœç­‰ä»·äºä»»æ„çš„$g_t$ï¼›å¦‚æœæ¯ä¸ª$g_t$åƒå·®ä¸‡åˆ«ï¼Œå°±æ˜¯å°‘æ•°æœä»å¤šæ•°ã€‚è¯¥æ–¹æ³•å¯ä»¥ç›´æ¥æ¨å¹¿åˆ°å¤šç±»çš„æƒ…å†µï¼Œ
\[
G(\mathbf x)=\arg\max_{1\leq k\leq K}\sum_{t=1}^T[[g_t(\mathbf x)=k]]ã€‚
\]</p>

<p>å‡åŒ€æ··åˆè§£å†³å›å½’é—®é¢˜çš„æ–¹æ³•æ˜¯
\[
G(\mathbf x) = {1\over T}\sum_{t=1}^Tg_t(\mathbf x)ã€‚
\]
å¦‚æœæ¯ä¸ª$g_t$éƒ½ç›¸åŒï¼Œç»“æœç­‰ä»·äºä»»æ„çš„$g_t$ï¼›å¯¹äºä¸åŒçš„$g_t$ï¼Œå¯èƒ½å¾—åˆ°æ¯”å•ä¸€åˆ¤åˆ«æ›´ç²¾ç¡®çš„ç»“æœã€‚</p>

<p>ç”±æ­¤å¯è§ï¼Œå¯¹äºå¤šä¸ªä¸åŒçš„å‡è®¾ï¼Œå³ä½¿é‡‡ç”¨ç®€å•çš„æ··åˆæ³•åˆ™ï¼Œä¹Ÿå¯ä»¥å¾—åˆ°æ¯”å•ä¸€å‡è®¾æ›´å¥½çš„ç»“æœã€‚</p>

<p>å¯¹äºå‡åŒ€æ··åˆçš„å›å½’ï¼Œ
\[
\begin{aligned}
avg\left(\left(g_t(\mathbf x)-f(\mathbf x)\right)^2\right)
=&amp;avg\left(g_t^2-2g_t^2f+f^2\right)\\
=&amp;avg\left(g_t^2\right)-2Gf+f^2\\
=&amp;avg\left(g_t^2\right)-G^2+(G-f)^2\\
=&amp;avg\left(g_t^2\right)-2G^2 + G^2 +(G-f)^2\\
=&amp;avg\left(g_t^2-2g_tG + G^2\right) +(G-f)^2\\
=&amp;avg\left(\left(g_t-G\right)^2\right) +(G-f)^2ã€‚
\end{aligned}
\]</p>

<p>è‹¥å¯¹äº§ç”Ÿ$\mathbf x$åˆ†å¸ƒçš„æ‰€æœ‰ç‚¹éƒ½è¿›è¡Œä¸Šè¿°è¿ç®—ï¼Œç„¶åå–æœŸæœ›å¯å¾—
\[
avg\left(E_{out}\left(g_t\right)\right)=avg(\varepsilon(g_t-G)^2)+E_{out}(G)\geq E_{out}(G)ï¼Œ
\]
ä¹Ÿå°±æ˜¯è¯´ï¼Œå‡åŒ€æ··åˆæ–¹æ³•çš„æ•ˆæœä¼šæ¯”é€‰æ‹©å…¶ä¸­ä¸€ä¸ªå¥½ã€‚</p>

<p>ä»$P^N$é‡‡é›†å¤§å°ä¸º$N$çš„$T$ä¸ªæ•°æ®é›†ï¼Œåˆ©ç”¨ä¸Šè¿°å…¬å¼ï¼Œè¡¡é‡æ¼”ç®—æ³•$\mathcal A$çš„è¡¨ç°ã€‚é€šè¿‡$\mathcal A(\mathcal D_t)$è·å¾—$g_t$ï¼Œå¯¹å…¶å¹³å‡
\[
\bar g=\lim_{T\rightarrow\infty}G=\lim_{T\rightarrow\infty}{1\over T}\sum_{t=1}^Tg_t=\varepsilon_{\mathcal D}\mathcal A(\mathcal D)ï¼Œ
\]
ç®—æ³•$\mathcal A$çš„æ€§èƒ½æœŸæœ›ä¸º
\begin{equation}
avg(E_{out}(g_t))=avg(\varepsilon(g_t-\bar g)^2)+E_{out}(\bar g)ã€‚
\label{eq:bias-variance-decomposition}
\end{equation}</p>

<p>ä¸Šè¿°å…¬å¼ä¸­ï¼š</p>

<ul>
  <li>$avg(E_{out}(g_t))$ï¼šç®—æ³•$\mathcal A$çš„æœŸæœ›æ€§èƒ½ï¼›</li>
  <li>$E_{out}(\bar g)$ï¼šç®—æ³•å…±è¯†ï¼ˆconsensusï¼‰çš„æ€§èƒ½ï¼ˆ$\bar g$å°±æ˜¯ä»$\mathcal D_t\sim P^N$æœŸæœ›è·å¾—çš„$g_t$ï¼‰ï¼Œé€šå¸¸ç§°ä¸º<strong>bias</strong>ï¼›</li>
  <li>$avg(\varepsilon(g_t-\bar g)^2)$ï¼šåç¦»å…±è¯†çš„æœŸæœ›ï¼Œé€šå¸¸ç§°ä¸º<strong>variance</strong>ã€‚</li>
</ul>

<p>é€šè¿‡biaså’Œvarianceï¼Œå°†æ¼”ç®—æ³•çš„è¡¨ç°æ‹†åˆ†ä¸ºä¸¤éƒ¨åˆ†ã€‚å‡åŒ€æ··åˆé€šè¿‡å‡å°varianceè·å¾—æ›´ç¨³å®šçš„æ€§èƒ½ã€‚</p>

<h2 id="section-2">çº¿æ€§æ··åˆ</h2>

<p>é€šè¿‡\eqref{eq:linear-blending-hypothesis}ï¼Œèµ‹äºˆä¸åŒå‡è®¾ä¸åŒçš„æƒé‡å°±æ˜¯<strong>çº¿æ€§æ··åˆ</strong>ï¼ˆlinear blendingï¼‰ã€‚</p>

<p>çº¿æ€§å›å½’çš„çº¿æ€§æ··åˆç›®æ ‡ä¸º
\[
\min_{\alpha_t\geq 0}{1\over N}\sum_{n=1}^N\left(y_n-\sum_{t=1}^T\alpha_tg_t(\mathbf x_n)\right)^2ï¼Œ
\]
å°†$g(\mathbf x)$è§†ä¸ºç‰¹å¾å˜æ¢$\phi(\mathbf x)$ï¼Œæ¢ä¸€ç§è¡¨è¾¾å½¢å¼
\[
\min_{\mathbf w}{1\over N}\sum_{n=1}^{N}\left(y_n-\sum_{i=1}^{\tilde d}w_i\phi_i(\mathbf x_n)\right)^2ï¼Œ
\]
è¿™å°±ç±»ä¼¼ä¸¤é˜¶ï¼ˆtwo-levelï¼‰çš„å­¦ä¹ æ–¹æ³•ã€‚</p>

<p>çº¿æ€§æ··åˆï¼çº¿æ€§æ¨¡å‹ï¼‹å‡è®¾ï¼ˆhypothesisï¼‰è§†ä¸ºå˜æ¢ï¼‹çº¦æŸæ¡ä»¶ï¼Œ
\[
\min_{\alpha_t\geq 0}{1\over N}\sum_{n=1}^Nerr\left(y_n,\sum_{t=1}^T\alpha_tg_t(\mathbf x_n)\right)ã€‚
\]
å¯¹äºäºŒåˆ†ç±»é—®é¢˜
\[
\alpha_tg_t(\mathbf x)=|\alpha_t|(-g_t(\mathbf x))\qquad\mbox{if }\alpha_t&lt;0ï¼Œ
\]
æ­£è´Ÿå¯¹åˆ†ç±»å™¨æœ¬è´¨ä¸Šæ²¡æœ‰å·®åˆ«ï¼Œå®é™…ä¸Šæœ‰â€œçº¿æ€§æ··åˆï¼çº¿æ€§æ¨¡å‹ï¼‹å‡è®¾ï¼ˆhypothesisï¼‰è§†ä¸ºå˜æ¢â€ï¼Œä¸éœ€è¦$\alpha_t$çš„çº¦æŸæ¡ä»¶ã€‚</p>

<p>åœ¨å®é™…ä¸­ï¼Œ$g_t$é€šå¸¸æ˜¯ç”¨$E_{in}$ä»å„æ¨¡å‹ä¸­é€‰çš„æœ€ä¼˜ï¼Œ$g_1\in\mathcal H_1,g_2\in\mathcal H_2,\dots,g_T\in\mathcal H_T$ã€‚å¦‚æœåœ¨è¿™äº›$g_t$ä¸­ç”¨$E_{in}$å†é€‰æœ€ä¼˜çš„ï¼Œå°±æ˜¯best of bestï¼Œå°†ä»˜å‡ºé«˜å¤æ‚åº¦$d_{VC}=\left(\bigcup\limits_{t=1}^T\mathcal H_t\right)$çš„ä»£ä»·ã€‚å¦‚æœåœ¨è¿™äº›$g_t$ä¸­ç”¨$E_{in}$å†é‡‡ç”¨çº¿æ€§æ··åˆï¼Œå°±æ˜¯aggregation of bestï¼Œå°†ä»˜å‡º<strong>é«˜äº</strong>$d_{VC}=\left(\bigcup\limits_{t=1}^T\mathcal H_t\right)$çš„ä»£ä»·ã€‚å®é™…ä¸Šé€šå¸¸é‡‡ç”¨$E_{val}$æ›¿ä»£$E_{in}$ï¼Œé€šè¿‡æœ€å°åŒ–$E_{train}$å¾—åˆ°$g_t^-$ã€‚</p>

<blockquote>
  <h4 id="section-3">çº¿æ€§æ··åˆç®—æ³•</h4>
  <hr />

  <ol>
    <li>ä»$\mathcal D_{train}$ä¸­è·å–$g_1^-,g_2^-,\ldots,g_T^-$ï¼›     </li>
    <li>åœ¨$\mathcal D_{val}$ä¸­å°†$(\mathbf x_n,y_n)$è½¬æ¢ä¸º$(\mathbf z_n=\phi^-(\mathbf x_n),y_n)$ï¼Œå…¶ä¸­$\phi^-(\mathbf x)ï¼(g_1^-(\mathbf x),g_2^-(\mathbf x),\ldots,g_T^-(\mathbf x))$ï¼›</li>
    <li>è®¡ç®—$\boldsymbol\alpha=\mbox{LinearModel}\left(\{(\mathbf z_n, y_n)\}\right)$ï¼›</li>
    <li>è¿”å› $G_{LINB}(\mathbf x)=\mbox{LinearHypothesis}_\boldsymbol\alpha(\phi(\mathbf x))$ï¼Œå…¶ä¸­$\phi(\mathbf x)ï¼(g_1(\mathbf x),g_2(\mathbf x),\ldots,g_T(\mathbf x))$<sup id="fnref:how-gt-gt-x"><a href="#fn:how-gt-gt-x" class="footnote">3</a></sup>ã€‚</li>
  </ol>

</blockquote>

<p><strong>å¦‚æœå°†3ã€4ä¸¤æ­¥æ¢ä¸ºï¼š</strong></p>

<ul>
  <li>è®¡ç®—$\tilde g=\mbox{AnyModel}\left(\{(\mathbf z_n, y_n)\}\right)$ï¼›</li>
  <li>è¿”å›$G_{ANYB}(\mathbf x)=\tilde g(\phi(\mathbf x))$ã€‚</li>
</ul>

<p>è¿™å°±æ˜¯any blendingï¼ˆstackingï¼‰çš„æ–¹æ³•ã€‚any blendingæ–¹æ³•å¼ºå¤§ï¼Œå¯ä»¥å®ç°conditional blendingï¼Œä½†æ˜¯ä¹Ÿå­˜åœ¨è¿‡æ‹Ÿåˆçš„é£é™©ã€‚</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-15-blending-and-bagging-blending-example.png"><img src="/assets/images/2015-01-15-blending-and-bagging-blending-example.png" alt="æ··åˆæ–¹æ³•ä½¿ç”¨å®ä¾‹" /></a><div class="caption">Figure 2:  æ··åˆæ–¹æ³•ä½¿ç”¨å®ä¾‹ [<a href="/assets/images/2015-01-15-blending-and-bagging-blending-example.png">PNG</a>]</div></div></div>

<p>ä¸Šå›¾çš„æµç¨‹ä¸­ï¼ŒVal.-Set Blendingå°±æ˜¯any blendingçš„æ–¹æ³•ï¼Œä½¿å¾—$E_{test}$é™ä½åˆ°$456.24$ã€‚ç„¶åå†å°†è¿™ä¸€æ­¥å¾—åˆ°çš„ä¸Šç™¾ä¸ª$gï¼ŒG$ç”¨è¿‘ä¼¼çš„$\tilde E_{test}$ï¼ˆ$\tilde E_{test}$å¥½å¯ä½¿çœŸæ­£çš„$E_{test}$æ›´å¥½ï¼‰è¿›è¡Œlinear blendingã€‚</p>

<p>æ··åˆï¼ˆblendingï¼‰åœ¨å®é™…ä¸­å¾ˆæœ‰ç”¨ï¼Œä½†æ˜¯æ¨¡å‹è®¡ç®—å¤æ‚åº¦å¢å¤§äº†ã€‚</p>

<h2 id="section-4">â¾ƒåŠ©èšåˆ</h2>

<p>æ··åˆï¼ˆblendingï¼‰æ–¹æ³•çš„ç­–ç•¥æ˜¯å…ˆå­¦ä¹ åˆ°$g_t$ï¼Œç„¶åå†èšåˆï¼ˆaggregateï¼‰ã€‚<del>èƒ½å¦åœ¨å­¦ä¹ $g_t$çš„åŒæ—¶è¿›è¡Œèšåˆå‘¢ï¼Ÿâœ…</del></p>

<p>å¯¹äºå‡åŒ€èšåˆï¼ˆuniform aggregationï¼‰ï¼Œä¸åŒæ¨¡å‹å‚ä¸èšåˆæ˜¯å…³é”®ï¼Œè·å–ä¸åŒæ¨¡å‹çš„æ–¹æ³•åŒ…æ‹¬ï¼š</p>

<ul>
  <li>ä»ä¸åŒå‡è®¾é›†è·å–æ¨¡å‹ï¼š$g_1\in\mathcal H_1,g_2\in\mathcal H_2,\ldots,g_T\in\mathcal H_T$ï¼›</li>
  <li>é‡‡ç”¨ä¸åŒçš„å‚æ•°ï¼šå¯¹äºæ¢¯åº¦ä¸‹é™æ³•ï¼Œ$\eta=0.001,0.01,\ldots,10$ï¼›</li>
  <li>åˆ©ç”¨ç®—æ³•çš„éšæœºæ€§ï¼šä»ä¸åŒçš„åˆå§‹åŒ–å¼€å§‹PLAï¼›</li>
  <li>åˆ©ç”¨æ•°æ®çš„éšæœºæ€§ï¼šäº¤å‰æ£€éªŒé‡‡ç”¨ä¸åŒæ•°æ®é›†éªŒè¯$g_v^-$<sup id="fnref:how-to-gv-x"><a href="#fn:how-to-gv-x" class="footnote">4</a></sup>ã€‚</li>
</ul>

<p>å›é¡¾\eqref{eq:bias-variance-decomposition}ï¼Œç®—æ³•çš„æ€§èƒ½è¢«æ‹†åˆ†ä¸ºbiaså’Œvarianceä¸¤éƒ¨åˆ†è¿›è¡Œè¯„ä¼°ã€‚å…±è¯†çš„ç»“æœä¼šæ¯”$\mathcal A(\mathcal D)$çš„å•ä¸€$g$æ•ˆæœå¥½ï¼Œä½†æ˜¯æ¯æ¬¡éƒ½éœ€è¦ç”¨ä¸åŒçš„$\mathcal D_t$è·å¾—$g_t$ã€‚</p>

<p>èƒ½å¦é€šè¿‡æœ‰é™çš„$T$å’Œå•ä¸€çš„æ•°æ®é›†$\mathcal D$å¾—è¿‘ä¼¼çš„$\bar g$ï¼Ÿâœ…</p>

<p><strong>bootstrapping</strong>æ˜¯ä¸€ç§é€šè¿‡é‡é‡‡æ ·ï¼ˆre-sampleï¼‰$\mathcal D$æ¨¡æ‹Ÿ$\mathcal D_t$çš„ç»Ÿè®¡å­¦å·¥å…·ã€‚bootstrapå¾—åˆ°$\tilde{\mathcal D}_t$çš„æ–¹æ³•ï¼šä»$\mathcal D$ä¸­éšæœºæŠ½å–ä¸€ä¸ªç‚¹ï¼Œçºªå½•è¯¥ç‚¹åç„¶åæ”¾å›ï¼Œé‡å¤è¯¥è¿‡ç¨‹ç›´åˆ°æŠ½å–åˆ°$Nâ€™$ä¸ªæ•°æ®ã€‚</p>

<blockquote>
  <h4 id="section-5">è‡ªåŠ©èšåˆç®—æ³•</h4>
  <hr />

  <ol>
    <li>åˆ©ç”¨bootstrappingæŠ€æœ¯å¾—åˆ°$Nâ€™$ç‚¹çš„æ•°æ®é›†$\tilde{\mathcal D}_t$ï¼›</li>
    <li>åˆ©ç”¨$\mathcal A(\tilde{\mathcal D}_t)$ï¼Œç®—æ³•$\mathcal A$åœ¨æ•°æ®é›†$\tilde{\mathcal D}_t$ä¸Šå¾—åˆ°$g_t$ï¼›</li>
    <li>$G=\mbox{Uniform}(g_t)$ã€‚</li>
  </ol>
</blockquote>

<p><strong>â¾ƒåŠ©èšåˆ</strong>ï¼ˆ<strong>b</strong>ootstrap <strong>agg</strong>regat<strong>ing</strong>ï¼‰ä¹Ÿç§°ä¸º<strong>æ‰“åŒ…</strong>ï¼ˆbaggingï¼‰ã€‚åƒâ¾ƒåŠ©èšåˆè¿™ç§ï¼Œå»ºç«‹åœ¨å…¶å®ƒåŸºç¡€ç®—æ³•ï¼ˆbase algorithmï¼‰$\mathcal A$ä¹‹ä¸Šçš„ç®—æ³•ç§°ä¸ºmeta algorithmã€‚</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-15-blending-and-bagging-pla-bagging.png"><img src="/assets/images/2015-01-15-blending-and-bagging-pla-bagging.png" alt="bagging pocketæ–¹æ³•" /></a><div class="caption">Figure 3:  bagging pocketæ–¹æ³• [<a href="/assets/images/2015-01-15-blending-and-bagging-pla-bagging.png">PNG</a>]</div></div></div>

<p>ä¸Šå›¾æ˜¯bagging pocketæ–¹æ³•çš„æ•ˆæœï¼Œé€šè¿‡baggingå¾—åˆ°å„ä¸ç›¸åŒçš„$g_t$ï¼Œç„¶åé€šè¿‡èšåˆå¾—åˆ°åˆé€‚çš„éçº¿æ€§åˆ†ç±»å™¨ã€‚</p>

<p>å¦‚æœåŸºç¡€ç®—æ³•ï¼ˆbase algorithmï¼‰å¯¹æ•°æ®çš„éšæœºæ€§å¾ˆæ•æ„Ÿï¼Œbaggingå¯ä»¥å·¥ä½œå¾—ç›¸å½“å¥½ã€‚</p>

<h2 id="section-6">å‚è€ƒèµ„æ–™</h2>

<ol class="bibliography"></ol>

<h3 id="section-7">è„šæ³¨</h3>

<div class="footnotes">
  <ol>
    <li id="fn:why-large-dvc">
      <p>ä¸ºä»€ä¹ˆä¼šä»˜å‡ºå¾ˆå¤§VCç»´çš„ä»£ä»·ï¼Ÿ <a href="#fnref:why-large-dvc" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:why-feateure-tansform">
      <p>ä¸ºä»€ä¹ˆç›¸å½“äºç‰¹å¾å˜æ¢çš„æ•ˆæœï¼Ÿ <a href="#fnref:why-feateure-tansform" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:how-gt-gt-x">
      <p>$g_t^-(\mathbf x)$å’Œ$g_t(\mathbf x)$å…·ä½“å¦‚ä½•è®¡ç®—ï¼Ÿ <a href="#fnref:how-gt-gt-x" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:how-to-gv-x">
      <p>è¿™æ­¥å¦‚ä½•æ“ä½œï¼Ÿã€Œæ©Ÿå™¨å­¸ç¿’åŸºçŸ³ã€ç¬¬åäº”è¬›æœ‰é—œã€‚ <a href="#fnref:how-to-gv-x" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>çº¿æ€§å›å½’</title>
      <link href="http://qianjiye.de/2015/01/linear-regression" />
      <pubdate>2015-01-13T20:17:01+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/linear-regression</guid>
      <content:encoded>&lt;![CDATA[<p><img src="/assets/images/2014-10-19-linear_regression_0.png" alt="çº¿æ€§å›å½’" /></p>

<p>æœ¬èŠ‚çš„ä¸»è¦å‚è€ƒèµ„æ–™æ˜¯æœºå™¨å­¦ä¹ åŸºçŸ³<a href="#lin_mlf_linreg_2014">[1]</a>å’Œæœºå™¨å­¦ä¹ <a href="#ng_ml_linreg_2014">[2]</a>ç½‘ç»œè¯¾ç¨‹ã€‚</p>

<h2 id="section">çº¿æ€§å›å½’æ¨¡å‹</h2>

<p>çº¿æ€§å›å½’çš„å‡è®¾é›†ï¼ˆhypothesisï¼‰ä¸º
\begin{equation}
h(\mathbf x) = \mathbf w^T\mathbf xï¼Œ
\label{eq:linear-regression-model}
\end{equation}
$\mathbf x$æ˜¯å«æœ‰å¸¸æ•°é¡¹$x_0 = 1$çš„$d+1$ç»´å‘é‡$\mathbf x =\left[1,x_1,\ldots,x_d\right]^T$ï¼Œ$\mathbf w=\left[w_0,w_1,\ldots,w_d\right]^T$ï¼Œ$d$æ˜¯ç‰¹å¾ç»´æ•°ã€‚</p>

<p>ç›®æ ‡ä»£ä»·å‡½æ•°é‡‡ç”¨å¹³æ–¹è¯¯å·®å’Œä¼°è®¡
\begin{equation}
E_{in}(\mathbf w)={1\over N}\sum_{n=1}^N\left(\mathbf w^T\mathbf x_n-y_n\right)^2ï¼Œ
\label{eq:cost-function-linear-regression}
\end{equation}
$N$æ˜¯æ ·æœ¬æ•°ã€‚é€šè¿‡æœºå™¨å­¦ä¹ ç®—æ³•æ±‚å¾—çº¿æ€§å›å½’çš„å‚æ•°
\begin{equation}
\mathbf w_{LIN} = \arg\min_{\mathbf w}E_{in}(\mathbf w)ï¼Œ
\end{equation}
é€šå¸¸æ–¹æ³•æœ‰æ­£è§„æ–¹ç¨‹ï¼ˆnormal equationï¼‰çš„è§£ææ–¹æ³•å’Œæ¢¯åº¦ä¸‹é™æ³•ï¼ˆgradient descentï¼‰ã€‚</p>

<h2 id="section-1">è§£ææ–¹æ³•</h2>

<p>è§£ææ–¹æ³•å¾—åˆ°çš„æœ€ä¼˜è§£ä¹Ÿç§°ä¸º<strong>çº¿æ€§å›å½’çš„æœ€å°äºŒä¹˜è§£</strong>ã€‚</p>

<p>ä»£ä»·å‡½æ•°æ”¹å†™ä¸ºçŸ©é˜µå½¢å¼
\[
E_{in}(\mathbf w) 
={1\over N}\lVert\mathbf X\mathbf w-\mathbf y\rVert^2
={1\over N}\left(\mathbf w^T\mathbf X^T\mathbf X\mathbf w-2\mathbf w^T\mathbf X^T\mathbf y+\mathbf y^T\mathbf y\right)ï¼Œ
\]
$\mathbf X$æ˜¯æ ·æœ¬æ•°æ®çŸ©é˜µï¼Œæ¯è¡Œä»£è¡¨ä¸€ä¸ªæ ·æœ¬ç‚¹ï¼Œæ¯åˆ—ä»£è¡¨ä¸€ä¸ªç‰¹å¾ï¼Œç¬¬ä¸€åˆ—çš„å‘é‡$\mathbf 1_N$å¯¹åº”å¸¸æ•°åç§»ã€‚$E_{in}(\mathbf w)$æ˜¯è¿ç»­å¯å¾®çš„å‡¸å‡½æ•°ï¼Œå½“$\nabla E_{in}(\mathbf w)=0$æ—¶å–å¾—æœ€å°å€¼ï¼Œ
\[
\nabla E_{in}(\mathbf w)={2\over N}\left(\mathbf X^T\mathbf X\mathbf w-\mathbf X^T\mathbf y\right)ï¼Œ
\]
å–å¾—æœ€å°å€¼æ—¶
\begin{equation}
\mathbf w_{LIN} = \left(\mathbf X^T\mathbf X\right)^{-1}\mathbf X^T\mathbf y = \mathbf X^\dagger \mathbf yï¼Œ
\end{equation}
$\mathbf X^\dagger$ç§°ä¸º<strong>ä¼ªé€†</strong>ï¼ˆpseudo-inverseï¼‰ã€‚é€šå¸¸æƒ…å†µ$N\gg d+1$ï¼Œå› æ­¤$\left(\mathbf X^T\mathbf X\right)^{-1}$é€šå¸¸éƒ½å¯é€†ï¼›å¦‚æœä¸å¯é€†ï¼Œè§£ä¸å”¯ä¸€ã€‚</p>

<p>å¯¼è‡´$\mathbf X^T\mathbf X$ä¸å¯é€†çš„åŸå› å¯èƒ½æ˜¯å†—ä½™ç‰¹å¾ï¼ˆredundant featuresï¼‰æˆ–è€…ç‰¹å¾æ•°ç›®è¿‡å¤šï¼ˆ$d$å¤ªå¤§è€Œ$N$å¤ªå°‘ï¼‰ï¼Œè§£å†³çš„åŠæ³•ï¼š   </p>

<ul>
  <li>å¯¹äºå†—ä½™çš„çº¿æ€§ç›¸å…³ç‰¹å¾ï¼Œä¾‹å¦‚$x_1 = 2x_2$ï¼Œåˆ é™¤çº¿æ€§ç›¸å…³ç‰¹å¾ï¼›</li>
  <li>å¯¹äºç‰¹å¾æ•°ç›®è¿‡å¤šï¼Œä¾‹å¦‚$N&lt;d$ï¼Œåˆ é™¤ç‰¹å¾æˆ–æ­£åˆ™åŒ–ï¼ˆregularizationï¼‰<sup id="fnref:how-to-regularize"><a href="#fn:how-to-regularize" class="footnote">1</a></sup>ã€‚</li>
</ul>

<p>Matlabçš„<code>pinv</code>å‡½æ•°å¯ä»¥å¤„ç†$\mathbf X^T\mathbf X$ä¸å¯é€†çš„æƒ…å†µ<sup id="fnref:pinv-vs-inv"><a href="#fn:pinv-vs-inv" class="footnote">2</a></sup>ã€‚</p>

<h3 id="mathbf-wlin">è§£ææ–¹æ³•æ±‚è§£$\mathbf w_{LIN}$æ˜¯æœºå™¨å­¦ä¹ ç®—æ³•å—ï¼Ÿ</h3>

<p>âœ…é€šè¿‡VCç»´çš„è§’åº¦åˆ†æï¼Œèƒ½å¾—åˆ°å°çš„$E_{out}\left(\mathbf w_{\small{LIN}}\right)$ï¼Œå°±æ˜¯å­¦ä¹ â€¦â€¦</p>

<ul>
  <li>èƒ½å¤Ÿå¾—åˆ°æœ€ä½³çš„$E_{in}$ï¼›</li>
  <li>$d+1$ä¸ªå˜é‡ï¼Œæœ‰é™çš„$d_{VC}$ï¼Œå› æ­¤æœ‰å¥½çš„$E_{out}$ï¼›</li>
  <li>äº‹å®ä¸Šï¼Œæ±‚è§£ä¼ªé€†çš„è¿‡ç¨‹ä¹Ÿæ˜¯è¿­ä»£é€æ­¥æœ€ä¼˜çš„è¿‡ç¨‹ï¼ˆé«˜æ–¯æ¶ˆå…ƒæ³•ï¼‰ã€‚</li>
</ul>

<p>VCç»´è€ƒå¯Ÿçš„æ˜¯ä¸ªåˆ«çš„$E_{in}$<sup id="fnref:some-E-in"><a href="#fn:some-E-in" class="footnote">3</a></sup>ï¼Œä»$E_{in}$å¹³å‡è¯¯å·®è§’åº¦åˆ†æ
\begin{equation}
\bar E_{in}
=\varepsilon_{\mathcal D\sim P^N}\left\{E_{in}\left(\mathbf w_{LIN}\mbox{ w.r.t }\mathcal D\right)\right\}
=\mbox{noise level}\cdot\left(1-{d+1\over N}\right)ï¼Œ
\label{eq:noise-level-e-in}
\end{equation}
$\mbox{noise level}$è¡¨ç¤ºæ•°æ®ä¸­çš„å™ªå£°ï¼Œ${d+1\over N}$è¡¨ç¤ºæ¯”å™ªå£°å°çš„æ¯”ç‡ï¼Œæ•°æ®è¶Šå¤šäºŒè€…å·®åˆ«è¶Šå°ã€‚</p>

<p>$E_{in}\left(\mathbf w_{LIN}\right)$è®¡ç®—æ–¹æ³•ä¸º
\[
E_{in}\left(\mathbf w_{LIN}\right)
={1\over N}\left\lVert\mathbf y-\hat{\mathbf y}\right\rVert^2
={1\over N}\left\lVert\mathbf y-\mathbf X\mathbf X^\dagger\mathbf y\right\rVert^2
={1\over N}\left\lVert\left(\mathbf I-\mathbf X\mathbf X^\dagger\right)\mathbf y\right\rVert^2ï¼Œ
\]
$\mathbf X\mathbf X^\dagger$è®©$\mathbf y$åŠ å¸½$\wedge$å˜æˆäº†$\hat{\mathbf y}$ï¼Œä¹Ÿå«<strong>å¸½çŸ©é˜µ</strong><sup id="fnref:hat-matrix-properties"><a href="#fn:hat-matrix-properties" class="footnote">4</a></sup>ï¼ˆhat matrixï¼‰ï¼Œè®°ä¸º$\mathbf H$ã€‚</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-13-linear-regression-learning-curve.png"><img src="/assets/images/2015-01-13-linear-regression-learning-curve.png" alt="ï¼»å·¦ï¼½ï¼šå›¾è§£è¯æ˜ï¼›ï¼»å³ï¼½ï¼šå­¦ä¹ æ›²çº¿" /></a><div class="caption">Figure 1:  ï¼»å·¦ï¼½ï¼šå›¾è§£è¯æ˜ï¼›ï¼»å³ï¼½ï¼šå­¦ä¹ æ›²çº¿ [<a href="/assets/images/2015-01-13-linear-regression-learning-curve.png">PNG</a>]</div></div></div>

<p>ç”±$\hat{\mathbf y}=\mathbf X\mathbf w_{LIN}$å¯çŸ¥ï¼Œ$\hat{\mathbf y}$æ˜¯$\mathbf X$åˆ—å‘é‡çš„çº¿æ€§ç»„åˆï¼Œä¹Ÿå°±æ˜¯å¦‚ä¸Šå›¾å·¦æ‰€ç¤ºï¼Œ$\hat{\mathbf y}$ä½äº$\mathbf X$å¼ æˆçš„çº¿æ€§ç©ºé—´ä¸­ã€‚å½“$\mathbf y-\hat{\mathbf y}$å‚ç›´äºè¯¥ç”Ÿæˆç©ºé—´æ—¶ï¼Œ$\left\lVert\mathbf y-\hat{\mathbf y}\right\rVert^2$çš„å€¼æœ€å°ã€‚$\mathbf H$å°†$\mathbf y$æŠ•å½±ä¸º$\hat{\mathbf y}$ï¼Œ$\mathbf I-\mathbf H$å°†$\mathbf y$æŠ•å½±ä¸º$\mathbf y-\hat{\mathbf y}$ã€‚$\mathbf I-\mathbf H$çš„è¿¹ä¸º$trace(\mathbf I-\mathbf H)=N-(d+1)$ï¼Œè¡¨ç¤ºè‡ªç”±åº¦ä»$N$é™åˆ°$N-(d+1)$ã€‚</p>

<p>è§‚æµ‹åˆ°çš„æ•°æ®$\mathbf y$æ˜¯ç†æƒ³çš„æ•°æ®ç©ºé—´$f\left(\mathbf X\right)$å åŠ ä¸€äº›å™ªå£°ã€‚$\mathbf y-\hat{\mathbf y}$ä¹Ÿå¯ä»¥ä»å™ªå£°æŠ•å½±å¾—åˆ°ï¼Œå¦‚ä¸Šå›¾å·¦æ‰€ç¤ºï¼Œ
\[
E_{in}\left(\mathbf w_{LIN}\right)
={1\over N}\left\lVert\mathbf y-\hat{\mathbf y}\right\rVert^2
={1\over N}\left\lVert(\mathbf I-\mathbf H)\cdot\mbox{noise}\right\rVert^2
={1\over N}(N-(d+1))\lVert\mbox{noise}\rVert^2ï¼Œ
\]
å› æ­¤å¯å¾—å…¬å¼\eqref{eq:noise-level-e-in}çš„ç»“è®ºã€‚$E_{out}$çš„è¯æ˜è¿‡ç¨‹å«å¤æ‚ï¼Œä»ç„¶å¯ä»¥å¾—åˆ°
\[
\bar E_{out}
=\mbox{noise level}\cdot\left(1+{d+1\over N}\right)ã€‚
\]</p>

<p>$\mbox{noise level}$å¯ä»¥ç”¨$\sigma^2$è¡¨ç¤ºï¼Œä»ä¸Šå›¾å³å¯è§ï¼Œ$\bar E_{in}$å’Œ$\bar E_{out}$åœ¨$N\rightarrow\infty$æ—¶éƒ½ä¼šè¶‹è¿‘äº$\sigma^2$ã€‚æœŸæœ›çš„æ³›åŒ–è¯¯å·®ï¼ˆgeneralization errorï¼‰å¯ä»¥ç”¨${2(d+1)\over N}$è¡¡é‡ï¼Œè¿™é‡Œæ˜¯å¹³å‡æƒ…å†µï¼ŒVCç»´è¡¡é‡çš„æ˜¯æœ€åçš„æƒ…å†µã€‚</p>

<h2 id="gd-method">æ¢¯åº¦ä¸‹é™æ³•</h2>

<p>æ¢¯åº¦ä¸‹é™æ³•å°±æ˜¯æ²¿æ¢¯åº¦ä¸‹é™æ–¹å‘æ›´æ–°å‚æ•°ï¼Œä¹Ÿå°±æ˜¯å¯¹æ¯ä¸ªç‰¹å¾çš„æƒå€¼$w_i$ï¼Œä¸æ–­è¿­ä»£æ‰§è¡Œæ›´æ–°
\begin{equation}
w_i := w_i-\alpha{\partial E_{in}(\mathbf w)\over\partial w_i}\quad(i=0,1,\ldots,d)
\end{equation}
ç›´è‡³æ”¶æ•›ï¼Œå…¶ä¸­$\alpha$è¡¨ç¤ºå­¦ä¹ é€Ÿç‡ï¼Œæ¢¯åº¦è®¡ç®—å…¬å¼ä¸º
\[
{\partial E_{in}(\mathbf w)\over\partial w_i}
={1\over N}\sum_{n=1}^N\left(\mathbf w^T\mathbf x_n - y_n\right)x_{n,i}ã€‚
\]</p>

<p>å‚æ•°é¡»åŒæ—¶æ›´æ–°ï¼Œä¹Ÿå°±æ˜¯å½“æ¯ä¸ª$w_i$éƒ½æ›´æ–°å®Œæˆåï¼Œæ‰èƒ½ç”¨æ–°çš„$\mathbf w$è®¡ç®—$E_{in}(\mathbf w)$ï¼Œå…·ä½“å¯å‚è€ƒ<a href="/assets/images/2014-10-19-linear_regression_1.png">Andrew NGçš„è®²ä¹‰</a><sup id="fnref:andrew-simultaneous-update"><a href="#fn:andrew-simultaneous-update" class="footnote">5</a></sup>ã€‚</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-13-linear-regression-error-curve.png"><img src="/assets/images/2015-01-13-linear-regression-error-curve.png" alt="ï¼»å·¦1ï¼½ï¼šæœªå½’ä¸€åŒ–æ¢¯åº¦ä¸‹é™è·¯å¾„ï¼›ï¼»å·¦2ï¼½ï¼šå½’ä¸€åŒ–æ¢¯åº¦ä¸‹é™è·¯å¾„ï¼›&lt;br/&gt;ï¼»å³ï¼½ï¼šæ¢¯åº¦ä¸‹é™è·¯å¾„" /></a><div class="caption">Figure 2:  ï¼»å·¦1ï¼½ï¼šæœªå½’ä¸€åŒ–æ¢¯åº¦ä¸‹é™è·¯å¾„ï¼›ï¼»å·¦2ï¼½ï¼šå½’ä¸€åŒ–æ¢¯åº¦ä¸‹é™è·¯å¾„ï¼›<br />ï¼»å³ï¼½ï¼šæ¢¯åº¦ä¸‹é™è·¯å¾„ [<a href="/assets/images/2015-01-13-linear-regression-error-curve.png">PNG</a>]</div></div></div>

<p>æ¢¯åº¦ä¸‹é™æ³•éœ€è¦å°†æ‰€æœ‰ç‰¹å¾å½’ä¸€ï¼ˆfeature scalingï¼‰åˆ°ç»Ÿä¸€çš„å°ºåº¦ï¼ˆä¸ç”¨å½’ä¸€åŒ–$x_0$ï¼‰ï¼Œæ¯”å¦‚$-1\le x_i\le 1$ï¼Œ
\[
\hat{x}_i = \frac{x_i - x_{mean}}{x_{max}-x_{min}}
\qquad\mbox{or}\qquad
\hat{x}_i = \frac{x_i - x_{mean}}{x_{std}}ï¼Œ
\]
è¿™æ ·æœ‰åŠ©äºæé«˜æ¢¯åº¦ä¸‹é™æ³•çš„é€Ÿåº¦ï¼Œå¦‚ä¸Šå›¾å·¦2æ‰€ç¤ºã€‚</p>

<h4 id="alpha">å­¦ä¹ ç‡$\alpha$çš„æ³¨æ„äº‹é¡¹ï¼š</h4>
<ol>
  <li>åœ¨è¿­ä»£è¿‡ç¨‹ä¸­ä¸éœ€è°ƒèŠ‚$\alpha$å¤§å°ï¼Œç”±äºæ¢¯åº¦ä¼šä¸æ–­å‡å°ï¼Œ<a href="/2015/01/logistic-regression/#why-fixed-eta">åœ¨å›ºå®š$\alpha$çš„æƒ…å†µä¸‹æ¢¯åº¦ä¸‹é™æ­¥é•¿ä¹Ÿä¼šè‡ªåŠ¨å‡å°</a>ï¼Œå¦‚ä¸Šå›¾å³æ‰€ç¤ºï¼›</li>
  <li>$\alpha$å¤ªå°æ”¶æ•›æ…¢ï¼Œå¤ªå¤§å¯èƒ½é”™è¿‡æå€¼ç‚¹è€Œä¸æ”¶æ•›ï¼Œç”šè‡³å¯èƒ½å¯¼è‡´$E_{in}(\mathbf w)$ä¸é™åå‡ã€‚</li>
</ol>

<p>çº¿æ€§å›å½’çš„ä»£ä»·å‡½æ•°$E_{in}(\mathbf w)$ä¸å­˜åœ¨å±€éƒ¨æå€¼ï¼ˆlocal optimaï¼‰ï¼Œæå°å€¼å°±æ˜¯å…¨å±€æå€¼<sup id="fnref:no-local-optima"><a href="#fn:no-local-optima" class="footnote">6</a></sup>ã€‚</p>

<h2 id="section-2">ä¸¤ç§æ–¹æ³•å¯¹æ¯”</h2>

<table>
  <thead>
    <tr>
      <th>æ¢¯åº¦ä¸‹é™æ³•</th>
      <th>è§£æè§£æ³•</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>éœ€è¦$\alpha$</td>
      <td>ä¸éœ€è¦$\alpha$</td>
    </tr>
    <tr>
      <td>è¿­ä»£å®ç°ï¼Œå¯å®ç°åœ¨çº¿å¢é‡å­¦ä¹ </td>
      <td>ä¸éœ€è¦è¿­ä»£</td>
    </tr>
    <tr>
      <td>å½“ç‰¹å¾æ•°$d$å¾ˆå¤§æ—¶ï¼ˆ$10^6$ï¼‰å·¥ä½œè‰¯å¥½</td>
      <td>$d$å¾ˆå¤§æ—¶å¾ˆæ…¢</td>
    </tr>
    <tr>
      <td>ç‰¹å¾éœ€è¦å°ºåº¦è§„èŒƒåŒ–</td>
      <td>ç‰¹å¾ä¸éœ€è¦å°ºåº¦è§„èŒƒåŒ–<sup id="fnref:why-not-scale"><a href="#fn:why-not-scale" class="footnote">7</a></sup></td>
    </tr>
  </tbody>
</table>

<h2 id="section-3">åˆ†ç±»é—®é¢˜</h2>

<p>çº¿æ€§åˆ†ç±»å™¨å’Œçº¿æ€§å›å½’çš„å¯¹æ¯”å¦‚ä¸‹è¡¨ï¼š</p>

<table>
  <thead>
    <tr>
      <th>æŒ‡æ ‡</th>
      <th>çº¿æ€§åˆ†ç±»å™¨</th>
      <th>çº¿æ€§å›å½’</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>$\mathcal Y$</td>
      <td>$\{-1,+1\}$</td>
      <td>$\mathbb R$</td>
    </tr>
    <tr>
      <td>$h(\mathbf x)$</td>
      <td>$\mbox{sign}\left(\mathbf w^T\mathbf x\right)$</td>
      <td>$\mathbf w^T\mathbf x$</td>
    </tr>
    <tr>
      <td>$err(\hat{y},y)$</td>
      <td>$[[\hat{y}\neq y]]$</td>
      <td>$(\hat{y}-y)^2$</td>
    </tr>
    <tr>
      <td>ç®—æ³•å¤æ‚åº¦</td>
      <td>é€šå¸¸æ˜¯NP-hard</td>
      <td>é«˜æ•ˆæ±‚è§£æ–¹æ³•</td>
    </tr>
  </tbody>
</table>

<p>èƒ½å¦åˆ©ç”¨çº¿æ€§å›å½’çš„é«˜æ•ˆï¼Œå€ŸåŠ©$g(\mathbf x)=\mbox{sign}\left(\mathbf w_{LIN}^T\mathbf x\right)$ï¼Œç”¨çº¿æ€§å›å½’è§£å†³åˆ†ç±»é—®é¢˜ï¼Ÿâœ…</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-13-linear-regression-error-compare.png"><img src="/assets/images/2015-01-13-linear-regression-error-compare.png" alt="çº¿æ€§åˆ†ç±»å™¨å’Œçº¿æ€§å›å½’è¯¯å·®æ¯”è¾ƒ" /></a><div class="caption">Figure 3:  çº¿æ€§åˆ†ç±»å™¨å’Œçº¿æ€§å›å½’è¯¯å·®æ¯”è¾ƒ [<a href="/assets/images/2015-01-13-linear-regression-error-compare.png">PNG</a>]</div></div></div>

<p>ä¸Šå›¾å±•ç¤ºäº†ä¸¤ç§æ–¹æ³•è¯¯å·®çš„å¯¹æ¯”ï¼Œ$err_{0/1}\leq err_{sqr}$ï¼Œå¹³æ–¹è¯¯å·®æ˜¯0/1è¯¯å·®çš„ä¸Šé™ã€‚ä»VCç»´çš„ç†è®ºå¯çŸ¥
\[
\mbox{classification }E_{out}(\mathbf w)
\leq \mbox{classification }E_{in}(\mathbf w)+\sqrt{\cdots}
\leq \mbox{regression }E_{in}(\mathbf w)+\sqrt{\cdots}ï¼Œ
\]
in-sampleå›å½’è¯¯å·®ä¹Ÿæ˜¯out-sampleåˆ†ç±»è¯¯å·®çš„ä¸Šé™ï¼Œåšå¥½in-sampleå›å½’è¯¯å·®ä¹Ÿæ˜¯åšå¥½in-sampleåˆ†ç±»è¯¯å·®çš„ä¸€ç§æ–¹æ³•ï¼Œin-sampleå›å½’è¯¯å·®å¾ˆå°æ—¶èƒ½ä¿è¯out-sampleåˆ†ç±»è¯¯å·®ä¹Ÿå¾ˆå°ã€‚ç”±æ­¤å¯è§ï¼Œå¯ç”¨çº¿æ€§å›å½’è§£å†³åˆ†ç±»é—®é¢˜ã€‚</p>

<p>ä¹Ÿå¯ç›´æ¥å°†å›å½’é—®é¢˜è§†ä¸ºåˆ†ç±»é—®é¢˜ï¼Œåªæ˜¯ç”¨$err_{sqr}$å½“ä½œ$\widehat{err}$ä½œä¸º$err_{0/1}$è¯¯å·®çš„è¿‘ä¼¼ã€‚ä¸ºåˆ†ç±»é—®é¢˜é€‰æ‹©ç¨å®½æ¾çš„è¯¯å·®ä¸Šç•Œï¼Œè¿™æ ·å®¹æ˜“æ±‚è§£å‚æ•°ã€‚</p>

<p>åœ¨å¾ˆå¤šæ—¶å€™ï¼Œç”¨çº¿æ€§å›å½’è§£å†³åˆ†ç±»é—®é¢˜æ•ˆæœå°šå¯ã€‚å¦‚æœè¦è®©æ•ˆæœæ›´å¥½ï¼Œå¯å°†$\mathbf w_{LIN}$å½“åšPLAæˆ–pocketç®—æ³•çš„åˆå§‹å€¼$\mathbf w_0$ï¼ŒåŠ é€ŸPLAæˆ–pocketç®—æ³•ã€‚</p>

<h2 id="section-4">å¤šé¡¹å¼å›å½’</h2>

<p>æ„é€ å¤šé¡¹å¼ç‰¹å¾ï¼Œåˆ©ç”¨çº¿æ€§å›å½’æ¨¡å‹è§£å†³éçº¿æ€§é—®é¢˜ï¼Œç§°ä¸º<strong>å¤šé¡¹å¼å›å½’</strong>ï¼ˆpolynomial regressionï¼‰ã€‚ä¾‹å¦‚åˆ©ç”¨$x_1 = x, x_2 = x^2, x_3 = x^3, \ldots $ï¼Œæ„é€ æ–°çš„ç‰¹å¾å‘é‡$\mathbf x$ï¼Œå¸¦å…¥çº¿æ€§å›å½’æ¨¡å‹\eqref{eq:linear-regression-model}æ±‚è§£ã€‚ä»å¦ä¸€ä¸ªè§’åº¦çœ‹ï¼Œå½“ç‰¹å¾æ˜¯å¤šé¡¹å¼æ—¶ï¼Œå¯ç›´æ¥åˆ©ç”¨çº¿æ€§æ¨¡å‹æ±‚è§£ã€‚</p>

<p>å½“å¯¹ç‰¹å¾è¿›è¡Œé«˜æ¬¡å¤šé¡¹å¼å˜æ¢åï¼Œå–å€¼èŒƒå›´å¯èƒ½æ€¥å‰§å˜åŒ–ï¼Œéœ€è¦å¯¹å¤šé¡¹å¼ç‰¹å¾è¿›è¡Œå°ºåº¦å½’ä¸€åŒ–å¤„ç†<a href="#ng_ml_rlrbv_pe_2014">[3, P. 8]</a>ã€‚</p>

<h2 id="section-5">å‚è€ƒèµ„æ–™</h2>

<ol class="bibliography"><li><span id="lin_mlf_linreg_2014">[1]H.-T. Lin, â€œLecture 9: Linear Regression.â€ Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ntumlone">Online</a>]

</li>
<li><span id="ng_ml_linreg_2014">[2]A. Ng, â€œLinear Regression with multiple variables.â€ Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ml">Online</a>]

</li>
<li><span id="ng_ml_rlrbv_pe_2014">[3]A. Ng, â€œProgramming Exercise 5: Regularized Linear Regression and Bias v.s. Variance.â€ Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ml">Online</a>]

</li></ol>

<h3 id="section-6">è„šæ³¨</h3>

<div class="footnotes">
  <ol>
    <li id="fn:how-to-regularize">
      <p>å¦‚ä½•è¿›è¡Œæ­£åˆ™åŒ–ï¼Ÿ <a href="#fnref:how-to-regularize" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:pinv-vs-inv">
      <p>Matlabçš„<code>pinv</code>å’Œ<code>inv</code>æœ‰ä½•åŒºåˆ«ï¼Ÿ <a href="#fnref:pinv-vs-inv" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:some-E-in">
      <p>ä¸ºä»€ä¹ˆVCç»´è€ƒå¯Ÿçš„æ˜¯ä¸ªåˆ«çš„$E_{in}$ï¼Ÿ <a href="#fnref:some-E-in" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:hat-matrix-properties">
      <p>å¸½çŸ©é˜µçš„æ€§è´¨ï¼ˆå¯ä»æ–‡ä¸­å›¾ç¤ºçš„è§’åº¦ç†è§£ï¼‰ï¼šï¼ˆ1ï¼‰$\mathbf H$æ˜¯å¯¹ç§°çš„ï¼›ï¼ˆ2ï¼‰$\mathbf H^2=\mathbf H$ï¼›ï¼ˆ3ï¼‰$(\mathbf I-\mathbf H)^2=\mathbf I-\mathbf H$ã€‚ <a href="#fnref:hat-matrix-properties" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:andrew-simultaneous-update">
      <p>äº‹å®ä¸Šï¼Œä¸åŒæ—¶æ›´æ–°çš„æƒ…å†µå¾ˆå°‘å‘ç”Ÿï¼Œå› ä¸ºåœ¨æ›´æ–°æ¯ä¸ª$w_i$å‰ï¼Œå·²ç»ç”¨$\mathbf w$è®¡ç®—è¿‡äº†$E_{in}(\mathbf w)$ï¼Œæ›´æ–°è¿‡ç¨‹ä¸­ï¼Œä¸å†éœ€è¦é‡å¤è®¡ç®—$E_{in}(\mathbf w)$ã€‚ <a href="#fnref:andrew-simultaneous-update" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:no-local-optima">
      <p>è¿™æ˜¯çœŸçš„å—ï¼Ÿ <a href="#fnref:no-local-optima" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:why-not-scale">
      <p>ä¸ºä»€ä¹ˆè§£ææ–¹æ³•ä¸éœ€è¦è§„èŒƒåŒ–ç‰¹å¾ï¼Ÿ <a href="#fnref:why-not-scale" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>æ”¯æŒå‘é‡æœºï¼ˆ6ï¼‰ï¼šæ”¯æŒå‘é‡å›å½’</title>
      <link href="http://qianjiye.de/2015/01/svm-support-vector-regression" />
      <pubdate>2015-01-12T18:31:45+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/svm-support-vector-regression</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">è„Šå›å½’</h2>

<p>æœ‰æ­£åˆ™åŒ–é¡¹çš„å›å½’ç§°ä¸º<strong>è„Šå›å½’</strong>ï¼ˆridge regressionï¼‰ã€‚è„Šå›å½’çš„æ ¸æ¨¡å‹æœ‰è§£æè§£ä¹ˆï¼Ÿ</p>

<p>è„Šå›å½’çš„æœ€ä¼˜åŒ–æ¨¡å‹ä¸º
\[
\min_{\mathbf w}\left({\lambda\over N}\mathbf w^T\mathbf w+{1\over N}\sum_{n=1}^N\left(y_n-\mathbf w^T\mathbf z_n\right)^2\right)ï¼Œ
\]
æ ¹æ®è¡¨ç¤ºå®šç†å¯çŸ¥ï¼Œå­˜åœ¨å½¢å¦‚$\mathbf w_*=\sum_{n=1}^N\beta_n\mathbf z_n$çš„æœ€ä¼˜è§£ï¼Œå°†å…¶å¸¦å…¥å¹¶è¡¨ç¤ºä¸ºæ ¸å½¢å¼
\begin{equation}
\min_\beta\left({\lambda\over N}\sum_{n=1}^N\sum_{m=1}^N\beta_n\beta_mK(\mathbf x_n,\mathbf x_m)+{1\over N}\sum_{n=1}^N\left(y_n-\sum_{n=1}^N\beta_mK(\mathbf x_n,\mathbf x_m)\right)\right)ã€‚
\end{equation}
<strong>è„Šå›å½’çš„æ ¸æ¨¡å‹</strong>å°±æ˜¯åˆ©ç”¨è¡¨ç¤ºå®šç†å°†è„Šå›å½’æ ¸åŒ–ã€‚ç›®æ ‡å‡½æ•°å†™ä¸ºçŸ©é˜µçš„å½¢å¼
\begin{equation}
E_{aug}(\boldsymbol\beta)={\lambda\over N}\boldsymbol\beta^T\mathbf K\boldsymbol\beta + {1\over N}\left(\boldsymbol\beta^T\mathbf K^T\mathbf K\boldsymbol\beta-2\boldsymbol\beta^T\mathbf K^T\mathbf y + \mathbf y^T\mathbf y\right)ï¼Œ
\end{equation}
æ— çº¦æŸæœ€ä¼˜åŒ–é—®é¢˜å¯ä»¥é€šè¿‡
\[
\nabla E_{aug}(\boldsymbol\beta)={2\over N}\left(\lambda\mathbf K^T\mathbf I\boldsymbol\beta+\mathbf K^T\mathbf K\boldsymbol\beta-\mathbf K^T\right)={2\over N}\mathbf K^T\left((\lambda\mathbf I+\mathbf K)\boldsymbol\beta-\mathbf y\right)
\]
ä»¤$\nabla E_{aug}(\boldsymbol\beta)=0$æ±‚è§£ï¼Œ
\begin{equation}
\boldsymbol\beta=(\lambda\mathbf I+\mathbf K)^{-1}\mathbf yã€‚
\end{equation}
æ ¹æ®Merceræ¡ä»¶å¯çŸ¥$\mathbf K$åŠæ­£å®šï¼Œå¹¶ä¸”$\lambda&gt;0$ï¼Œå› æ­¤çŸ©é˜µæ€»å¯é€†ã€‚ç¨ å¯†çŸ©é˜µæ±‚é€†çš„æ—¶é—´å¤æ‚åº¦ä¸º$O\left(N^3\right)$ã€‚</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-12-svm-support-vector-regression-ridge-regression-compare.png"><img src="/assets/images/2015-01-12-svm-support-vector-regression-ridge-regression-compare.png" alt="ï¼»å·¦ï¼½ï¼šè„Šå›å½’çš„çº¿æ€§æ¨¡å‹ï¼›ï¼»å³ï¼½ï¼šè„Šå›å½’çš„æ ¸æ¨¡å‹" /></a><div class="caption">Figure 1:  ï¼»å·¦ï¼½ï¼šè„Šå›å½’çš„çº¿æ€§æ¨¡å‹ï¼›ï¼»å³ï¼½ï¼šè„Šå›å½’çš„æ ¸æ¨¡å‹ [<a href="/assets/images/2015-01-12-svm-support-vector-regression-ridge-regression-compare.png">PNG</a>]</div></div></div>

<p>ä¸Šå›¾ä¸­çš„è“çº¿æ˜¯è„Šå›å½’çš„æ•ˆæœã€‚çº¿æ€§æ¨¡å‹ä¸æ ¸æ¨¡å‹çš„é€‰æ‹©æ˜¯é€Ÿåº¦ä¸æ•ˆç‡çš„æŠ˜ä¸­æƒè¡¡ï¼Œå®ƒä»¬ä¹‹é—´çš„å¯¹æ¯”å¦‚ä¸‹è¡¨ï¼š</p>

<table>
  <thead>
    <tr>
      <th>çº¿æ€§æ¨¡å‹</th>
      <th>æ ¸æ¨¡å‹</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>$\mathbf w = (\lambda\mathbf I+\mathbf X^TX)^{-1}\mathbf X^T\mathbf y$</td>
      <td>$\boldsymbol\beta=(\lambda\mathbf I+\mathbf K)^{-1}\mathbf y$</td>
    </tr>
    <tr>
      <td>åŠŸèƒ½å—é™</td>
      <td>é€šè¿‡$K$å®ç°å¼ºå¤§çš„åŠŸèƒ½</td>
    </tr>
    <tr>
      <td>è®­ç»ƒæ—¶é—´å¤æ‚åº¦ä¸º$O\left(d^3+d^2N\right)$</td>
      <td>è®­ç»ƒæ—¶é—´å¤æ‚åº¦ä¸º$O\left(N^3\right)$</td>
    </tr>
    <tr>
      <td>é¢„æµ‹æ—¶é—´å¤æ‚åº¦ä¸º$O(d)$ï¼Œå½“$N\gg d$æ—¶æ•ˆç‡é«˜</td>
      <td>é¢„æµ‹æ—¶é—´å¤æ‚åº¦ä¸º$O(N)$ï¼Œå½“è®­ç»ƒæ ·æœ¬å¤§æ—¶æ•ˆç‡ä½</td>
    </tr>
  </tbody>
</table>

<p>å½“å‚æ•°è·å¾—åï¼Œå›å½’å‡½æ•°å°±å¯ä»¥ç”¨æ ¸è¡¨ç¤ºä¸º
\begin{equation}
g(\mathbf x)=\sum_{n=1}^N\beta_nK\left(\mathbf x_n, \mathbf x\right)ã€‚
\end{equation}</p>

<h2 id="section-1">æœ€å°äºŒä¹˜æ”¯æŒå‘é‡æœº</h2>

<p><strong>æœ€å°äºŒä¹˜æ”¯æŒå‘é‡æœº</strong>ï¼ˆLSSVMï¼Œleast-squares SVMï¼‰å°±æ˜¯å°†è„Šå›å½’çš„æ ¸æ¨¡å‹ç”¨äºåˆ†ç±»ã€‚</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-12-svm-support-vector-regression-svm-vs-lssvm.png"><img src="/assets/images/2015-01-12-svm-support-vector-regression-svm-vs-lssvm.png" alt="æœ€å°äºŒä¹˜ä¸soft-marginæ”¯æŒå‘é‡æœºçš„å¯¹æ¯”" /></a><div class="caption">Figure 2:  æœ€å°äºŒä¹˜ä¸soft-marginæ”¯æŒå‘é‡æœºçš„å¯¹æ¯” [<a href="/assets/images/2015-01-12-svm-support-vector-regression-svm-vs-lssvm.png">PNG</a>]</div></div></div>

<p>ä¸Šå›¾å¯ä»¥çœ‹å‡ºï¼Œæœ€å°äºŒä¹˜ä¸soft-marginæ”¯æŒå‘é‡æœºçš„åˆ†ç±»é¢å¾ˆç›¸ä¼¼ï¼Œä½†æ˜¯LSSVMçš„æ”¯æŒå‘é‡è¦å¤šå¾—å¤šï¼Œé¢„æµ‹é€Ÿåº¦ä¼šå¾ˆæ…¢ã€‚</p>

<p>LSSVMå’Œlogisticå›å½’çš„æ ¸æ¨¡å‹å¾—åˆ°çš„å‚æ•°$\boldsymbol\beta$æ˜¯ç¨ å¯†çš„ï¼Œæ ‡å‡†æ”¯æŒå‘é‡æœºçš„å‚æ•°$\boldsymbol\alpha$æ˜¯ç¨€ç–çš„ã€‚èƒ½å¦å¾—åˆ°åƒæ ‡å‡†æ”¯æŒå‘é‡æœºä¸€æ ·ç¨€ç–çš„$\boldsymbol\beta$å‘¢ï¼Ÿ</p>

<h2 id="tube">tubeå›å½’</h2>

<p>å®šä¹‰tubeå›å½’çš„è¯¯å·®ä¸º
\begin{equation}
err(y, s) = \max(0, \lvert s-y\rvert-\epsilon)ï¼Œ
\end{equation}
åœ¨tubeåŒºåŸŸå†…ä¸è®¡è¯¯å·®ï¼Œåœ¨è¯¥åŒºåŸŸå¤–åˆ°tubeçš„è·ç¦»è®°ä¸ºè¯¯å·®ã€‚</p>

<div class="image_line" id="tube-error-illustration"><div class="image_card"><a href="/assets/images/2015-01-12-svm-support-vector-regression-tube-vs-square-error.png"><img src="/assets/images/2015-01-12-svm-support-vector-regression-tube-vs-square-error.png" alt="tubeä¸å¹³æ–¹è¯¯å·®å¯¹æ¯”" /></a><div class="caption">Figure 3:  tubeä¸å¹³æ–¹è¯¯å·®å¯¹æ¯” [<a href="/assets/images/2015-01-12-svm-support-vector-regression-tube-vs-square-error.png">PNG</a>]</div></div></div>

<p>å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œtubeä¸å¹³æ–¹è¯¯å·®å¾ˆç›¸ä¼¼ï¼Œå°¤å…¶æ˜¯åœ¨$\lvert s-y\rvert$å¾ˆå°çš„åŒºåŸŸå†…ï¼Œå½“$\lvert s-y\rvert$å¾ˆå¤§æ—¶ï¼Œtubeè¯¯å·®ä¸å¦‚å¹³æ–¹è¯¯å·®å˜åŒ–é™¡å³­ï¼Œå› æ­¤å—å™ªå£°å½±å“æ›´å°ã€‚</p>

<p>åŸºäºtubeè¯¯å·®çš„æ¨¡å‹èƒ½å¦å¾—åˆ°ç¨€ç–çš„ç³»æ•°å‘¢ï¼Ÿ</p>

<h2 id="section-2">æ”¯æŒå‘é‡å›å½’</h2>

<p>åŸºäº$L_2$æ­£åˆ™åŒ–çš„tubeå›å½’æ¨¡å‹ä¸º
\begin{equation*}
\min\limits_{\mathbf w}\left({\lambda\over N}\mathbf w^T\mathbf w+{1\over N}\sum_{n=1}^N\max\left(0, \left\lvert \mathbf w^T\mathbf z_n-y_n\right\rvert-\epsilon\right)\right)ï¼Œ
\end{equation*}
è™½æ— çº¦æŸï¼Œä½†$\max$å¯¼è‡´ä¸å¯å¾®ï¼›åˆ©ç”¨è¡¨ç¤ºå®šç†å¯æ ¸åŒ–ï¼Œä½†æ— æ³•æ˜ç¡®å¾—åˆ°ç¨€ç–çš„ç³»æ•°ã€‚ä»¿ç…§<a href="/2015/01/svm-kernel-logistic-regression/#mjx-eqn-equniform-soft-margin-svm">æ— çº¦æŸå½¢å¼</a>çš„soft-marginæ”¯æŒå‘é‡æœºï¼Œåˆ†ç¦»å‡º$b$åæ”¹å†™ä¸º
\begin{equation*}
\min\limits_{b,\mathbf w}\left({1\over 2}\mathbf w^T\mathbf w+C\sum_{n=1}^N\max\left(0, \left\lvert \mathbf w^T\mathbf z_n+b-y_n\right\rvert-\epsilon\right)\right)ï¼Œ
\end{equation*}
è™½ç„¶ä¸å¯å¾®ï¼Œä½†æ˜¯QPé—®é¢˜ï¼›å¯¹å¶é—®é¢˜å¯æ ¸åŒ–ï¼ŒKKTæ¡ä»¶èƒ½å¾—åˆ°ç³»æ•°ç¨€ç–ã€‚å†å¯¹æ¯”<a href="/2015/01/svm-soft-margin-svm/#mjx-eqn-eqsoft-margin-primal-svm">çº¦æŸå½¢å¼</a>çš„soft-marginæ”¯æŒå‘é‡æœºï¼Œæ”¹å†™ä¸ºå¸¦çº¦æŸçš„ä¼˜åŒ–é—®é¢˜
\begin{equation*}
\begin{aligned}
\min\limits_{b,\mathbf w,\boldsymbol\xi}&amp;\quad\frac{1}{2}\mathbf w^T\mathbf w + C\sum_{n=1}^N\xi_n\\
\mbox{s.t.}&amp;\quad \left\lvert\mathbf w^T\mathbf z_n+b-y_n\right\rvert\leq \epsilon+\xi_n\\
&amp;\quad\xi_n\geq 0 \mbox{ for all }nï¼Œ
\end{aligned}
\end{equation*}
çº¦æŸæ¡ä»¶çº¿æ€§åŒ–
\begin{equation}
\begin{aligned}
\min\limits_{b,\mathbf w,\boldsymbol\xi^\vee,\boldsymbol\xi^\wedge}&amp;\quad\frac{1}{2}\mathbf w^T\mathbf w + C\sum_{n=1}^N\left(\xi_n^\vee+\xi_n^\wedge\right)\\
\mbox{s.t.}&amp;\quad -\epsilon-\xi_n^\vee\leq y_n - \mathbf w^T\mathbf z_n-b\leq \epsilon+\xi_n^\wedge\\
&amp;\quad\xi_n^\vee\geq 0,\xi_n^\wedge\geq 0\mbox{ for all }nï¼Œ
\end{aligned}
\end{equation}
è¿™å°±æ˜¯æ ‡å‡†çš„<strong>æ”¯æŒå‘é‡å›å½’</strong>ï¼ˆSVRï¼Œsupport vector regressionï¼‰åŸé—®é¢˜ï¼Œ$\xi_n^\vee$å’Œ$\xi_n^\wedge$åˆ†åˆ«è®°å½•tubeä¸‹å±Šå’Œä¸Šç•Œè¿è§„ï¼Œå¦‚<a href="#tube-error-illustration">ä¸Šå›¾å·¦</a>æ‰€ç¤ºçš„åˆ†ç•Œçº¿ä¸‹è¾¹å’Œä¸Šè¾¹æ ‡çº¢çš„çº¿æ®µã€‚é€šè¿‡$C$å¯¹æ­£åˆ™åŒ–å’Œtubeè¿è§„è¿›è¡ŒæŠ˜ä¸­ï¼Œè°ƒèŠ‚å‚æ•°$\epsilon$å¯æ§åˆ¶tubeçš„é«˜åº¦ã€‚è¯¥QPæ¨¡å‹æœ‰$\tilde d+1+2N$ä¸ªå˜é‡ï¼Œ$2N+2N$ä¸ªçº¦æŸæ¡ä»¶ã€‚</p>

<p>å°†æ”¯æŒå‘é‡å›å½’çš„åŸé—®é¢˜è½¬æˆå¯¹å¶é—®é¢˜ï¼Œå¯ç§»é™¤å¯¹$\tilde d$çš„ä¾èµ–ã€‚</p>

<h2 id="section-3">æ”¯æŒå‘é‡å›å½’çš„å¯¹å¶æ¨¡å‹</h2>

<p>é€šè¿‡æ‹‰æ ¼æœ—æ—¥ä¹˜å­æ³•çš„KKTæ¡ä»¶${\partial\mathcal L\over\partial\mathbf w}=0$å¯å¾—
\begin{equation}
\mathbf w = \sum_{n=1}^N\left(\alpha_n^\wedge-\alpha_n^\vee\right)\mathbf z_n = \sum_{n=1}^N\beta_n\mathbf z_nï¼Œ
\end{equation}
é€šè¿‡${\partial\mathcal L\over\partial b}=0$å¯å¾—
\[
\sum_{n=1}^N\left(\alpha_n^\wedge-\alpha_n^\vee\right)ï¼0ï¼Œ
\]
äº’è¡¥æ¾å¼›æ¡ä»¶ï¼ˆcomplementary slacknessï¼‰ä¸º
\begin{equation}
\left\{
\begin{aligned}
\alpha_n^\wedge\left(\epsilon+\xi_n^\wedge-y_n+\mathbf w^T\mathbf z_n+b\right)=&amp;0\\
\alpha_n^\vee\left(\epsilon+\xi_n^\vee+y_n-\mathbf w^T\mathbf z_n-b\right)=&amp;0ã€‚
\end{aligned}
\right.
\label{eq:complementary-slackness-svm-regession}
\end{equation}</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-01-12-svm-support-vector-regression-primal-vs-dual-QP.png"><img src="/assets/images/2015-01-12-svm-support-vector-regression-primal-vs-dual-QP.png" alt="QPåŸé—®é¢˜ä¸å¯¹å¶é—®é¢˜çš„å¯¹æ¯”" /></a><div class="caption">Figure 4:  QPåŸé—®é¢˜ä¸å¯¹å¶é—®é¢˜çš„å¯¹æ¯” [<a href="/assets/images/2015-01-12-svm-support-vector-regression-primal-vs-dual-QP.png">PNG</a>]</div></div></div>

<p>ä¸Šå›¾å·¦ä¸Šå’Œå·¦ä¸‹åˆ†åˆ«è¡¨ç¤ºsoft-marginæ”¯æŒå‘é‡æœºçš„åŸé—®é¢˜å’Œå¯¹å¶é—®é¢˜çš„QPæ¨¡å‹ï¼›ä¸Šå›¾å³ä¸Šå’Œå³ä¸‹åˆ†åˆ«è¡¨ç¤ºæ”¯æŒå‘é‡å›å½’çš„åŸé—®é¢˜å’Œå¯¹å¶é—®é¢˜çš„QPæ¨¡å‹ã€‚ä¸Šå›¾ä¸­ï¼Œç›¸åŒé¢œè‰²çš„ç¬¦å·å±•ç¤ºäº†å¦‚ä½•ä»åŸé—®é¢˜å˜åŒ–åˆ°å¯¹å¶é—®é¢˜ã€‚</p>

<p>å½“æ•°æ®ç‚¹ä½äºtubeä¸­æœ‰$\left\lvert\mathbf w^T\mathbf z_n+b-y_n\right\rvert&lt;\epsilon$ï¼Œä¸è®¡è¯¯å·®ï¼Œ$\xi_n^\wedge=\xi_n^\vee=0$ï¼Œæ ¹æ®äº’è¡¥æ¾å¼›æ¡ä»¶\eqref{eq:complementary-slackness-svm-regession}å¯çŸ¥
\[
\left\{
\begin{aligned}
\epsilon+\xi_n^\wedge-y_n+\mathbf w^T\mathbf z_n+b\neq &amp;0\\
\epsilon+\xi_n^\vee+y_n-\mathbf w^T\mathbf z_n-b\neq &amp;0ï¼Œ
\end{aligned}
\right.
\]
ä»¥åŠ$\alpha_n^\wedge=\alpha_n^\veeï¼0$ï¼Œå› æ­¤å¯å¾—$\beta_n=0$ã€‚ç”±æ­¤å¯çŸ¥ï¼Œæ”¯æŒå‘é‡å›å½’é—®é¢˜ä¸­$\beta_n\neq 0$çš„æ”¯æŒå‘é‡åˆšå¥½ä½äºtubeçš„è¾¹ç•Œä¸Šæˆ–åœ¨tubeä¹‹å¤–ã€‚</p>

<p>å‚è€ƒ<a href="/2015/01/svm-soft-margin-svm/#mjx-eqn-eqsoft-margin-complementary-slackness">soft-marginæ”¯æŒå‘é‡æœº</a>å¯å¾—
\begin{equation}
b=
\left\{
\begin{aligned}
y_n-\mathbf w^T\mathbf z_n-\epsilon&amp;\quad(0&lt;\alpha_n^\wedge&lt;C)\\
y_n-\mathbf w^T\mathbf z_n+\epsilon&amp;\quad(0&lt;\alpha_n^\vee&lt;C)ã€‚
\end{aligned}
\right.
\end{equation}</p>

]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>æ”¯æŒå‘é‡æœºï¼ˆ5ï¼‰ï¼šæ ¸logisticå›å½’</title>
      <link href="http://qianjiye.de/2015/01/svm-kernel-logistic-regression" />
      <pubdate>2015-01-09T15:01:15+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/svm-kernel-logistic-regression</guid>
      <content:encoded>&lt;![CDATA[<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-09-svm-kernel-logistic-regression-SVMs.png"><img src="/assets/images/2015-01-09-svm-kernel-logistic-regression-SVMs.png" alt="4ç§å½¢å¼çš„æ”¯æŒå‘é‡æœº" /></a><div class="caption">Figure 1:  4ç§å½¢å¼çš„æ”¯æŒå‘é‡æœº [<a href="/assets/images/2015-01-09-svm-kernel-logistic-regression-SVMs.png">PNG</a>]</div></div></div>

<h2 id="section">æ”¯æŒå‘é‡æœºçš„æ­£åˆ™åŒ–å½¢å¼</h2>

<p>å›é¡¾<a href="/2015/01/svm-soft-margin-svm/#mjx-eqn-eqsoft-margin-primal-svm">soft-marginæ”¯æŒå‘é‡æœº</a>ï¼Œå½“è¿åè¾¹ç•Œçš„æ—¶å€™$\xi_n=1-y_n\left(\mathbf w^T\mathbf z_n + b\right)$ï¼Œå½“æ²¡æœ‰è¿åè¾¹ç•Œçš„æ—¶å€™$\xi_n = 0$ï¼Œè¾¹ç•Œè¿æ³•çš„æƒ…å†µå¯ä»¥ç»Ÿä¸€å®šä¹‰ä¸º$\xi_n=\max\left(1-y_n\left(\mathbf w^T\mathbf z_n + b\right), 0\right)$ï¼Œäºæ˜¯æ— çº¦æŸå½¢å¼çš„soft-marginæ”¯æŒå‘é‡æœºä¸º
\begin{equation}
\min\limits_{b,\mathbf w}\left({1\over 2}\mathbf w^T\mathbf w + C\sum_{n=1}^N\max\left(1-y_n\left(\mathbf w^T\mathbf z_n + b\right), 0\right)\right)ï¼Œ
\label{eq:uniform-soft-margin-svm}
\end{equation}
å¯ä»¥ç®€å†™ä¸º
\[
\min\limits_{b,\mathbf w}\left({1\over 2}\mathbf w^T\mathbf w + C\sum\widehat{\mbox{err}}\right)ã€‚
\]
è¿™æ˜¯ç›®æ ‡å‡½æ•°çš„æ­£åˆ™åŒ–å½¢å¼è¡¨ç¤ºæ–¹æ³•ï¼Œsoft-marginå¯ä»¥çœ‹ä½œä¸€ç§ç‰¹æ®Šçš„è¯¯å·®$\widehat{\mbox {err}}$åº¦é‡ã€‚$L_2$æ­£åˆ™åŒ–æ˜¯å¯¹$\mathbf w$é•¿åº¦çš„çº¦æŸ
\[
\min\limits_{b,\mathbf w}\left({\lambda\over N}\mathbf w^T\mathbf w + {1\over N}\sum\mbox{err}\right)ã€‚
\]</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-09-svm-kernel-logistic-regression-regularized-model.png"><img src="/assets/images/2015-01-09-svm-kernel-logistic-regression-regularized-model.png" alt="SVMä¸æ­£åˆ™åŒ–" /></a><div class="caption">Figure 2:  SVMä¸æ­£åˆ™åŒ– [<a href="/assets/images/2015-01-09-svm-kernel-logistic-regression-regularized-model.png">PNG</a>]</div></div></div>

<p>åŠ å…¥äº†å¤§åˆ†ç±»çš„è¾¹ç•Œé™åˆ¶ï¼Œå¯ä»¥å¾—åˆ°æ›´å°‘çš„åˆ†ç±»æƒ…å†µï¼Œä¹Ÿå¯ä»¥é€šè¿‡$L_2$æ­£åˆ™åŒ–å®ç°ã€‚
ä»ä¸Šå›¾å¯¹æ¯”æ­£åˆ™åŒ–æ–¹æ³•å¯çŸ¥ï¼Œæ”¯æŒå‘é‡æœºå¯ä»¥çœ‹ä½œä¸ºç‰¹æ®Šçš„æ­£åˆ™åŒ–æ–¹æ³•ã€‚å¤§çš„$C$ï¼Œå¯¹åº”äºå°çš„$\lambda$ï¼Œæ›´å¼±çš„æ­£åˆ™åŒ–ã€‚</p>

<h2 id="section-1">è¯¯å·®åº¦é‡</h2>

<p>ä»¤çº¿æ€§é¡¹è¾“å‡º$s=\mathbf w^T\mathbf z_n + b$ï¼Œæ„ŸçŸ¥å™¨ç®—æ³•ã€æ”¯æŒå‘é‡æœºå’Œlogisticå›å½’çš„è¯¯å·®åº¦é‡ä¸º
\begin{equation}
\left\{
\begin{aligned}
err_{0/1}(s, y)&amp;=[[\mbox{sign}(ys)\neq 1]]\\
\widehat{err}_{SVM}(s, y)&amp;=\max(1-ys, 0)\\
err_{SCE}(s, y)&amp;=\log(1+\exp(-ys))ã€‚
\end{aligned}
\right.
\end{equation}</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-09-svm-kernel-logistic-regression-error_compare.png"><img src="/assets/images/2015-01-09-svm-kernel-logistic-regression-error_compare.png" alt="è¯¯å·®åº¦é‡æ¯”è¾ƒ" /></a><div class="caption">Figure 3:  è¯¯å·®åº¦é‡æ¯”è¾ƒ [<a href="/assets/images/2015-01-09-svm-kernel-logistic-regression-error_compare.png">PNG</a>]</div></div></div>

<p>å‡ ç§è¯¯å·®æ›²çº¿å¯¹æ¯”å¦‚ä¸Šå›¾æ‰€ç¤ºã€‚å…¶ä¸­ï¼Œæ”¯æŒå‘é‡æœºçš„è¿™ç§è¯¯å·®åº¦é‡æ–¹å¼é€šå¸¸ç§°ä¸ºhinge error measureã€‚æ”¯æŒå‘é‡æœºå’Œlogisticå›å½’çš„è¯¯å·®æ˜¯0/1è¯¯å·®çš„ä¸Šç•Œï¼Œå¯¹äºåˆ†ç±»é—®é¢˜ï¼Œé€šè¿‡ä¸Šç•Œçš„æœ€å°åŒ–ï¼Œé—´æ¥åšå¥½0/1è¯¯å·®çš„æœ€ä¼˜åŒ–ã€‚ä»è¯¯å·®æ›²çº¿è¿˜å¯ä»¥çœ‹å‡ºï¼Œæ”¯æŒå‘é‡æœºå’Œ$L_2$æ­£åˆ™åŒ–çš„logisticçš„è¯¯å·®åº¦é‡éå¸¸ç›¸ä¼¼ã€‚è¿™å‡ ç§åˆ†ç±»å™¨çš„æ¯”è¾ƒå¦‚ä¸‹ï¼š</p>

<table>
  <thead>
    <tr>
      <th>ç®—æ³•</th>
      <th>ä¼˜åŒ–æ–¹æ³•</th>
      <th>ä¼˜åŠ¿</th>
      <th>åŠ£åŠ¿</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>æ„ŸçŸ¥å™¨ç®—æ³•</td>
      <td>æœ€å°åŒ–$err_{0/1}$</td>
      <td>çº¿æ€§å¯åˆ†æ—¶æ•ˆç‡è¾ƒé«˜</td>
      <td>åªé€‚ç”¨çº¿æ€§å¯åˆ†ï¼Œå¦åˆ™é‡‡ç”¨pocketç®—æ³•</td>
    </tr>
    <tr>
      <td>soft-marginæ”¯æŒå‘é‡æœº</td>
      <td>QPæœ€å°åŒ–è¯¯å·®$err_{0/1}$</td>
      <td>å®¹æ˜“ä¼˜åŒ–ï¼Œç†è®ºåŸºç¡€è¾ƒå¥½</td>
      <td>å¯¹äºè´Ÿå€¼å¾ˆå¤§çš„è¯¯å·®ï¼Œæ˜¯$err_{0/1}$å¾ˆæ¾çš„ä¸Šç•Œ</td>
    </tr>
    <tr>
      <td>æ­£åˆ™åŒ–logisticå›å½’</td>
      <td>GDï¼SGDæœ€å°åŒ–è¯¯å·®$err_{SCE}$</td>
      <td>å®¹æ˜“ä¼˜åŒ–ï¼Œæ­£åˆ™åŒ–æ§åˆ¶æ¨¡å‹</td>
      <td>å¯¹äºè´Ÿå€¼å¾ˆå¤§çš„è¯¯å·®ï¼Œæ˜¯$err_{0/1}$å¾ˆæ¾çš„ä¸Šç•Œ</td>
    </tr>
  </tbody>
</table>

<p>ä»æ¯”è¾ƒå¯ä»¥çœ‹å‡ºï¼Œlogisticå›å½’æ˜¯soft-marginæ”¯æŒå‘é‡æœºçš„è¿‘ä¼¼ã€‚</p>

<h2 id="section-2">æ”¯æŒå‘é‡æœºçš„æ¦‚ç‡æ¨¡å‹</h2>

<p>å¦‚ä½•è®©æ”¯æŒå‘é‡æœºè¾“å‡º$[0,1]$ä¹‹é—´çš„æ¦‚ç‡ï¼Ÿ</p>

<p>ä¸€ç§æ€è·¯æ˜¯å°†æ”¯æŒå‘é‡æœºçš„å‚æ•°$\mathbf w_{SVM}$å’Œ$b_{SVM}$ä½œä¸ºlogisticå›å½’ä¸­çº¿æ€§åˆ¤åˆ«éƒ¨åˆ†çš„å‚æ•°
$
g(\mathbf x) = \theta\left(\mathbf w_{SVM}^T\mathbf x + b_{SVM}\right)
$ï¼Œ
ç›´æ¥åˆ©ç”¨æ”¯æŒå‘é‡æœºå’Œlogisticå›å½’ã€‚è¿™åœ¨å®é™…åº”ç”¨ä¸­è¡¨ç°å°šä½³ï¼Œä½†ä¸§å¤±äº†logisticå›å½’çš„ä¼˜è‰¯ç‰¹æ€§ï¼ˆæ¯”å¦‚maxmum likehoodï¼‰ã€‚</p>

<p>å¦ä¸€ç§æ€è·¯å°†å‘æ”¯æŒå‘é‡æœºçš„å‚æ•°$\mathbf w_{SVM}$å’Œ$b_{SVM}$å½“ä½œlogisticçš„èµ·å§‹ç‚¹ï¼Œæœ€ç»ˆå¾—åˆ°logisticå›å½’æ¨¡å‹ã€‚è¿™å’Œç›´æ¥åˆ©ç”¨logisticç»“æœå·®ä¸å¤šï¼Œè¿˜ä¸§å¤±äº†æ”¯æŒå‘é‡æœºæ ¸æ–¹æ³•ç­‰ä¼˜è‰¯ç‰¹æ€§ã€‚</p>

<p>å¦‚ä½•èåˆæ”¯æŒå‘é‡æœºå’Œlogisticå›å½’çš„ä¼˜ç‚¹ï¼Ÿ</p>

<p>ç»„åˆlogisticå›å½’å’Œæ”¯æŒå‘é‡æœº
\begin{equation}
g(\mathbf x) = \theta\left(A\left(\mathbf w_{SVM}^T\mathbf \Phi(\mathbf x) + b_{SVM}\right)+B\right)ï¼Œ
\label{eq:mixture-svm-logistic-model}
\end{equation}
è¿™æ ·æ—¢èåˆäº†æ”¯æŒå‘é‡æœºçš„æ ¸ç‰¹æ€§ï¼Œåˆé€šè¿‡$A$å’Œ$B$ä¸¤ä¸ªè‡ªç”±åº¦è°ƒèŠ‚åˆ†ç±»è¶…å¹³é¢é€‚åˆæœ€å¤§ä¼¼ç„¶ã€‚å¦‚æœ$A&gt;0$ï¼Œè¡¨ç¤ºæ”¯æŒå‘é‡æœºå¾—åˆ°çš„$\mathbf w_{SVM}$è¾ƒå¥½ï¼›å¦‚æœ$B\approx 0$ï¼Œè¡¨ç¤ºæ”¯æŒå‘é‡æœºå¾—åˆ°çš„$b_{SVM}$è¾ƒå¥½ã€‚æ–°çš„logisticé—®é¢˜å°±å˜ä¸ºäº†
\begin{equation}
\min_{A, B}{1\over N}\sum_{n=1}^N\log\left(1+\exp\left(-y_n\left(A\left(\mathbf w_{SVM}^T\mathbf \Phi(\mathbf x_n) + b_{SVM}\right)+B\right)\right)\right)ï¼Œ
\end{equation}
è¯¥æ¨¡å‹å¯ä»¥åˆ†ä¸º2é˜¶æ®µï¼Œé¦–å…ˆåˆ©ç”¨æ”¯æŒå‘é‡æœºå¾—åˆ°1ç»´ç‰¹å¾ï¼Œç„¶åé‡‡ç”¨ç®€å•çš„logisticæ¨¡å‹ï¼Œè¿™ç§°ä¸º<strong>æ”¯æŒå‘é‡æœºçš„Plattæ¦‚ç‡æ¨¡å‹</strong>ï¼š</p>

<ol>
  <li>å…ˆåœ¨æ•°æ®é›†ä¸Š$\mathcal D$ä¸Šåˆ©ç”¨æ”¯æŒå‘é‡æœºå¾—åˆ°æ¨¡å‹å‚æ•°$\mathbf w_{SVM}$å’Œ$b_{SVM}$ï¼ˆæˆ–è€…$\boldsymbol\alpha$ï¼‰ï¼Œå†è¿›è¡Œå˜æ¢$\mathbf zâ€™_n=\mathbf w_{SVM}^T\mathbf \Phi(\mathbf x_n) + b_{SVM}$ï¼›</li>
  <li>åœ¨$\{\left(\mathbf zâ€™_n, y_n\right)\}_{n=1}^N$ä¸Šå¾—åˆ°logisticæ¨¡å‹çš„å‚æ•°$A,B$ï¼›</li>
  <li>å°†å…¬å¼\eqref{eq:mixture-svm-logistic-model}çš„ç»“æœä½œä¸ºæ¨¡å‹è¾“å‡ºã€‚</li>
</ol>

<p>ä»æ¨¡å‹å¯ä»¥çœ‹å‡ºï¼Œè¿™å¹¶ä¸æ˜¯ä¸¥æ ¼çš„$\mathcal Z$ç©ºé—´logisticå›å½’ã€‚</p>

<h2 id="logistic">æ ¸logisticå›å½’</h2>

<p>æœ€ä½³çš„$\mathbf w$æ˜¯$\mathbf z_n$çš„çº¿æ€§ç»„åˆï¼Œè¿™æ˜¯èƒ½ä½¿ç”¨æ ¸æ–¹æ³•çš„å…³é”®ã€‚</p>

<p>ä»SGDæ¥çœ‹ï¼Œlogisticå›å½’çš„$\mathbf w$ä¹Ÿæ˜¯$\mathbf z_n$çš„çº¿æ€§ç»„åˆ
\[
\mathbf w_{LOGREG}ï¼\sum_{n=1}^N\left(\alpha_ny_n\right)\mathbf z_nã€‚
\]</p>

<blockquote>
  <h4 id="representer-theorem">è¡¨ç¤ºå®šç†ï¼ˆrepresenter theoremï¼‰</h4>
  <hr />
  <p>å¯¹ä»»æ„çš„$L_2$æ­£åˆ™åŒ–çº¿æ€§æ¨¡å‹     <br />
\begin{equation*}
\min_{\mathbf w}\left({\lambda\over N}\mathbf w^T\mathbf w+{1\over N}\sum_{n=1}^Nerr\left(y_n,\mathbf w^T\mathbf z_n\right)\right)ï¼Œ
\end{equation*} 
å­˜åœ¨èƒ½ç”¨$\mathbf z_n$çº¿æ€§è¡¨ç¤ºçš„æœ€ä½³è§£$\mathbf w_*=\sum_{n=1}^N\beta_n\mathbf z_n$ã€‚</p>
</blockquote>

<p>ä»»æ„$L_2$æ­£åˆ™åŒ–çš„çº¿æ€§æ¨¡å‹éƒ½èƒ½ä½¿ç”¨æ ¸æ–¹æ³•ã€‚$L_2$æ­£åˆ™åŒ–çš„logisticå›å½’ä¼˜åŒ–æ¨¡å‹ä¸º
\[
\min_{\mathbf w}\left({\lambda\over N}\mathbf w^T\mathbf w+{1\over N}\sum_{n=1}^N\log\left(1+\exp\left(-y_n\mathbf w^T\mathbf z_n\right)\right)\right)ã€‚
\]
ç”±ä¸Šè¿°å®šç†å¯çŸ¥ï¼Œæœ€ä½³$\mathbf w$ä¸€å®šæ˜¯$\mathbf z_n$çš„çº¿æ€§ç»„åˆã€‚ç›´æ¥å°†ç”¨$\mathbf z_n$è¡¨ç¤ºçš„$\mathbf w$ä»£å…¥ä¸Šå¼ï¼Œå†ç”¨æ ¸æ–¹æ³•è¡¨ç¤ºï¼Œå¯ä»¥å¾—åˆ°åŸºäº$L_2$æ­£åˆ™åŒ–çš„æ ¸logisticå›å½’ä¼˜åŒ–æ¨¡å‹
\begin{equation}
\min_\beta\left({\lambda\over N}\sum_{n=1}^N\sum_{m=1}^N\beta_n\beta_mK(\mathbf x_n,\mathbf x_m)+{1\over N}\sum_{n=1}^N\log\left(1+\exp\left(-y_n\sum_{m=1}^N\beta_mK(\mathbf x_m,\mathbf x_n)\right)\right)\right)ï¼Œ
\end{equation}
è¿™æ˜¯æ— çº¦æŸæœ€ä¼˜åŒ–é—®é¢˜ï¼ŒGDï¼SGDç­‰éƒ½å¯æ±‚è§£ã€‚ä¸æ”¯æŒå‘é‡æœºä¸åŒï¼ŒKLRçš„å¤§éƒ¨åˆ†$\beta_n\neq 0$ã€‚</p>

]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>æ”¯æŒå‘é‡æœºï¼ˆ4ï¼‰ï¼šsoft-marginæ”¯æŒå‘é‡æœº</title>
      <link href="http://qianjiye.de/2015/01/svm-soft-margin-svm" />
      <pubdate>2015-01-07T17:24:31+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/svm-soft-margin-svm</guid>
      <content:encoded>&lt;![CDATA[<h2 id="soft-margin">soft-marginæ”¯æŒå‘é‡æœº</h2>

<p>åœ¨æ±‚è§£æ”¯æŒå‘é‡æœºå‚æ•°çš„äºŒæ¬¡è§„åˆ’ä¸­ï¼Œçº¦æŸæ¡ä»¶è¦æ±‚æ‰€æœ‰ç‚¹è¢«æ­£ç¡®åˆ†ç±»çš„å«<strong>hard-marginæ”¯æŒå‘é‡æœº</strong>ã€‚è¿™ç±»æ”¯æŒå‘é‡æœºè¿‡æ‹ŸåˆåŸå› ï¼šï¼ˆ1ï¼‰ç‰¹å¾è½¬æ¢åŠŸèƒ½å¤ªå¼ºï¼›ï¼ˆ2ï¼‰åšæŒæ‰€æœ‰ç‚¹éƒ½è¢«æ­£ç¡®åˆ†ç±»ã€‚</p>

<p>å¯ä»¥é€šè¿‡æ”¾å®½æ¡ä»¶ï¼Œå®¹å¿éƒ¨åˆ†å™ªå£°ï¼ˆå®¹è®¸è¿™éƒ¨åˆ†å™ªå£°æ•°æ®åˆ†ç±»é”™è¯¯ï¼‰ï¼Œä½¿å¾—æ”¯æŒå‘é‡æœºå…·æœ‰æ›´å¥½çš„æ³›åŒ–æ€§èƒ½ã€‚</p>

<p>å¯¹äºpocket PLAï¼Œç›®æ ‡å‡½æ•°ä¸º
\[
\min\limits_{b,\mathbf w}\sum_{n=1}^N\left[\left[y_n\neq\mbox{sign}\left(\mathbf w^T\mathbf z_n+b\right)\right]\right]ï¼Œ
\]
ç»“åˆ<a href="/2015/01/svm-linear-svm/#mjx-eqn-eqlinear-svm-model">çº¿æ€§æ”¯æŒå‘é‡æœº</a>ï¼Œå¯ä»¥å¾—åˆ°å®¹å¿é”™åˆ†çš„ä¼˜åŒ–æ¨¡å‹
\[
\begin{aligned}
\min\limits_{b,\mathbf w}&amp;\quad\frac{1}{2}\mathbf w^T\mathbf w + C\sum_{n=1}^N\left[\left[y_n\neq\mbox{sign}\left(\mathbf w^T\mathbf z_n+b\right)\right]\right]\\
\mbox{s.t.}&amp;\quad y_n\left(\mathbf w^T\mathbf z_n+b\right)\geq 1-\infty\cdot\left[\left[y_n\neq\mbox{sign}\left(\mathbf w^T\mathbf z_n+b\right)\right]\right]ï¼Œ
\end{aligned}
\]
$C$æ˜¯è°ƒèŠ‚æœ€å¤§è¾¹ç•Œå’Œå™ªå£°å®¹å¿åº¦çš„å‚æ•°ã€‚ä½†æ˜¯ï¼Œä¸Šè¿°æ¨¡å‹ä¸æ˜¯QPï¼Œå¹¶ä¸”ä¸èƒ½åŒºåˆ«åˆ†ç±»é”™è¯¯æ—¶è¯¯å·®çš„å¤§å°ï¼Œè¿›ä¸€æ­¥é™æ¨¡å‹å˜ä¸º<strong>soft-marginæ”¯æŒå‘é‡æœº</strong>
\begin{equation}
\begin{aligned}
\min\limits_{b,\mathbf w,\boldsymbol\xi}&amp;\quad\frac{1}{2}\mathbf w^T\mathbf w + C\sum_{n=1}^N\xi_n\\
\mbox{s.t.}&amp;\quad y_n\left(\mathbf w^T\mathbf z_n+b\right)\geq 1-\xi_n\\
&amp;\quad\xi_n\geq 0 \mbox{ for all }nï¼Œ
\end{aligned}
\label{eq:soft-margin-primal-svm}
\end{equation}
è¯¥QPæ¨¡å‹æœ‰$\tilde d+1+N$ä¸ªå˜é‡å’Œ$2N$ä¸ªçº¦æŸæ¡ä»¶ï¼Œä¹Ÿè¢«ç§°ä¸ºåŸºäº$\ell_1$æŸå¤±çš„soft-marginã€‚å¦‚æœé‡‡ç”¨$\xi_n^2$ï¼Œåˆ™è¢«ç§°ä¸ºåŸºäº$\ell_2$æŸå¤±çš„soft-margin
\begin{equation*}
\begin{aligned}
\min\limits_{b,\mathbf w,\boldsymbol\xi}&amp;\quad\frac{1}{2}\mathbf w^T\mathbf w + C\sum_{n=1}^N\xi_n^2\\
\mbox{s.t.}&amp;\quad y_n\left(\mathbf w^T\mathbf z_n+b\right)\geq 1-\xi_nï¼Œ
\end{aligned}
\end{equation*}
æ­¤æ—¶ä¸å†éœ€è¦çº¦æŸæ¡ä»¶$\xi_n\geq 0$ã€‚</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-07-svm-soft-margin-svm-margin-violation.png"><img src="/assets/images/2015-01-07-svm-soft-margin-svm-margin-violation.png" alt="è¾¹ç•Œå®¹å¿åº¦" /></a><div class="caption">Figure 1:  è¾¹ç•Œå®¹å¿åº¦ [<a href="/assets/images/2015-01-07-svm-soft-margin-svm-margin-violation.png">PNG</a>]</div></div></div>

<p>$C$æ˜¯è°ƒèŠ‚æœ€å¤§è¾¹ç•Œå’Œè¾¹ç•Œå®¹å¿åº¦çš„å‚æ•°ï¼Œ$\xi_n$æ˜¯å®¹å¿è¯¯å·®çš„å¤§å°ï¼Œå¦‚ä¸Šå›¾æ‰€ç¤ºã€‚$C$è¶Šå°ï¼Œå¯¹æœ€å¤§è¾¹ç•Œè¦æ±‚è¶Šé«˜ï¼›$C$è¶Šå¤§ï¼Œèƒ½å®¹å¿çš„è¾¹ç•Œè¯¯å·®è¶Šå°ã€‚</p>

<h2 id="soft-margin-1">å¯¹å¶soft-marginæ”¯æŒå‘é‡æœº</h2>

<p>soft-marginæ”¯æŒå‘é‡æœºçš„æ‹‰æ ¼æœ—æ—¥å‡½æ•°ä¸º
\[
\begin{aligned}
\mathcal L(b,\mathbf w,\boldsymbol\alpha, \boldsymbol\beta)=
&amp;{1\over 2}\mathbf w^T\mathbf w + C\sum_{n=1}^N\xi_n\\
&amp;+\sum_{n=1}^N\alpha_n\left(1-\xi_n-y_n\left(\mathbf w^T\mathbf z_n+b\right)\right)+\sum_{n=1}^N\beta_n\left(-\xi_n\right)ï¼Œ
\end{aligned}
\]
æ ¹æ®${\partial\mathcal L\over\partial\xi_n}=0$å¯å¾—$C-\alpha_n-\beta_n=0$ï¼Œåˆ©ç”¨åŒ–è§£<a href="/2015/01/svm-dual-svm/#lagrange-dual-problem">æ‹‰æ ¼æœ—æ—¥å¯¹å¶é—®é¢˜</a>ç›¸åŒçš„æ–¹æ³•å¯å¾—
\begin{equation}
\begin{aligned}
\min\limits_{\boldsymbol\alpha}&amp;\quad\frac{1}{2}\sum_{n=1}^N\sum_{m=1}^N\alpha_n\alpha_my_ny_m\mathbf z_n^T\mathbf z_m-\sum_{n=1}^N\alpha_n \\
\mbox{subject to}&amp;\quad\sum_{n=1}^Ny_n\alpha_n=0\\
&amp;\quad 0\leq\alpha_n\leq C,\mbox{ for }n=1,2,\ldots,N \\
\mbox{implicitly}&amp;\quad \mathbf w=\sum_{n=1}^N\alpha_ny_n\mathbf z_n\\
&amp;\quad\beta_n=C-\alpha_n,\mbox{ for }n=1,2,\ldots,Nï¼Œ
\end{aligned}
\label{eq:qp-soft-margin-dual-svm}
\end{equation}
ä¸hard-marginå¯¹å¶æ”¯æŒå‘é‡æœºä¸åŒçš„åœ°æ–¹åªæ˜¯$\alpha_n$å¤šäº†ä¸€ä¸ªä¸Šç•Œ$C$ï¼Œè¿™æ˜¯$N$ä¸ªå˜é‡$2N+1$ä¸ªçº¦æŸæ¡ä»¶çš„QPã€‚$\alpha_n$çš„çº¦æŸç•Œä¹Ÿå¯ä»¥è¡¨ç¤ºä¸ºçŸ©é˜µå½¢å¼
\begin{equation}
\mathbf 0_N\leq \mathbf I_N\boldsymbol\alpha \leq C\cdot \mathbf 1_Nã€‚
\end{equation}</p>

<h2 id="soft-margin-2">æ ¸soft-marginæ”¯æŒå‘é‡æœº</h2>

<p>soft-marginæ˜¯å®é™…ä¸­å¹¿æ³›åº”ç”¨çš„æ”¯æŒå‘é‡æœºã€‚</p>

<p>soft-marginçš„æ”¯æŒå‘é‡æœºä¸<a href="/2015/01/svm-kernel-svm/#kernel-trick">hard-marginçš„æ”¯æŒå‘é‡æœº</a>åŸºæœ¬ç›¸åŒï¼Œ$\alpha_n$ä¸Šç•Œ$C$çš„é™åˆ¶ï¼Œå¯¼è‡´$b$çš„è®¡ç®—ä¸åŒã€‚</p>

<p>åˆ©ç”¨complementary slacknessæ¡ä»¶å¯å¾—
\begin{equation}
\begin{aligned}
\alpha_n\left(1-\xi_n-y_n\left(\mathbf w^T\mathbf z_n+b\right)\right)=&amp;0\\
\left(C-\alpha_n\right)\xi_n=&amp;0ï¼Œ
\end{aligned}
\label{eq:soft-margin-complementary-slackness}
\end{equation}
å½“$\alpha_s&gt;0$æ—¶ï¼Œ$b=y_s-y_s\xi_s-\mathbf w^T\mathbf z_s$ï¼›å½“$\alpha_s&lt;C$æ—¶ï¼Œ$\xi_s=0$ã€‚æ»¡è¶³$0&lt;\alpha_s&lt;C$çš„ç‚¹ç§°ä¸º<strong>è‡ªç”±æ”¯æŒå‘é‡</strong>$\left(\mathbf x_s, y_s\right)$ï¼Œåˆ©ç”¨è¿™äº›ç‚¹å®¹æ˜“å¾—åˆ°
\begin{equation}
b=y_s-\sum\limits_{SV}\alpha_ny_nK\left(\mathbf x_n, \mathbf x_s\right)ã€‚
\end{equation}
åœ¨æå°‘æ•°æƒ…å†µä¸‹ï¼Œä¸å­˜åœ¨è‡ªç”±æ”¯æŒå‘é‡ï¼Œ$b$é€šè¿‡ä¸ç­‰å¼é™å®šï¼Œåªè¦æ»¡è¶³KKTæ¡ä»¶çš„å–å€¼éƒ½æ˜¯åˆç†çš„$b$ã€‚</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-07-svm-soft-margin-svm-soft-margin-gaussian-svm.png"><img src="/assets/images/2015-01-07-svm-soft-margin-svm-soft-margin-gaussian-svm.png" alt="soft-marginé«˜æ–¯æ ¸æ”¯æŒå‘é‡æœº" /></a><div class="caption">Figure 2:  soft-marginé«˜æ–¯æ ¸æ”¯æŒå‘é‡æœº [<a href="/assets/images/2015-01-07-svm-soft-margin-svm-soft-margin-gaussian-svm.png">PNG</a>]</div></div></div>

<p>ä¸Šå›¾å±•ç¤ºäº†soft-marginé«˜æ–¯æ ¸æ”¯æŒå‘é‡æœºçš„æ•ˆæœï¼Œç°è‰²çš„åŒºåŸŸè¡¨ç¤ºæœ€å¤§åˆ†ç±»é—´éš”ã€‚ä»å›¾ä¸­å¯ä»¥çœ‹å‡ºï¼Œ$C$è¶Šå¤§ï¼Œå¯¹è¯¯å·®çš„å®¹å¿è¶Šå¼±ï¼Œè¶Šå®¹æ˜“å¯¼è‡´è¿‡æ‹Ÿåˆã€‚</p>

<h2 id="alphan">$\alpha_n$çš„ç‰©ç†å«ä¹‰</h2>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-07-svm-soft-margin-svm-alpha-n.png"><img src="/assets/images/2015-01-07-svm-soft-margin-svm-alpha-n.png" alt="ä¸åŒç±»å‹çš„æ•°æ®ç‚¹" /></a><div class="caption">Figure 3:  ä¸åŒç±»å‹çš„æ•°æ®ç‚¹ [<a href="/assets/images/2015-01-07-svm-soft-margin-svm-alpha-n.png">PNG</a>]</div></div></div>

<p>é€šè¿‡å…¬å¼\eqref{eq:soft-margin-complementary-slackness}å¯çŸ¥ï¼Œ$\alpha_n$å°†æ•°æ®ç‚¹åˆ†ä¸ºå¦‚ä¸Šå›¾æ‰€ç¤ºçš„3ç§ç±»å‹ï¼š</p>

<ol>
  <li>å½“$\alpha_n=0$æ—¶ï¼Œéæ”¯æŒå‘é‡ï¼Œ$\xi_n=0$ï¼Œä½äºè¾¹ç•Œä¹‹å¤–ï¼Œæå°‘æ•°å¯èƒ½åœ¨è¾¹ç•Œä¸Šï¼›</li>
  <li>å½“$0&lt;\alpha_n&lt;C$æ—¶ï¼Œè‡ªç”±ï¼ˆfreeï¼‰æ”¯æŒå‘é‡$\square$ï¼Œ$\xi_n=0$ï¼Œä½äºè¾¹ç•Œä¸Šï¼Œç”¨äºè®¡ç®—$b$ï¼›</li>
  <li>å½“$\alpha_n=C$æ—¶ï¼Œæœ‰ç•Œï¼ˆboundedï¼‰æ”¯æŒå‘é‡$\triangle$ï¼Œ$\xi_n=1-y_n\left(\mathbf w^T\mathbf z_n+b\right)$ï¼Œè½åœ¨è¾¹ç•Œå†…ï¼Œå¯èƒ½æ­£ç¡®åˆ†ç±»ä¹Ÿå¯èƒ½åˆ†é”™ï¼Œæå°‘æ•°å¯èƒ½åœ¨è¾¹ç•Œä¸Šã€‚</li>
</ol>

<h2 id="section">æ¨¡å‹é€‰æ‹©</h2>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-01-07-svm-soft-margin-svm-model-select.png"><img src="/assets/images/2015-01-07-svm-soft-margin-svm-model-select.png" alt="ï¼»ä¸­ï¼½ï¼šäº¤å‰éªŒè¯è¯¯å·®ï¼›ï¼»å³ï¼½ï¼šæ”¯æŒå‘é‡ä¸ªæ•°" /></a><div class="caption">Figure 4:  ï¼»ä¸­ï¼½ï¼šäº¤å‰éªŒè¯è¯¯å·®ï¼›ï¼»å³ï¼½ï¼šæ”¯æŒå‘é‡ä¸ªæ•° [<a href="/assets/images/2015-01-07-svm-soft-margin-svm-model-select.png">PNG</a>]</div></div></div>

<p>ä¸Šå›¾å·¦æ˜¯soft-marginé«˜æ–¯æ ¸æ”¯æŒå‘é‡æœºçš„åˆ†ç±»æ•ˆæœï¼Œæ¨ªè½´æ˜¯$C$çš„å˜åŒ–ï¼Œçºµè½´æ˜¯$\gamma$çš„å˜åŒ–ã€‚ç”±äº$E_{cv}(C,\gamma)$ä¸å…‰æ»‘ï¼Œé€šå¸¸çš„æ¨¡å‹é€‰æ‹©æ–¹æ³•æ˜¯é€šè¿‡$C$å’Œ$\gamma$çš„æ•°æ®ç½‘æ ¼ï¼Œåˆ©ç”¨äº¤å‰éªŒè¯çš„æ–¹æ³•é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼Œä¸Šå›¾ä¸­æ‰€ç¤ºï¼Œé€‰æ‹©äº†å·¦ä¸‹è§’çš„æ¨¡å‹ã€‚</p>

<p>äº¤å‰éªŒè¯ä¸­ï¼Œå°†æ•°æ®åˆ†ä¸º$N$ä»½çš„éªŒè¯ç§°ä¸º<strong>leave-one-outäº¤å‰éªŒè¯</strong>ï¼Œå®ƒçš„è¯¯å·®ä¸Šç•Œæ˜¯
\begin{equation}
E_{loocv}\leq\frac{\#SV}{N}ï¼Œ
\label{eq:eloocv-upper-bound}
\end{equation}
$\#SV$è¡¨ç¤ºæ”¯æŒå‘é‡çš„ä¸ªæ•°ã€‚å¯ä»¥é€šè¿‡æ”¯æŒå‘é‡çš„ä¸ªæ•°è¿›è¡Œæ¨¡å‹é€‰æ‹©ã€‚ç”±äºæ”¯æŒå‘é‡ä¸ªæ•°çš„å‡½æ•°ä¹Ÿæ˜¯éå…‰æ»‘çš„ï¼Œéš¾ä»¥ä¼˜åŒ–ï¼Œä¹Ÿé‡‡å–åˆ©ç”¨$C$å’Œ$\gamma$çš„æ•°æ®ç½‘æ ¼ï¼Œå¤šæ¬¡è®¡ç®—ååšé€‰æ‹©ã€‚</p>

<p>ç”±äº\eqref{eq:eloocv-upper-bound}ä¹Ÿåªæ˜¯ç»™å‡ºäº†$E_{loocv}$çš„ä¸Šç•Œï¼Œé€šå¸¸ç”¨äºå½“$E_{cv}$è®¡ç®—é‡å¾ˆå¤§æ—¶æ¨¡å‹çš„å®‰å…¨æ£€æŸ¥ï¼Œå‰”é™¤é‚£äº›æ”¯æŒå‘é‡è¿‡å¤šçš„å±é™©æ¨¡å‹ï¼Œç„¶åå†åœ¨å‰©ä½™æ¨¡å‹ä¸­è¿›ä¸€æ­¥åšäº¤å‰éªŒè¯é€‰æ‹©åˆé€‚çš„æ¨¡å‹ã€‚</p>

]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>æ”¯æŒå‘é‡æœºï¼ˆ3ï¼‰ï¼šæ ¸æ”¯æŒå‘é‡æœº</title>
      <link href="http://qianjiye.de/2015/01/svm-kernel-svm" />
      <pubdate>2015-01-06T14:25:58+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/svm-kernel-svm</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">å›é¡¾å¯¹å¶æ”¯æŒå‘é‡æœº</h2>

<p>å½“ç‰¹å¾ç©ºé—´ç»´æ•°$\tilde d$å¾ˆå¤§æ—¶ï¼Œè®¡ç®—$q_{n,m}=y_ny_m\mathbf z_n^T\mathbf z_m$æ˜¯å¯¹å¶æ”¯æŒå‘é‡æœºçš„æ±‚è§£ç“¶é¢ˆã€‚</p>

<p>èƒ½å¦æ‰¾åˆ°æ¯”$O(\tilde d)$å¿«çš„æ–¹æ³•è®¡ç®—$\mathbf z_n^T\mathbf z_m=\Phi(\mathbf x_n)^T\Phi(\mathbf x_m)$ï¼Ÿèƒ½å¦å°†å…ˆç‰¹å¾è½¬æ¢å†è®¡ç®—å†…ç§¯çš„ä¸¤æ­¥åˆä¸ºä¸€æ­¥å‘¢ï¼Ÿ</p>

<h2 id="kernel-trick">æ ¸æŠ€å·§</h2>

<p>å¯¹äº2é˜¶å¤šé¡¹å¼å˜æ¢
\[
\Phi_2(\mathbf x)=\left(1, x_1,x_2,\ldots,x_d,x_1^2,x_1x_2,\ldots,x_1x_d,x_2x_1,x_2^2,\ldots,x_2x_d,\ldots,x_d^2\right)ï¼Œ
\]
ä¸ºäº†ç®€åŒ–åŒæ—¶åŒ…å«äº†$x_1x_2$å’Œ$x_2x_1$è¿™æ ·çš„é¡¹ã€‚å˜æ¢ä¹‹å$Z$ç©ºé—´çš„å†…ç§¯å¯ä»¥å¯ç›´æ¥é€šè¿‡$X$ç©ºé—´è®¡ç®—
\[
\Phi_2(\mathbf x)^T\Phi_2(\mathbf xâ€™)=1+\left(\mathbf x^T\mathbf xâ€™\right)+\left(\mathbf x^T\mathbf xâ€™\right)^2ã€‚
\]
è¿™ç§ç‰¹å¾è½¬æ¢å’Œå†…ç§¯åˆå¹¶çš„æ–¹æ³•ç§°ä¹‹ä¸º<strong>æ ¸å‡½æ•°</strong>ï¼Œ
\begin{equation*}
K_{\Phi_2}\left(\mathbf x,\mathbf xâ€™\right)=\Phi_2(\mathbf x)^T\Phi_2(\mathbf xâ€™)ã€‚
\end{equation*}
åˆ©ç”¨æ ¸å‡½æ•°ï¼Œå¯ä»¥ç®€åŒ–å¯¹å¶æ”¯æŒå‘é‡æœºçš„å®ç°ï¼ŒäºŒæ¬¡é¡¹çš„ç³»æ•°ä¸º
\begin{equation}
q_{n,m}=y_ny_m\mathbf z_n^T\mathbf z_m=y_ny_mK\left(\mathbf x_n,\mathbf x_m\right)ï¼Œ
\end{equation}
åˆ©ç”¨æ”¯æŒå‘é‡$\left(\mathbf x_s, y_s\right)$è®¡ç®—åç§»é‡
\begin{equation}
\begin{aligned}
b
=&amp;y_s-\mathbf w^T\mathbf z_s\\
=&amp;y_s-\left(\sum_{n=1}^N\alpha_ny_n\mathbf z_n\right)^T\mathbf z_s\\
=&amp;y_s-\sum_{n=1}^N\alpha_ny_nK\left(\mathbf x_n,\mathbf x_s\right)
ï¼Œ
\end{aligned}
\end{equation}
å¯¹äºç‰¹å®šçš„è¾“å…¥$\mathbf x$ï¼Œåˆ¤åˆ«å‡½æ•°ä¸º
\begin{equation}
\begin{aligned}
g_{SVM}(\mathbf x)
=&amp;\mbox{sign}\left(\mathbf w^T\Phi(\mathbf x)+b\right)\\
=&amp;\mbox{sign}\left(\sum_{n=1}^N\alpha_ny_nK\left(\mathbf x_n,\mathbf x\right)+b\right)
ã€‚
\end{aligned}
\end{equation}
ä»ä¸Šé¢çš„å…¬å¼å¯ä»¥çœ‹å‡ºï¼Œè®¡ç®—ä¸å†ä¾èµ–å˜æ¢åçš„ç©ºé—´ï¼Œåªä¾èµ–åŸç©ºé—´ï¼Œ$b$å’Œåˆ¤åˆ«å‡½æ•°åªä¾èµ–åŸç©ºé—´çš„æ”¯æŒå‘é‡ï¼Œå¤§å¤§ç®€åŒ–äº†è®¡ç®—ã€‚</p>

<h2 id="section-1">å¤šé¡¹å¼æ ¸</h2>

<p>ä»¿ç…§2é˜¶å¤šé¡¹å¼æ ¸çš„å®šä¹‰ï¼Œå¯ä»¥æ¨å¯¼é«˜é˜¶å¤šé¡¹å¼æ ¸çš„å®šä¹‰ä¸º
\begin{equation}
K_Q(\mathbf x,\mathbf xâ€™)=\left(\zeta + \gamma\mathbf x^T\mathbf xâ€™\right)^Q\quad\zeta\geq 0,\gamma &gt; 0ã€‚
\end{equation}
äº‹å®ä¸Šï¼Œç³»æ•°$\zeta$å’Œ$\gamma$çš„å–å€¼ä¸ä¼šæ”¹å˜å¤šé¡¹å¼æ‰€åœ¨çš„ç©ºé—´ï¼Œè¿™äº›ç³»æ•°ä¼šè¢«$\mathbf w$æ‰€åå™¬ã€‚ä½†æ˜¯ï¼Œä¸åŒçš„ç³»æ•°ä¼šå¾—åˆ°ä¸åŒçš„æ”¯æŒå‘é‡å’Œåˆ¤åˆ«å‡½æ•°ã€‚é€‰æ‹©ä¸åŒçš„æ ¸ï¼Œç›¸å½“äºæ”¹å˜äº†è¾¹ç•Œçš„å®šä¹‰ã€‚å¤šé¡¹å¼æ ¸å¯ä»¥åœ¨å‡ ä¹ä¸å¢åŠ è®¡ç®—é‡çš„æƒ…å†µä¸‹ï¼Œå¾—åˆ°å¤æ‚çš„åˆ¤åˆ«ç•Œã€‚æ”¯æŒå‘é‡æœºé€šè¿‡large-marginæ§åˆ¶åˆ¤åˆ«ç•Œçš„å¤æ‚åº¦ã€‚</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-06-svm-kernel-svm-poly2-kernel-svm.png"><img src="/assets/images/2015-01-06-svm-kernel-svm-poly2-kernel-svm.png" alt="2é˜¶å¤šé¡¹å¼æ ¸SVMçš„æ•ˆæœ" /></a><div class="caption">Figure 1:  2é˜¶å¤šé¡¹å¼æ ¸SVMçš„æ•ˆæœ [<a href="/assets/images/2015-01-06-svm-kernel-svm-poly2-kernel-svm.png">PNG</a>]</div></div></div>

<p>ä¸Šå›¾æ˜¯2é˜¶å¤šé¡¹å¼æ ¸æ”¯æŒå‘é‡æœºçš„æ•ˆæœï¼Œä¸åŒç³»æ•°ä¸‹çš„æ”¯æŒå‘é‡å’Œåˆ¤åˆ«ç•Œä¸åŒã€‚</p>

<p>å½“$\zeta=0,\gamma=1$æ—¶ï¼Œå¤šé¡¹å¼æ ¸å°±å˜ä¸ºäº†çº¿æ€§æ ¸ã€‚çº¿æ€§æ ¸åˆ©ç”¨åŸå§‹æ”¯æŒå‘é‡æœºå°±æ¯”è¾ƒé«˜æ•ˆã€‚å› æ­¤ï¼Œåº”å½“é¦–å…ˆå°è¯•çº¿æ€§æ ¸ï¼Œå½“çº¿æ€§æ ¸ä¸èƒ½æ»¡è¶³è¦æ±‚æ—¶å†å°è¯•å…¶å®ƒé«˜é˜¶æ ¸ã€‚</p>

<h2 id="section-2">é«˜æ–¯æ ¸</h2>

<p>å¯¹äº1ç»´æ•°æ®çš„é«˜æ–¯æ ¸ï¼Œåˆ©ç”¨Taylorå±•å¼å¯å¾—
\begin{equation*}
\begin{aligned}
K(x,xâ€™)
=&amp;\exp\left(-\left(x-xâ€™\right)^2\right)\\
=&amp;\exp\left(-x^2\right)\exp\left(-xâ€™^2\right)\exp\left(2xxâ€™\right)\\
=&amp;\exp\left(-x^2\right)\exp\left(-xâ€™^2\right)\sum_{i=0}^\infty\frac{\left(2xxâ€™\right)^i}{i!}\\
=&amp;\sum_{i=0}^\infty\exp\left(-x^2\right)\exp\left(-xâ€™^2\right)\sqrt{\frac{2^i}{i!}}\sqrt{\frac{2^i}{i!}}x^ixâ€™^i\\
=&amp;\Phi(x)^T\Phi(xâ€™)ï¼Œ
\end{aligned}
\end{equation*}
å…¶ä¸­$\Phi(x)=\exp\left(-x^2\right)\cdot\left(1,\sqrt{\frac{2^1}{1!}}x,\sqrt{\frac{2^2}{2!}}x^2,\ldots\right)$ï¼Œå®¹æ˜“çœ‹å‡ºè¿™æ˜¯æ— ç©·ç»´çš„ç‰¹å¾å˜æ¢ã€‚æ›´ä¸€èˆ¬çš„é«˜æ–¯æ ¸å®šä¹‰ä¸º
\begin{equation}
K\left(\mathbf x,\mathbf xâ€™\right)=\exp\left(-\gamma\left\lVert\mathbf x-\mathbf xâ€™\right\rVert^2\right)\quad \gamma&gt;0ã€‚
\end{equation}
é«˜æ–¯æ ¸ä¹Ÿæˆä¸ºå¾„å‘åŸºå‡½æ•°ï¼ˆRBFï¼ŒRadial Basis Functionï¼‰æ ¸ã€‚åŸºäºé«˜æ–¯æ ¸çš„åˆ¤åˆ«å‡½æ•°ä¸º
\begin{equation}
g_{SVM}(\mathbf x)=\mbox{sign}\left(\sum_{SV}\alpha_ny_n\exp\left(-\gamma\left\lVert\mathbf x-\mathbf x_n\right\rVert^2\right)+b\right)ï¼Œ
\end{equation}
å®ƒæ˜¯ä»¥æ”¯æŒå‘é‡ä¸ºä¸­å¿ƒçš„é«˜æ–¯å‡½æ•°çš„çº¿æ€§ç»„åˆï¼Œä¸å†ä¾èµ–$\mathbf w$ï¼Œåªä¾èµ–äºæ”¯æŒå‘é‡å’Œç³»æ•°$\alpha_n$ã€‚</p>

<p>é«˜æ–¯æ ¸ç›¸å½“äºè¿›è¡Œäº†æ— é™ç»´çš„ç‰¹å¾è½¬æ¢ï¼Œå¯ä»¥å¾—åˆ°å¤æ‚çš„åˆ¤åˆ«ç•Œï¼Œæ³›åŒ–æ€§èƒ½é€šè¿‡æœ€å¤§è¾¹ç•Œâ€œä¿è¯â€ã€‚</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-06-svm-kernel-svm-gaussian-kernel-svm.png"><img src="/assets/images/2015-01-06-svm-kernel-svm-gaussian-kernel-svm.png" alt="é«˜æ–¯æ ¸çš„SVMçš„æ•ˆæœ" /></a><div class="caption">Figure 2:  é«˜æ–¯æ ¸çš„SVMçš„æ•ˆæœ [<a href="/assets/images/2015-01-06-svm-kernel-svm-gaussian-kernel-svm.png">PNG</a>]</div></div></div>

<p>ä¸Šå›¾æ˜¯ä¸åŒç³»æ•°çš„é«˜æ–¯æ ¸æ”¯æŒå‘é‡æœºçš„æ•ˆæœï¼Œ$\gamma$è¶Šå¤§ï¼Œé«˜æ–¯å‡½æ•°è¶Šå°–ï¼Œè¶Šå®¹æ˜“è¿‡æ‹Ÿåˆã€‚å½“$\gamma\rightarrow\infty$æ—¶ï¼Œ$K_{lim}\left(\mathbf x,\mathbf xâ€™\right)=[[\mathbf xï¼\mathbf xâ€™]]$ï¼Œç›¸å½“äºä¸¥æ ¼åˆ¤æ–­æ˜¯å¦ä¸æ”¯æŒå‘é‡ä¸€è‡´ã€‚</p>

<h2 id="section-3">å°ç»“</h2>

<p>å„ç§æ ¸å‡½æ•°çš„æ¯”è¾ƒå¦‚ä¸‹è¡¨ï¼š</p>

<table>
  <thead>
    <tr>
      <th>æ ¸å‡½æ•°</th>
      <th>ä¼˜åŠ¿</th>
      <th>å±€é™æ€§</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>çº¿æ€§æ ¸</td>
      <td>è®¡ç®—å¿«ï¼›<br />é€šè¿‡$\mathbf w$å’Œæ”¯æŒå‘é‡å®¹æ˜“è§£é‡Š</td>
      <td>æ— æ³•å¤„ç†çº¿æ€§ä¸å¯åˆ†æ•°æ®</td>
    </tr>
    <tr>
      <td>å¤šé¡¹å¼æ ¸</td>
      <td>å¯ä»¥é€šè¿‡æ¬¡æ•°$Q$æ§åˆ¶å¤æ‚åº¦</td>
      <td>å½“$Q$å¾ˆå¤§æ—¶æ•°å€¼è®¡ç®—å›°éš¾<br />ï¼ˆå½“$\left\lvert\zeta+\gamma\mathbf x^T\mathbf xâ€™\right\rvert&lt;1$æ—¶ï¼Œ$K(\mathbf x, \mathbf xâ€™)\rightarrow 0$ï¼‰ï¼›<br />3ä¸ªå‚æ•°éš¾ä»¥é€‰æ‹©</td>
    </tr>
    <tr>
      <td>é«˜æ–¯æ ¸</td>
      <td>å¼ºå¤§ï¼›<br />$K(\mathbf x, \mathbf xâ€™)$æœ‰ç•Œï¼›<br />1ä¸ªå‚æ•°éš¾ä»¥é€‰æ‹©ï¼›</td>
      <td>æ²¡æœ‰æ˜¾ç¤ºçš„$\mathbf w$ä¾›è§£è¯»ï¼›<br />è®¡ç®—æ¯”çº¿æ€§æ ¸æ…¢ï¼›<br />å¤ªå¼ºå¤§å¯¼è‡´å®¹æ˜“è¿‡æ‹Ÿåˆ</td>
    </tr>
  </tbody>
</table>

<p>å½“é‡‡ç”¨å¤šé¡¹å¼æ ¸æ—¶ï¼Œå¦‚æœ$Q$è¾ƒå°ï¼Œå¯ä»¥å°è¯•ç›´æ¥åˆ©ç”¨ç‰¹å¾å˜æ¢å’ŒåŸå§‹æ”¯æŒå‘é‡æœºï¼Œæ±‚è§£é€Ÿåº¦å¯èƒ½æ¯”æ ¸æ–¹æ³•æ›´å¿«ã€‚</p>

<p>æ ¸æ˜¯ä¸€ç§ç‰¹æ®Šçš„ç›¸ä¼¼æ€§åº¦é‡ï¼Œä½†æ˜¯ä¸æ˜¯æ‰€æœ‰çš„ç›¸ä¼¼æ€§åº¦é‡éƒ½å¯ä»¥ä½œä¸ºæ ¸ã€‚æœ‰æ•ˆçš„æ ¸å¿…é¡»æ»¡è¶³<strong>Merceræ¡ä»¶</strong>ï¼ˆå……è¦æ¡ä»¶ï¼‰ï¼šæ ¸å‡½æ•°çŸ©é˜µ
\begin{equation*}
\begin{aligned}
\mathbf K
=&amp;\begin{bmatrix}
\Phi(\mathbf x_1)^T\Phi(\mathbf x_1) &amp; \Phi(\mathbf x_1)^T\Phi(\mathbf x_2) &amp;\ldots &amp;\Phi(\mathbf x_1)^T\Phi(\mathbf x_N)\\
\Phi(\mathbf x_2)^T\Phi(\mathbf x_1) &amp; \Phi(\mathbf x_2)^T\Phi(\mathbf x_2) &amp;\ldots &amp;\Phi(\mathbf x_2)^T\Phi(\mathbf x_N)\\
\ldots&amp;\ldots&amp;\ldots&amp;\ldots\\
\Phi(\mathbf x_N)^T\Phi(\mathbf x_1) &amp; \Phi(\mathbf x_N)^T\Phi(\mathbf x_2) &amp;\ldots &amp;\Phi(\mathbf x_N)^T\Phi(\mathbf x_N)
\end{bmatrix}\\
=&amp;\left[\mathbf z_1\quad\mathbf z_2\quad\ldots\quad\mathbf z_N\right]^T\left[\mathbf z_1\quad\mathbf z_2\quad\ldots\quad\mathbf z_N\right]\\
=&amp;\mathbf Z\mathbf Z^T
\end{aligned}
\end{equation*}
å¿…é¡»æ˜¯å¯¹ç§°åŠæ­£å®šã€‚</p>

<p>è‹¥$K_1(\mathbf x,\mathbf xâ€™)=\Phi_1(\mathbf x)^T\Phi_1(\mathbf xâ€™)$å’Œ$K_2(\mathbf x,\mathbf xâ€™)=\Phi_2(\mathbf x)^T\Phi_2(\mathbf xâ€™)$æ˜¯ä¸¤ä¸ªæœ‰æ•ˆçš„æ ¸ï¼Œé‚£ä¹ˆä¸‹é¢ç”Ÿæˆçš„ä¹Ÿæ˜¯æœ‰æ•ˆçš„æ ¸ï¼š</p>

<ul>
  <li>$K(\mathbf x,\mathbf xâ€™) = K_1(\mathbf x,\mathbf xâ€™)\cdot K_2(\mathbf x,\mathbf xâ€™)$ï¼›</li>
  <li>$K(\mathbf x,\mathbf xâ€™) = K_1(\mathbf x,\mathbf xâ€™)+K_2(\mathbf x,\mathbf xâ€™)$ï¼›</li>
  <li>$K(\mathbf x,\mathbf xâ€™) = (1-K_1(\mathbf x,\mathbf xâ€™))^{-1},\quad 0&lt;K_1(\mathbf x,\mathbf xâ€™)&lt;1$ï¼›</li>
  <li>$K(\mathbf x,\mathbf xâ€™) = \alpha K_1(\mathbf x,\mathbf xâ€™),\quad\alpha\in\mathbb R$ã€‚</li>
</ul>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>æ”¯æŒå‘é‡æœºï¼ˆ2ï¼‰ï¼šå¯¹å¶æ”¯æŒå‘é‡æœº</title>
      <link href="http://qianjiye.de/2015/01/svm-dual-svm" />
      <pubdate>2015-01-05T18:24:26+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/svm-dual-svm</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">å¯¹å¶æ”¯æŒå‘é‡æœºçš„ä»·å€¼</h2>

<p>å¯¹äºæ±‚è§£éçº¿æ€§æ”¯æŒå‘é‡æœºç³»æ•°çš„QPï¼Œæœ‰$\tilde d+1$ä¸ªå˜é‡å’Œ$N$ä¸ªçº¦æŸæ¡ä»¶ï¼Œå¯¹äºç»è¿‡éçº¿æ€§ç‰¹å¾å˜æ¢å$Z$ç©ºé—´çš„ç‰¹å¾ç»´æ•°$\tilde d$ä¸€èˆ¬å¾ˆå¤§ã€‚å½“$\tilde d$å¾ˆå¤§æ—¶ï¼Œæ±‚è§£æ¯”è¾ƒå…·æœ‰æŒ‘æˆ˜æ€§ã€‚</p>

<p>å¯¹å¶æ”¯æŒå‘é‡æœºæ˜¯æ”¯æŒå‘é‡æœºçš„å¦ä¸€ç§å½¢å¼ï¼Œå®ƒä¸ä¾èµ–$\tilde d$ï¼Œæœ‰$N$ä¸ªå˜é‡å’Œ$N+1$ä¸ªçº¦æŸæ¡ä»¶ã€‚</p>

<h2 id="section-1">æ‹‰æ ¼æœ—æ—¥ä¹˜å­æ³•</h2>

<p>æ­£åˆ™åŒ–é‡‡ç”¨å¸¦çº¦æŸçš„æœ€å°åŒ–æ–¹æ³•
\[
\min\limits_{\mathbf w} E_{in}(\mathbf w)\mbox{ s.t. }\mathbf w^T\mathbf w \leq Cï¼Œ
\]
å¯ä»¥é€šè¿‡å¦‚ä¸‹ç­‰ä»·çš„æ‹‰æ ¼æœ—æ—¥ä¹˜å­æ³•å®ç°
\[
\min\limits_{\mathbf w} E_{aug}(\mathbf w)=E_{in}(\mathbf w)+{\lambda\over N}\mathbf w^T\mathbf wã€‚
\]
æ­£åˆ™åŒ–é€šè¿‡å°†$\lambda$ä½œä¸º<strong>ç¡®å®šå€¼</strong>ï¼Œä»£æ›¿$C$ä½œä¸ºçº¦æŸæ¡ä»¶ï¼Œæ±‚è§£æ›´å®¹æ˜“ã€‚å¯¹å¶æ”¯æŒå‘é‡æœºä¸åŒäºæ­£åˆ™åŒ–ï¼Œå®ƒå°†$N$ä¸ª$\lambda$è§†ä¸º<strong>å˜é‡</strong>æ±‚è§£ã€‚</p>

<p>å½“$\boldsymbol\alpha_n$ä¸ºæ‹‰æ ¼æœ—æ—¥ä¹˜å­æ—¶ï¼Œæ±‚è§£æ”¯æŒå‘é‡æœºå‚æ•°çš„æ‹‰æ ¼æœ—æ—¥å‡½æ•°ä¸º
\begin{equation}
\mathcal L(b, \mathbf w, \boldsymbol \alpha) = {1\over 2}\mathbf w^T\mathbf w + \sum_{n=1}^N\alpha_n\left(1-y_n\left(\mathbf w^T\mathbf z_n+b\right)\right)ã€‚
\end{equation}</p>

<h2 id="lagrange-dual-problem">æ‹‰æ ¼æœ—æ—¥å¯¹å¶é—®é¢˜</h2>

<p>æ ¹æ®æ‹‰æ ¼æœ—æ—¥å‡½æ•°ï¼Œå¯å¾—
\begin{equation}
\begin{aligned}
\mbox{SVM}\equiv &amp;\min\limits_{b,\mathbf w}\max\limits_{\mbox{all }\alpha_n\geq 0}\mathcal L(b,\mathbf w, \boldsymbol\alpha)\\
=&amp;\min\limits_{b,\mathbf w}\left(\infty\mbox{ if violating };{1\over 2}\mathbf w^T\mathbf w\mbox{ if feasible}\right)ã€‚
\end{aligned}
\end{equation}
æ ¹æ®$b$å’Œ$\mathbf w$å–å€¼çš„åˆ’åˆ†ï¼Œåˆ†ä¸¤ç§æƒ…å†µè§£é‡Šä¸Šè¿°å…¬å¼ï¼š</p>

<ol>
  <li>ä»»æ„violatingçš„$(b,\mathbf w)$ï¼š$\max\limits_{\mbox{all } \alpha_n\geq 0}\left(\square+\sum_n\alpha_n(\mbox{some positive})\right)\rightarrow\infty$ï¼›</li>
  <li>ä»»æ„feasibleçš„$(b,\mathbf w)$ï¼š$\max\limits_{\mbox{all } \alpha_n\geq 0}\left(\square+\sum_n\alpha_n(\mbox{all non-positive})\right)=\square$ã€‚</li>
</ol>

<p>å¯¹$\alphaâ€™_n\geq 0$çš„ä»»æ„$\boldsymbol\alphaâ€™$å¯å¾—
\[
\min\limits_{b,\mathbf w}\max\limits_{\mbox{all } \alpha_n\geq 0}\mathcal L(b,\mathbf w, \boldsymbol\alpha)\geq\min\limits_{b,\mathbf w}\mathcal L(b,\mathbf w, \boldsymbol\alphaâ€™)ï¼Œ
\]
äºæ˜¯æœ‰
\begin{equation}
\min\limits_{b,\mathbf w}\max\limits_{\mbox{all } \alpha_n\geq 0}\mathcal L(b,\mathbf w, \boldsymbol\alpha)\geq\max\limits_{\mbox{all } \alpha_n\geq 0}\min\limits_{b,\mathbf w}\mathcal L(b,\mathbf w, \boldsymbol\alpha)ã€‚
\end{equation}</p>

<p>è‹¥æœè§£å†³äº†å¯¹å¶é—®é¢˜ï¼Œå°±å¾—åˆ°åŸé—®é¢˜çš„ä¸‹ç•Œã€‚ä¸Šå¼å³è¾¹<strong>å°†å¯¹$b$å’Œ$\mathbf w$çš„ä¼˜åŒ–é—®é¢˜è½¬åŒ–æˆäº†å¯¹$\alpha_n$çš„ä¼˜åŒ–é—®é¢˜</strong>ï¼ŒåŒæ—¶å†…å±‚æ˜¯å¯¹$b$å’Œ$\mathbf w$æ— çº¦æŸæ¡ä»¶çš„æœ€ä¼˜åŒ–ï¼Œæ–¹ä¾¿æ±‚è§£ã€‚</p>

<p>å¦‚æœä¸Šå¼ä¸­åªæ˜¯â€œ$\geq$â€ï¼Œåˆ™è¡¨ç¤ºå¼±å¯¹å¶ï¼ˆweak dualityï¼‰ï¼›å¦‚æœä¸Šå¼ä¸­â€œ$=$â€æˆç«‹ï¼Œåˆ™ä¸ºå¼ºå¯¹å¶ï¼ˆstrong dualityï¼‰ã€‚å¯¹äºQPï¼Œâ€œ$=$â€æˆç«‹çš„æ¡ä»¶æ˜¯ï¼šï¼ˆ1ï¼‰åŸé—®é¢˜æ˜¯å‡¸çš„ï¼›ï¼ˆ2ï¼‰åŸé—®é¢˜æœ‰è§£ï¼ˆå¯¹æœ¬é—®é¢˜è€Œè¨€ï¼Œæ•°æ®æ˜¯å¯åˆ†çš„ï¼‰ï¼›ï¼ˆ3ï¼‰çº¿æ€§çº¦æŸæ¡ä»¶ã€‚</p>

<p>å¯¹äºæ”¯æŒå‘é‡æœºï¼Œâ€œ$=$â€æˆç«‹ï¼Œæ±‚è§£å³è¾¹çš„é—®é¢˜å³å¯ã€‚</p>

<h2 id="section-2">åŒ–ç®€æ‹‰æ ¼æœ—æ—¥å¯¹å¶é—®é¢˜</h2>

<p>å¯¹äºå¯¹å¶é—®é¢˜ï¼Œå†…å±‚æ— çº¦æŸä¼˜åŒ–å–å¾—æœ€å°å€¼çš„æ¡ä»¶æ˜¯
\[
{\partial \mathcal L(b, \mathbf w, \boldsymbol\alpha)\over\partial b} = 0;\quad{\partial \mathcal L(b, \mathbf w, \boldsymbol\alpha)\over\partial w_i} = 0ï¼Œ
\]
ä¹Ÿå°±æ˜¯
\[
\sum_{n=1}^N\alpha_ny_n=0;\quad\mathbf w=\sum_{n=1}^N\alpha_ny_n\mathbf z_nã€‚
\]
å°†ä¸Šè¿°å˜é‡å¸¦å…¥å¯¹å¶é—®é¢˜ï¼Œå¯ä»¥åŒ–è§£ä¸º
\[
\max\limits_{\mbox{all }\alpha_n\geq 0,\sum y_n\alpha_n=0,\mathbf w=\sum\alpha_ny_n\mathbf z_n}\min\limits_{b,\mathbf w}\left(\frac{1}{2}\mathbf w^T\mathbf w+\sum_{n=1}^N\alpha_n-\mathbf w^T\mathbf w\right)ï¼Œ
\]
ç»§ç»­å°†$\mathbf w$çš„å–å€¼å¸¦å…¥ï¼Œå¯å¾—
\begin{equation*}
\max\limits_{\mbox{all }\alpha_n\geq 0,\sum y_n\alpha_n=0,\mathbf w=\sum\alpha_ny_n\mathbf z_n}\left(-\frac{1}{2}\left\lVert\sum_{n=1}^N\alpha_ny_n\mathbf z_n\right\rVert^2+\sum_{n=1}^N\alpha_n\right)ï¼Œ
\end{equation*}
åŒ–ä¸ºäºŒæ¬¡è§„åˆ’çš„æ ‡å‡†å½¢å¼ä¸º
\begin{equation}
\begin{aligned}
\min\limits_{\boldsymbol\alpha}&amp;\quad\frac{1}{2}\sum_{n=1}^N\sum_{m=1}^N\alpha_n\alpha_my_ny_m\mathbf z_n^T\mathbf z_m-\sum_{n=1}^N\alpha_n \\
\mbox{subject to}&amp;\quad\sum_{n=1}^Ny_n\alpha_n=0\\
&amp;\quad\alpha_n\geq 0,\mbox{ for }n=1,2,\ldots,Nï¼Œ
\end{aligned}
\label{eq:qp-dual-svm}
\end{equation}</p>

<p>è¯¥ä¼˜åŒ–é—®é¢˜æœ‰$N$ä¸ªå˜é‡ï¼Œ$N+1$ä¸ªçº¦æŸæ¡ä»¶ã€‚æ ¹æ®<a href="/2015/01/svm-linear-svm/#mjx-eqn-eqqp-standard-format">QPçš„æ ‡å‡†å½¢å¼</a>ï¼Œå¯ä»¥å¾—åˆ°åˆ©ç”¨QPæ±‚è§£å¯¹å¶äºŒæ¬¡è§„åˆ’çš„ç³»æ•°
\[
\begin{aligned}
&amp;q_{n,m}=y_ny_m\mathbf z_n^T\mathbf z_m;\quad\mathbf p=-\mathbf 1_N;\\
&amp;\mathbf a_{\geq}=\mathbf y,c_{\geq}=0;\quad\mathbf a_{\leq}=-\mathbf y,c_{\leq}=0;\\
&amp;\mathbf a_n^T=\mbox{n-th unit direction},c_n=0ã€‚
\end{aligned}
\]
ä¸ºäº†åˆ©ç”¨æ ‡å‡†çš„QPï¼Œå°†â€œ$=$â€çº¦æŸè½¬æ¢æˆäº†â€œ$\geq$â€å’Œâ€œ$\leq$â€çº¦æŸã€‚é€šå¸¸æƒ…å†µ$q_{n,m}\neq 0$ï¼Œç³»æ•°å¯¹åº”ç€$N\times N$çš„éç¨€ç–çŸ©é˜µï¼Œ$N$å¾ˆå¤§æ—¶éœ€è¦å ç”¨å¾ˆå¤§çš„å­˜å‚¨ç©ºé—´ã€‚å› æ­¤ï¼Œé€šå¸¸ä¼šé‡‡ç”¨é’ˆå¯¹æ”¯æŒå‘é‡æœºè®¾è®¡çš„ç‰¹æ®ŠQPåŠ é€Ÿæ±‚è§£è¿‡ç¨‹ã€‚</p>

<p>å¯¹å¶æ”¯æŒå‘é‡æœºä¼˜åŒ–é—®é¢˜çš„çŸ©é˜µå½¢å¼ä¸º
\begin{equation}
\begin{aligned}
\min\limits_{\boldsymbol\alpha}&amp;\quad\frac{1}{2}\boldsymbol\alpha^T\mathbf Q_D\boldsymbol\alpha-\mathbf 1^T\boldsymbol\alpha \\
\mbox{subject to}&amp;\quad\mathbf y^T\boldsymbol\alpha=0\\
&amp;\quad\alpha_n\geq 0,\mbox{ for }n=1,2,\ldots,Nï¼Œ
\end{aligned}
\label{eq:qp-dual-svm2}
\end{equation}
å…¶ä¸­$q_{n,m}=y_ny_m\mathbf z_n^T\mathbf z_m$ï¼Œ$\alpha_n$çš„çº¦æŸç•Œä¹Ÿå¯ä»¥è¡¨ç¤ºä¸ºçŸ©é˜µå½¢å¼
\begin{equation}
\mathbf I_N\boldsymbol\alpha \geq \mathbf 0_Nã€‚
\end{equation}</p>

<h2 id="kkt">KKTæ¡ä»¶</h2>

<p>åŸé—®é¢˜å’Œå¯¹å¶é—®é¢˜éƒ½æ˜¯æœ€ä½³è§£éœ€è¦$b,\mathbf w,\boldsymbol\alpha$ä¹‹é—´æ»¡è¶³å¦‚ä¸‹æ¡ä»¶ï¼š</p>

<ol>
  <li>åŸé—®é¢˜å¯è¡Œï¼š$y_n(\mathbf w^T\mathbf z_n+b)\geq 1$ï¼›</li>
  <li>å¯¹å¶é—®é¢˜å¯è¡Œï¼š$\alpha_n\geq 0$ï¼›</li>
  <li>å¯¹å¶é—®é¢˜å†…æœ€ä¼˜åŒ–ï¼š$\sum_{n=1}^N\alpha_ny_n=0;\mathbf w=\sum_{n=1}^N\alpha_ny_n\mathbf z_n$ï¼›</li>
  <li>åŸé—®é¢˜å†…æœ€ä¼˜åŒ–ï¼š$\alpha_n\left(1-y_n\left(\mathbf w^T\mathbf z_n+b\right)\right)=0$ï¼Œè¿™ä¸ªæ¡ä»¶ä¹Ÿç§°ä¸ºcomplementary slacknessï¼Œå…¶ä¸­è‡³å°‘ä¸€é¡¹ä¸º$0$ã€‚</li>
</ol>

<p>è¿™ç§°ä¸ºKKTæ¡ä»¶ï¼Œå®ƒæ˜¯åŸé—®é¢˜å’Œå¯¹å¶é—®é¢˜éƒ½æ˜¯æœ€ä½³è§£çš„å¿…è¦ï¼ˆnecessaryï¼‰æ¡ä»¶ï¼Œæ­¤å¤„ä¹Ÿæ˜¯å……åˆ†ï¼ˆsufficientï¼‰æ¡ä»¶ã€‚</p>

<blockquote>
  <h4 id="example">Example</h4>
  <hr />
  <p>For a single variable $w$, consider minimizing ${1\over 2}w^2$ subject to two linear constraints $w\geq 1$ and $w\leq 3$. We know that the Lagrange function $\mathcal L(w,\alpha)={1\over 2}w^2+\alpha_1(1-w)+\alpha_2(w-3)$. Which of the following equations that contain $\alpha$ are among the KKT conditions of the optimization problem?</p>

  <ol>
    <li>$\alpha_1\geq 0$ and $\alpha_2\geq 0$</li>
    <li>$w=\alpha_1-\alpha_2$</li>
    <li>$\alpha_1(1-w)=0$ and $\alpha_2(w-3)=0$ </li>
    <li>all of the above</li>
  </ol>

  <p>Answerï¼š4</p>
</blockquote>

<p>é€šè¿‡KKTæ¡ä»¶ï¼Œå¯ä»¥åˆ©ç”¨$\boldsymbol\alpha$æ±‚è§£$b$å’Œ$\mathbf w$ã€‚åˆ©ç”¨KKTæ¡ä»¶3å®¹æ˜“æ±‚è§£$\mathbf w$ï¼Œåˆ©ç”¨KKTæ¡ä»¶4ï¼Œå½“$\alpha_n&gt;0$æ—¶ï¼Œ$1-y_n\left(\mathbf w^T\mathbf z_n+b\right)=0$ä¸¤è¾¹åŒæ—¶ä¹˜ä»¥$y_n$å¯å¾—$b$ï¼Œ
\begin{equation}
\left\{
\begin{aligned}
b=&amp;y_n-\mathbf w^T\mathbf z_n \quad\mbox{if }\alpha_n\neq 0ï¼›\\
\mathbf w=&amp;\sum_{n=1}^N\alpha_ny_n\mathbf z_nã€‚
\end{aligned}
\right.
\end{equation}
åˆ©ç”¨ä¸åŒ$\alpha_n&gt;0$æ—¶çš„æ•°æ®ï¼Œç†è®ºä¸Šæ±‚è§£åˆ°çš„$b$åº”è¯¥æ˜¯ä¸€æ ·çš„ï¼Œå¯ä»¥è®¡ç®—å¤šä¸ª$b$ç„¶åå¹³å‡å¾—åˆ°æ›´ç¨³å®šçš„è§£ã€‚</p>

<h2 id="section-3">æ”¯æŒå‘é‡</h2>

<p>$\alpha_n&gt;0$å¯¹åº”çš„ç‚¹ä¸€å®šåœ¨è¾¹ç•Œä¸Šï¼Œè¿™äº›ç‚¹ç§°ä¸º<strong>æ”¯æŒå‘é‡</strong>ã€‚ä¹Ÿæœ‰äº›åœ¨è¾¹ç•Œä¸Šçš„ç‚¹ï¼Œå¯¹åº”çš„$\alpha_n$ä¸ä¸€å®šå¤§äº$0$ã€‚å®¹æ˜“å‘ç°ï¼Œè®¡ç®—$b$å’Œ$\mathbf w$åªéœ€è¦æ”¯æŒå‘é‡å°±å¤Ÿäº†ã€‚</p>

<p>ä»è®¡ç®—å…¬å¼å¯ä»¥å‘ç°ï¼Œ$\mathbf w$å¯ä»¥ç”±$y_n\mathbf z_n$çš„çº¿æ€§ç»„åˆè¡¨ç¤ºï¼Œä¹Ÿå°±æ˜¯$\mathbf w$å¯ç”±æ•°æ®è¡¨ç¤ºï¼Œè¿™å’ŒPLAç®—æ³•ç›¸ä¼¼
\begin{equation*}
\mathbf w_{SVM}=\sum_{n=1}^N\alpha_n\left(y_n\mathbf z_n\right)ï¼Œ
\mathbf w_{PLA}=\sum_{n=1}^N\beta_n\left(y_n\mathbf z_n\right)ï¼Œ
\end{equation*}
å…¶ä¸­$\beta_n$è¡¨ç¤ºçŠ¯é”™è¯¯çš„æ¬¡æ•°ã€‚</p>

<h2 id="section-4">ä¸¤ç§å½¢å¼çš„æ”¯æŒå‘é‡æœº</h2>

<p>åŸå§‹æ”¯æŒå‘é‡æœºé€‚åˆç‰¹å¾ç»´æ•°$\tilde d$è¾ƒå°‘çš„æƒ…å½¢ï¼Œå¯¹å¶å½¢å¼çš„æ”¯æŒå‘é‡æœºé€‚åˆæ•°æ®ç‚¹$N$è¾ƒå°‘çš„æƒ…å½¢ï¼Œä¸¤è€…éƒ½æ˜¯é€šè¿‡æœ€ä¼˜åŒ–æ‰¾åˆ°æœ€å¤§è¾¹ç•Œçš„åˆ¤åˆ«ç•Œã€‚</p>

<p>äº‹å®ä¸Šï¼Œå¯¹å¶å½¢å¼çš„æ”¯æŒå‘é‡æœºå’Œç‰¹å¾ç»´æ•°$\tilde d$ä¹Ÿæœ‰å…³ç³»ï¼Œ$q_{n,m}=y_ny_m\mathbf z_n^T\mathbf z_m$çš„è®¡ç®—ä¹Ÿæ˜¯$\mathbb R^{\tilde d}$ç©ºé—´çš„å†…ç§¯ã€‚</p>

]]&gt;</content:encoded>
    </item>
    
  </channel>
</rss>
